{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05-bigsleep.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNRCN3quQHP6nu0YgFby+vp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jvLmBSMmqRz8"},"source":["# The Big Sleep: BigGAN+CLIP\n","\n","https://openai.com/blog/clip/\n","\n","https://github.com/lucidrains/big-sleep\n","\n","\n","![CLIP 1](https://openaiassets.blob.core.windows.net/$web/clip/draft/20210104b/overview-a.svg \"CLIP 1\")\n","![CLIP 2](https://openaiassets.blob.core.windows.net/$web/clip/draft/20210104b/overview-b.svg \"CLIP 2\")"]},{"cell_type":"code","metadata":{"id":"DnPMv4BjqHx-","cellView":"form"},"source":["#@title Imports\n","!pip install big-sleep --upgrade\n","!pip install gTTS\n","\n","from gtts import gTTS\n","import tqdm\n","from tqdm.notebook import trange\n","from IPython.display import Image, display\n","\n","from big_sleep import Imagine\n","import os\n","from pathlib import Path\n","\n","import moviepy.editor as mpy\n","import glob\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_FHEfP14nrN","cellView":"form"},"source":["#@title Test Big Sleep\n","#@markdown Text to visualize\n","txt = 'green dog on the snow' #@param {type:\"string\"}\n","\n","#@markdown Number of epochs \n","epochs = 20 #@param {type:\"integer\"}\n","#@markdown Number of iterations per epoch \n","iterations = 1000 #@param {type:\"integer\"}\n","#@markdown Save every\n","save_every = 100 #@param {type:\"integer\"}\n","\n","model = Imagine(\n","    text = txt,\n","    save_every = save_every,\n","    lr = 5e-2,\n","    iterations = iterations,\n","    save_progress = True,\n",")\n","path = \"/content/test_images\"\n","Path(path).mkdir(parents=True, exist_ok=True)\n","os.chdir(path)\n","for epoch in trange(epochs, desc = 'epochs'):\n","    for i in trange(iterations, desc = 'iteration'):\n","        model.train_step(epoch, i)\n","\n","        if i == 0 or i % model.save_every != 0:\n","            continue\n","\n","        filename = txt.replace(' ', '_')[:255]\n","        image = Image(f'{path}/{filename}.png')\n","        display(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"S5Y2YFPpuSGw","executionInfo":{"status":"ok","timestamp":1618988397700,"user_tz":-180,"elapsed":930,"user":{"displayName":"Artem Konevskikh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzk0bqzeBuXtDrZ7vBWslL76vC9-a_i8tXACnzQQ=s64","userId":"00874259313111924918"}}},"source":["#@title Text preparation\n","#@markdown Drag-n-drop txt file to the Files sidebar, paste the path to the file you want to use, then run this cell\n","text_file = '/content/Test.txt' #@param {type:\"string\"}\n","\n","#@markdown All the punctuation marks will be replaced with this symbol and text will be splitted into smaller chunks\n","delim = '.' #@param {type:\"string\"}\n","\n","\n","with open(text_file, 'r') as f:\n","  txt = f.read()\n","txt = txt.translate(str.maketrans({k:delim for k in '!\"\\'#$%&()*+,—./:;<=>?@[\\]^_`{|}~'})).replace('\\n', ' ').replace('====================', \". \")\n","# txt = txt.replace('—', delim).replace(':', delim).replace('.', delim).replace(',', delim).replace('?', delim).replace('!', delim).replace('\\n', ' ').replace('====================', \". \")\n","txt_splitted = [t.strip() for t in txt.split(delim) if t!='']\n"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"YDBvTqG8yy3t"},"source":["#@title Print processed text\n","print(len(txt_splitted))\n","print(txt_splitted)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dH4cDcrQukkf","cellView":"form"},"source":["#@title Visualize\n","\n","#@markdown Number of epochs\n","epochs = 10 #@param {type:\"integer\"}\n","#@markdown Number of iterations per epoch\n","iterations =  100#@param {type:\"integer\"}\n","#@markdown Save every\n","save_every = 10#@param {type:\"integer\"}\n","\n","\n","Path(\"/content/text_vis\").mkdir(parents=True, exist_ok=True)\n","for s, sent in enumerate(tqdm.tqdm(txt_splitted)):\n","  path = f\"/content/text_vis/{s:06}\"\n","  Path(path).mkdir(parents=True, exist_ok=True)\n","  os.chdir(path)\n","  model = Imagine(\n","      text = sent.replace('/',' '),\n","      save_every = save_every,\n","      lr = 5e-2,\n","      iterations = iterations,\n","      save_progress = True,\n","  )\n","  for epoch in trange(epochs, desc = 'epochs'):\n","    for i in trange(iterations, desc = 'iteration'):\n","        model.train_step(epoch, i)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9vG7dBTjutcM","cellView":"form"},"source":["\n","\n","accents = {\n","    'Australia':'com.au','United Kingdom':'co.uk', 'United States':'com', 'Canada':'ca', 'India':'co.in', 'Ireland':'ie', 'South Africa':'co.za'\n","}\n","\n","#@title Make clips\n","#@markdown This cell joins generated images to videoclip for each sentence. Then merge them\n","\n","#@markdown FPS (doesn't work with audio)\n","fps = 1 #@param {type:\"integer\"}\n","\n","#@markdown Add voice (fps will be ignored)\n","add_voice = True #@param {type:\"boolean\"}\n","#@markdown Language (currently this notebook supports only English)\n","lang = 'en' #@param ['en']\n","#@markdown Accent (works for English language only)\n","acc = 'United Kingdom' #@param ['Australia','United Kingdom', 'United States', 'Canada', 'India', 'Ireland', 'South Africa']\n","\n","Path(\"/content/vids\").mkdir(parents=True, exist_ok=True)\n","# clips = []\n","for i in trange(len(txt_splitted), desc = 'clips'):\n","  if Path(f\"/content/text_vis/{i:06}\").is_dir():\n","    images_list = sorted(glob.glob(f\"/content/text_vis/{i:06}/*.png\"))\n","    clip = mpy.ImageSequenceClip(images_list, fps=fps)\n","    if add_voice:\n","      tts = gTTS(txt_splitted[i], lang=lang, tld=accents[acc])\n","      tts.save(f\"/content/vids/{i:06}.mp3\")\n","      audio = mpy.AudioFileClip(f\"/content/vids/{i:06}.mp3\")\n","      clip = clip.set_duration(audio.duration)\n","      clip = clip.set_audio(audio)\n","      # clip.audio = mpy.CompositeAudioClip([audio])\n","    clip.write_videofile(f\"/content/vids/{i:06}.mp4\",temp_audiofile=\"tempaudio.m4a\",codec=\"libx264\",remove_temp=False,audio_codec='aac')\n","    # clips.append(clip)\n","\n","# final = mpy.concatenate_videoclips(clips)\n","# final.write_videofile(\"/content/result.mp4\")\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"Wc2mwgvv3l5M"},"source":["#@title Concatinate videos\n","#@markdown The result video will be in **output.mp4**\n","%cd /content/vids\n","!find *.mp4 | sed 's:\\ :\\\\\\ :g'| sed 's/^/file /' > fl.txt; ffmpeg -f concat -i fl.txt -c copy ../output.mp4; rm fl.txt\n"],"execution_count":null,"outputs":[]}]}