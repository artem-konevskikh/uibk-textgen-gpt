Neil Leach
Architecture in the Age of Artificial Intelligence

Attitudes to artificial intelligence (AI) remain remarkably polarised. For some it is a tool with extraordinary potential to make life easier in the future. As Alan Turing wrote of computation in general, ‘This is only a foretaste of what is to come, and only a shadow of what is going to be.’ Meanwhile for others, AI itself poses an existential threat to human civilization. As Stephen Hawking warns us, “The development of full artificial intelligence could spell the end of the human race.”2
In this sense, AI is a two edged sword. It has potential for both good and evil. AI poses a dilemma, and no one sums up this dilemma better than Elon Musk. On the one hand, Musk is himself developing AI based tools for his commercial ventures, from the now well established Tesla car company to the still speculative Neuralink project. On the other hand, Musk is only too aware of the
potential dangers it poses: “I think we should be very careful about artificial intelligence. If I were to
guess like what our biggest existential threat is, it’s probably that. So we need to be very careful with
the artificial intelligence. . . With artificial intelligence we are summoning the demon.”3 Stuart Russell
faces a similar dilemma. Although he is one of the pioneers of AI, and co-author of the influential
book, Artificial Intelligence: A Modern Approach, he has also commissioned an arms control video
warning us of the dangers of ‘slaughterbots’, autonomous AI controlled drones that can kill.4
This series reflects this paradox. This first volume, Architecture in the Age of Artificial Intelligence, is
a celebration of the positive contributions of AI. It outlines the extraordinary achievements of AI in
the past, and speculates about the potential of AI to design buildings for us in the future.5 By contrast,
the second volume, The Death of the Architect, exposes the potential dark side of AI, and outlines the
risks that it poses in terms of unemployment, surveillance, and loss of personal freedom.
These first two volumes are intended as a dialectical foil to each other. There is no presumption that
one should be more persuasive than the other. It is left to readers to form their own opinions, based on
the arguments in both volumes. In some senses, however, the arguments are actually the

AI is now very much part of our lives, even though we might not realise it.
AI identifies our friends on FaceBook, and categorises our images on Instagram. It feeds us news and
advertisements based on our online histories. It filters our email spam. It suggests how we should end
of our sentences. It translates foreign texts. It opens our phones. It feeds us music on Spotify, and
movies on Netflix. It even introduces us to our potential partners.
AI has colonised our homes in the form of Siri, Alexa, Cortana and Google Assistant.6 It monitors our
heating, and checks the quality of our water.7 It controls robots that clean our floors.8 It pays our bills,
helps us with our taxes, reminds us of our appointments and schedules our meetings. In some cases it
allows us to pay for our goods through facial recognition, and to even board our planes. It is
embedded throughout the fabric of our cities, monitoring them, and making them more efficient and
sustainable.
AI also warns us, when driving, if we stray out of lane. It controls self-driving cars, buses and trucks.
It pays our tolls with transponders and vehicle identification systems. It shows us the fastest route, and
tells us where to park.9 It is transforming how we shop, order rides, and organize our lives.
All of a sudden, AI is everywhere.
But it is not as though we even notice it. AI does not look like a robot. In fact it does not look like
anything at all. With AI, think algorithms, not robots. AI is completely invisible. AI controls the
environment around us. Even though we might not even realize it, AI has already infiltrated our lives.
And its influence is growing every day.
It is as though the Earth has been invaded by an invisible, super intelligent, alien species.10
AI and Architecture
What impact will AI have on architecture?
There are several areas where AI is already having a major impact on architectural culture. Its most
noticeable impact has been in academic circles, where AI has burst onto the scene in design studio in
certain progressive schools of architecture.11 Although the most popular AI techniques were
discovered only recently, interest in them has begun to spread like a wildfire. Inspirational images of
buildings and urban design proposals are now being generated automatically by a process often
referred to as ‘hallucination’, a term that also evokes the seemingly hallucinatory nature of the images
generated. AI generated work is starting to attract considerable interest.12 Workshops and tutorials for
generating AI based designs have also become immensely popular.13
AI has also become a hot topic in academic research conferences.14 It has become a popular field for
doctoral research, especially in technologically advanced institutions, such as MIT Media Lab.15
Several academic courses and even programs now focus specifically on AI.16 Within a few years we
can expect AI based courses in every single discipline.
AI is also having a major impact is the world of galleries and exhibitions. The first exhibition of AI
generated artworks was held in 2017, and the first auction of an AI generated artwork in 2018. And
architecture is not far behind. The first exhibition of AI generated architectural designs was held in
2019. There has been considerable interest in AI generated work online, with regular postings on
Instagram, Facebook, WeChat and other social media platforms.
AI is also starting to have an impact on progressive architectural practice. An increasing number of
high profile architects are starting to incorporate new AI based techniques into their design strategies.
Pritzker Prize winner, Thom Mayne, of Morphosis, has begun to explore the potential of AI to
increase the range of design options. Wolf Prix of Coop Himmelb(l)au has used it to improve the
design process. Meanwhile Patrik Schumacher of Zaha Hadid Architects (ZHA) has used it to
simulate the behaviour of occupants in his buildings.
AI is already embedded in standard architectural software, although most architects are probably not
11

Schools that already use AI in the design studio include the Architectural Association (AA), Bartlett School of Architecture, University
College London (Bartlett), Carnegie Mellon University (CMU), Florida Atlantic University (FAU), Florida International University (FIU),
Harvard Graduate School of Design (GSD), University of Innsbruck (Innsbruck), Massachusetts Institute of Technology (MIT), University
of California Los Angeles (UCLA), University of Michigan (Michigan), Southern California Institute of Architecture (SCI-Arc) and Tongji
University (Tongji).
12
In 2020 a review of a AI based studio at the University of Michigan, led by Matias del Campo, Sandra Manninger and Alexa Carlson
attracted over 1000 followers using a combination of Facebook and Zoom. SCI-Arc has also been particularly active in promoting social
media as a forum for AI based work: https://www.facebook.com/sciarc/videos/247490769948702/
13
The Shanghai-based DigitalFUTURES initiative has run numerous workshops on AI. https://www.digitalfutures.world
14
At the 2019 conference for the Association for Advanced Computer Aided Design in Architecture (ACADIA) in Austin, Texas, two full
sessions were dedicated to AI.
15
A number of AI based doctoral research projects have been undertaken within MIT Media Lab. One of the most interesting is Street Score,
a machine learning algorithm that predicts the perceived safety of a street: https://www.media.mit.edu/projects/streetscore/overview/
16
MIT now runs an undergraduate program in Urban Science and Planning with Computer Science that brings together AI and urbanism
http://urban-science.mit.edu/ New York University in Shanghai (NYU Shanghai) runs a masters program in AI and Culture. Some programs,
such as the DDes program at FIU, have a particular focus on the theory of AI, and AI based architectural design.

5

aware of it. Established commercial companies, such as Autodesk, are now beginning to integrate
more advanced AI into their software, while a number of startups, such as Xkool and Spacemaker AI,
are developing new AI based software tools for architects and developers.17 AI is proving capable of
processing complex site information, and offering a greater range of design options, maximising the
potential of any given site. In addition, AI is now being used to control robotic fabrication
technologies, and to improve the performance of buildings once constructed.
And yet we are still in the early stages of the AI revolution. Ben Bratton has described how we are
still in the ‘silent movies’ period of computation, and AI is but a recent development within the longer
history of computation. But there is a lot more to come. AI is certain to become an integral part of our
future, and will undoubtedly prove to be a powerful aid in augmenting human design abilities and
speeding up the design process. The writing is on the wall.
By the end of this decade, we could predict that there will not be a single profession or discipline left
untouched by AI. And architecture will be no exception. Thanks to AI, the very practice of
architectural design will be completely overhauled, and so will architectural education.
Beyond Technophobia
Not everyone will be so positive about the introduction of AI into architecture. Some will dismiss it,
just as some dismissed computers when first introduced into mainstream architectural culture some 30
years ago. Why use computers, they would ask, when human beings can draw so much better? Why
use artificial intelligence, some will no doubt ask, when we have human intelligence? Equally, others
might even be even more critical, dismissing AI as part of a ‘New Dark Age’, or a vital cog in
‘surveillance capitalism’.18
This is perhaps understandable. After all, how often do we see robots and computers portrayed in a
negative light in popular culture? From Metropolis onwards, many movies cast robots as evil artificial
life forms that pose a threat to humankind. Take 2001: A Space Odyssey, where Hal, the sentient
supercomputer controlling a space flight to Jupiter, eventually turns against the astronauts on board.
Or take the Terminator movies, where Skynet, the often invisible, super intelligent AI system, plays
the main antagonist. Or take Blade Runner, where bio-engineered robots infiltrate their way
seamlessly into human society, causing mayhem.
This distrust of robots and computers in the movies can be understood within the broader context of
technophobia in general that can also be traced back to some more of the conservative approaches in
17

Spacemaker AI was acquired by Autodesk in November 2020.
James Bridle, New Dark Age: Technology and the End of the Future, London: Verso, 2018; Shoshana Zuboff, The Age of Surveillance
Capitalism, New York: Hachette, 2018.
18

6

philosophy that still inform architectural theory. One problem with philosophy, as Stephen Hawking
famously observes, is that too often it fails to keep pace with technology.19 But another problem with
philosophy is that it is often antagonistic towards technology.
Martin Heidegger, for example, sees technology as a potential source of alienation.20 He fails to
appreciate, however, the gradual way in which we appropriate new technologies through a form of
proprioception.21 Think of the outrage caused by Le Corbusier’s famous description of the house as ‘a
machine for living in’. But do we not now live in houses bristling with technological devices of every
kind? The same goes for engineering. Take the Eiffel Tower. When first constructed, many Parisians
regarded it as an unspeakably ugly edifice. Indeed, Guy de Maupassant, would frequently take his
lunch at a restaurant in the Eiffel Tower, even though he was not so fond of the food there, on the
basis that it was the only place in Paris from which he could not see the tower.22 And yet the Eiffel
Tower has now become a much-loved symbol of Paris. Heidegger’s anti-technological stance now
seems radically out of place in a world where technology has colonized our horizon of consciousness,
where we not only accept technology, but even start connecting with it from an emotional perspective.
How long is it before we become attached to our laptops, and give our cars names? 23 Is it not time to
forget Heidegger?24
The Prosthetic Imagination
For a more nuanced philosophical understanding of how we adapt to technology, and absorb it so that
it becomes a prosthetic extension to our own bodies, we should perhaps turn to Maurice MerleauPonty, who recognizes that any tool can eventually be appropriated as part of our extended body
schema, so that we come to experience the world through our tools.25 Think of a blind person who has
to navigate the world using a white cane. Eventually the cane becomes ‘invisible’ as it is absorbed



Instead, perhaps, we need to engage with the rapidly developing world of cognitive science, when dealing with AI. Cognitive science is an
umbrella term embracing a series of related disciplines, including AI, neuroscience and philosophy.

Heidegger was once popular among architects, and it was his thinking that helped to fuel the denigration of computation in the early days
of Computer Aided Design (CAD). At the University of Cambridge in the 1990s, where theoretical debates were dominated by reference to
Heidegger and other similar thinkers, computers were banned from the architectural studio. Heidegger is still celebrated by the Object
Oriented Ontology [OOO] movement, such as Graham Harman. In his famous analysis of tools, for example, Heidegger argues that either
we are familiar with a tool, and know how to use it, or unfamiliar, and have no sense of how to use it. Harman’s continued celebration of
Heidegger’s understanding of tools now seems somewhat dated. Graham Harman, Tool-Being: Heidegger and the Metaphysics of Objects,
Chicago: Open Court, 2002. See Jonathan Hale, “Harman on Heidegger: ‘Buildings as Tool-Beings,” Body of Theory, 29 May 2013.
https://bodyoftheory.com/2013/05/29/. For a critique of Harman and Heidegger, see Neil Leach, ‘Digital Tool Thinking: Object Oriented
Ontology versus New Materialism’, in Kathy Velikov, Sean Ahlquist, Matias del Campo, Geoffrey Thün (eds.), ACADIA 2016: Posthuman
Frontiers: Data, Designers and Cognitive Machines, Proceedings of the 36th Annual Conference of the Association for Computer Aided
Design in Architecture, I


into the extended sense of the embodied self.26 The same happens with cars. With time we become so
familiar with the operations of driving – accelerating, braking, steering and so on – that they fade into
the background to become part of our subconscious such that we come to drive through our cars. And
something similar happens with the spaces we inhabit. The initial sense of displacement or alienation
that we might feel when first moving into a new apartment or house gradually fades away, and over
time we become attached to it, and start to feel at home there.27
Andy Clark and David Chalmers take this idea even further, and argue that a tool can even become
part of our ‘extended mind’.28 Take the mobile phone. Instead of memorizing phone numbers, we now
keep those numbers on our mobile phone. Our social contacts are stored there. Our whole lives are
contained there. Our ‘cellphones’ have become our ‘self-phones’. We have absorbed our mobile
phones and other external devices at a symbolic level, so that they have become part of who we are.
They have become prosthetic extensions of our minds.

Katherine Hayles then goes one step further still. Why limit ourselves to the human mind, when the
whole body has been augmented by the increasing introduction of these new technologies? For
Hayles, we cannot separate the mind from the body, as though the mind is simply housed in the
body.29 The mind is precisely part of the body. Moreover, as Hayles points out, the body has indeed
been extended by these new technologies, such that the traditional concept of ‘humanism’ – the notion
that the human body can be perceived as a discrete unit in and of itself – has now become untenable.
For Hayles, then, we need to go so far as to challenge the traditional liberal concept of humanism, and
accept that we now operate within a ‘posthuman condition’.30

Cyborg Culture
The term, cyborg, was first coined to refer to the potential of enhancing the human body in order for it
to survive in extraterrestrial environments.31 More recently, however, it has been deployed by Donna
Haraway to refer to a cybernetic organism, ‘a hybrid of machine and organism, a creature of social
reality as well as a creature of fiction.’32 Moreover, this hybrid condition, should be understood not as
static, but as one that is continually adapting and mutating: ‘Already in the few decades that they have
existed, they have mutated, in fact and fiction, into second-order entities like genomic and electronic


databases and the other denizens of the zone called cyberspaces’.33 As such, we have now evolved, so
that the cyborg has become our predominant disposition: ‘By the late twentieth century, our time, a
mythic time, we are all chimeras, theorized and fabricated hybrids of machine and organism; in short,
we are cyborgs.’34

Although this notion of the cyborg might conjure up images of technologically enhanced human
bodies, such as Terminator or Eve 8, a cyborg does not actually depend on advanced technology.
Forget the romanticized notion of the cyborg – half human, half robot – that we see in the movies. A
cyborg is simply a creature that uses any form of prosthesis. An ordinary walking stick is a
prosthesis.35 As Clark comments:

The cyborg is a potent cultural icon of the late twentieth century. It conjures images of humanmachine hybrids and the physical merging of flesh and electronic circuitry. My goal is to hijack
that image and to reshape it, revealing it as a disguised vision of (oddly) our own biological
nature. For what is special about human brains, and what best explains the distinctive
features of human intelligence, is precisely their ability to enter into deep and complex
relationships with nonbiological constructs, props, and aids.
The usefulness of these ‘constructs, props and aids’, however, is determined by their affordances –
their potential uses – which remain constrained by our own capabilities. A tool, after all, is no use, if
we cannot use it. Likewise a tool might ‘lend itself’ to certain operations, but not to others.36 A tool,
however, has no agency.37 It cannot force us to use it in a certain way. Nonetheless, with an
The theory of affordances was introduced initially by James Gibson in an article, James Gibson, ‘The Theory of Affordances’, in Robert
Shaw and John Bransford (eds.), Perceiving, Acting, and Knowing, London: Wiley, 1977. Gibson later elaborated on this theory in his book,
James Gibson, The Ecological Approach to Visual Perception, Hove: Psychology Press, 1979. It was also developed by Gibson’s wife,
Eleanor Gibson together with Anne Pick: Eleanor Gibson, Eleanor, Anne Pick, An Ecological Approach to Perceptual Learning and
Development. New York: Oxford University Press, 2000. As I have noted elsewhere: ‘The theory of affordances suggests that there is a
particular action or set of actions that is afforded by a tool or object. Thus a knob might afford pulling – or possibly pushing – while a cord
might afford pulling. This is not to say that the tool or object has agency as such. In other words the tool or object does not have the capacity
to actually ‘invite’ or ‘prevent’ certain actions. Rather it simply ‘affords’ certain operations that it is incumbent on the user to recognize,
dependent in part on a set of pre-existing associations that have been made with that tool or object. Likewise that action or set of actions is
also dependent upon the capacity of an individual to undertake those actions. Thus certain actions might not be afforded to small children or
those without the strength or agility to perform those actions. Moreover, certain tools afford certain operations, but do not preclude other
operations. For example, we might perhaps affix a nail with a screwdriver – albeit less efficiently – if we do not have a hammer at hand. We
might also recognize that it is easier to cut wood with a saw than with a hammer, and that the technique of cutting with a saw affords a
limited range of possible operations. Importantly also the theory of affordances has been applied to human computer interfaces to refer to
the easy discoverability of certain actions. As such, we might be able to identify various operations afforded by digital tools that might
thereby become popular.’ Neil Leach, ‘There is No Such Thing as Parametric Architecture; There is No Such Thing as Political Architecture’
in Matthew Poole, Manuel Shvartzberg (eds.), The Politics of Parametricism, London: Bloomsbury, 2015, pp. 58-78.
37
Here I would challenge in the strongest possible terms the notion that Bruno Latour has advanced in his Actor Network Theory (ANT)
that tools ‘act’ in social networks. (Latour, Bruno [Jim Johnson]. 1988. “Mixing Humans with Non-Humans: Sociology of a Door-Closer.”


appropriate tool, the capacity of human beings can be enhanced considerably.

As such, as Elon Musk has commented, ‘All of us already are cyborgs.’38 It is, moreover, our
increasing reliance on sophisticated digital prostheses that is making us ever more cyborg-like. 39
These digital prostheses are enhancing our abilities, such that they have begun to make us
‘superhuman’. Musk again: ‘You have a machine extension of yourself in the form of your phone, and
your computer and all your applications. You are already superhuman.’40

It is precisely our capacity to adapt so effectively to new tools that, for Clark, makes human beings
‘natural born cyborgs’.41 We are naturally adaptive creatures, because our brains are themselves so
adaptive. Neuroscientists tell us that the human brain is ‘plastic.’42 The brain has the capacity to adapt
constantly to ever changing circumstances, and it is its very 'plasticity' that gives human beings the
capacity to appropriate new technologies so that they become part of our extended sense of self: : ‘It
is the presence of this unusual plasticity that makes humans (but not dogs, cats, or elephants) naturalborn cyborgs: beings primed by Mother Nature to annex wave upon wave of external elements and
structures as part and parcel of their own extended minds.’43
Moreover, for Clark, this is why cyborg culture does not make us posthuman, but rather affirms us as
being quintessentially human, in that the innate capacity to adapt, that plays such a significant role in
what it is to be human. This, then, allows Clark to challenge Hayles’s claim that we have become
posthuman: ‘Such extensions should not be thought of as rendering us in any way post-human; not
because they are not deeply transformative but because we humans are naturally designed to be the
subjects of just such repeated transformations!’44
Extended Intelligence
It is in the context of this burgeoning ‘cyborg culture’ – where humans have been augmented to
become superhuman – that we can explore the full potential of AI as being not an end in itself, but a
prosthetic device that can enhance the natural intelligence of the human being. For if the mind – or

indeed the embodied self – can be extended through the phone and other devices, could we not also
argue that intelligence itself can be enhanced through artificial intelligence?
Increasingly nowadays we are hearing references not to straightforward ‘artificial intelligence’ but to
‘extended intelligence’ [EI]. Ultimately, the most productive strategy is to see the relationship
between AI and human intelligence not as one of competition, but rather as a potential synergy
between the two, whereby AI operates in tandem with human intelligence, and becomes an extension
to human intelligence. As Joi Ito puts it:
“Instead of thinking about machine intelligence in terms of humans vs. machines, we should
consider the system that integrates humans and machines—not artificial intelligence, but
extended intelligence. Instead of trying to control or design or even understand systems, it is
more important to design systems that participate as responsible, aware and robust elements of
even more complex systems. And we must question and adapt our own purpose and
sensibilities as designers and components of the system for a much more humble approach:
Humility over Control. We could call it “participant design”—design of systems as and by
participants—that is more akin to the increase of a flourishing function, where flourishing is a
measure of vigor and health rather than scale or power. We can measure the ability for systems
to adapt creatively, as well as their resilience and their ability to use resources in an interesting
way.”45
An alternative way of understanding this coupling of human and AI is as a form of ‘intelligence
augmentation (IA).’ As Anant Jhingran comments, ‘“AI makes machines autonomous and detached
from humans; IA, in on the other hand, puts humans in control and leverages computing power to
amplify our capabilities”.’ 46 Whether we call it ‘extended intelligence’ or ‘intelligence augmentation’,
the basic concept of coupling human intelligence with AI remains the same. As such, we should not
be referring to AI in isolation, so much as a potential extension or augmentation of human
intelligence.47 This extended or augmented intelligence – this synergy between our bodies and
machines – will undoubtedly prove enormously productive. 48 As Yann Lecunn observes, ‘Our
intelligence is what makes us smarter, and AI is an extension of that quality.’49
An Introduction to AI
This is an introductory book outlining what AI can contribute to the discipline of architecture. As
such, it does not go into any great detail. Rather it offers an overview of what is a fascinating and
increasingly relevant topic. It tries to describe in a few broad brush-strokes how AI operates, how it
has developed and what potential it holds for the future of architecture. It should be noted, however,
that this book is no technical manual. It does not offer any technical instructions as to how to use AI.50
Nor does it attempt to provide a comprehensive account of AI. Indeed, although it does touch on
questions of performance, it is preoccupied largely with a relatively narrow range of popular AI
techniques being used by some architects to generate some extraordinary design work at the moment.
It therefore privileges the aesthetic potential of AI to produce visually stimulating images over
performance-based considerations. This is where AI is arguably having its most significant impact at
the moment. In the future, however, the success of AI is likely to be judged in a very different way by
its capacity to calculate the most efficient solution to a design challenge from the perspective of
performance.
Chapter 1, ‘What is AI?’, is the most technical chapter. It introduces the basic principles of AI. It
makes a series important distinctions between the different forms of AI, and offers definitions of a
number of key terms. It addresses the development of deep learning and the use of neural networks,
and focuses in particular on a series of techniques used for generating images using DeepDream and
various kinds of Generative Adversarial Networks (GANs). The chapter then goes on to look at some
of the AI techniques that have been developed for architecture, and the burgeoning field of
‘architectural intelligence’.
Chapter 2, ‘A History of AI’, is more historical in its orientation. It offers a background history of AI,
focusing in particular on the visibility and invisibility of AI. It introduces some of the important
figures in the history of AI, such as Alan Turing, whose once secret and little known contributions to
computation have now been recognised and celebrated in popular culture. It highlights both the low
points in its history – the so-called AI ‘winters’ – but also the high profile media events – Chess,
Jeopardy! and Go challenges – that have brought AI to worldwide attention. The chapter ends,


however, with a warning about the risks of AI being exploited as a marketing tool, precisely because
of its invisibility.
Chapter 3, ‘AI, Art and Creativity’, examines the capacity for AI to be ‘creative’. It looks at the
impact of generative AI techniques on the field of art especially, at a moment when AI artworks have
not only been displayed at art exhibitions and sold at auctions, but have also won international art
prizes. But this chapter also asks some searching questions. Is AI generated art really art? Who owns
the copyright of AI generated art? And is it not time to rethink our understanding of creativity in the
light of AI? The chapter concludes with the observation that perhaps AI might be able to offer a
mirror in which to understand human intelligence and creativity.
Chapter 4, ‘AI, Media Art and Neuroscience’, asks whether machines are able to ‘dream’ or
‘hallucinate’. It highlights the importance of the moment when Refik Anadol projected his machine
hallucinations on to Frank Gehry’s Walt Disney Concert Hall in LA, and compares these machine
hallucinations with the theory of ‘controlled hallucinations’ developed recently in the field of
neuroscience. The chapter goes on to consider what insights AI and neuroscience can offer us into the
way that architects think and see the world. The chapter concludes with the observation that the
primary role of AI is perhaps to act as an inspirational muse for architects.
Chapter 5, ‘AI and Architectural Design,’ looks at the recent explosion of interest in AI within
architectural design circles. It reflects upon the significance of the first ever exhibition of AI and
architecture, and considers how AI is beginning to bring fresh approaches to architectural design. In
particular, the chapter focuses on the different approaches that progressive architects, such as Wolf
Prix (Coop Himmelb(l)au), Thom Mayne (Morphosis) and Patrik Schumacher (ZHA), are taking
towards AI in their design practices. The chapter also considers what potential role AI might play in
the fabrication of buildings.
Chapter 6, ‘AI and the Office of the Future,’ considers how the architectural office of the future will
engage with AI. Here the focus is less on experimentation, and more on practical applications, and
less on aesthetics and more on questions of performance. The chapter engages with two of the leading
developers of AI-based architectural software, Xkool and Spacemaker AI, and compares their
different approaches. It argues that in terms of the introduction of AI into the architectural office, the
crucial turning point will come when clients start to insist that their architects use AI. The chapter
concludes by noting that in the age of AI design itself will be reconfigured as a process of searching
for potential outcomes, rather than as the top down form making process that it has been in the past.
Chapter 7, ‘AI and the City of the Future,’ speculates on the potential impact of AI on the future of
13

our cities. It argues that the key driver of change is less likely to be the quest for novel architectural
forms, than the introduction of AI based informational technologies. AI will begin to inform not only
how cities are designed, but also how they operate. Cities will become informational cities, and AI
will operate as a form of ‘brain’ to allow them to operate more efficiently. The city of the future will
become an intelligent, efficient city – a ‘Brain City’ – an AI-enhanced version of the city of today.
The final chapter, ‘The Future of AI,’ speculates about the future of AI, and offers an overview of
predictions made about the potential of AI. Will AI ever be able to match or even surpass human
intelligence? Might it be able to achieve consciousness, and think like us? And if so, what might be
the consequences? The book concludes with a list of predictions about the impact of AI on the
profession of architecture. It argues that over time AI will become an increasingly pervasive,
indispensable tool in the architectural office, until eventually it will be capable of designing buildings
on its own, and the full potential of AI will have been realised.
Intended Audience
This book is aimed primarily, but not exclusively, at a younger generation – especially students of
architecture. After all, this is the generation can relate most to AI, because AI is already so much part
of their world. This is the FaceBook generation whose social lives depend upon AI, a generation that
uses TikTok, Spotify and Wayz, and a generation that has absorbed AI into almost every aspect of
their existence. Moreover, this is a generation for whom the real contributions of AI will kick in as
they approach the peak of their careers. However, this book is also aimed at architects already in
practice, offering them some insights into the kinds of tools that are now being developed, and into
the changes that are likely to occur in architectural practice in the future. Finally, it is also aimed at
the general public, and anyone else interested in the creative potential of AI.
This is a timely book. AI is a hot topic. And new ideas, new design techniques, are being developed
every day. Soon this book will need to be revised – updated – just as our technical devices are
themselves constantly being updated. But at least it is a start. And perhaps its greatest contribution
will be to help to initiate a debate about the potential impact of AI on the world of architecture. And,
for sure, it will produce a counter-reaction. Many will be deeply sceptical of AI.
This series, however, anticipates this counter-reaction. This first volume is largely positive about AI,
and argues that AI will eventually be able to design buildings. The second volume, however, looks at
the dark side of AI. Among other concerns, it argues that inevitably AI will lead to the death of
architecture, a profession that is already struggling.

14

Future generations, no doubt, will look back at this publication, and see it as offering a time capsule
of important ideas from a precise moment in time at the beginning of the third decade of the twenty
first century, when architectural culture began to embrace the possibilities afforded by AI.

15

Chapter 1
What is AI?
A common definition of AI is that it seeks to mimic or simulate the intelligence of the human mind.
As Margaret Boden puts it, ‘AI seeks to make computers do the sorts of things that minds can do.’51
Meanwhile John Kelleher describes AI as ‘that field of research that is focused on developing
computational systems that can perform tasks and activities normally considered to require human
intelligence.’52 The implication here is that AI might soon be able to take over these tasks and
activities.53
In the longer term, however, AI is likely to exceed the intelligence of the human mind.54 Human
intelligence does not constitute the absolute pinnacle of intelligence. It merely constitutes ‘humanlevel intelligence’. After all, there are already specific domains, such as the games of Chess and Go,
where AI outperforms human intelligence. In the future, there are likely to be forms of intelligence
that far exceed the intelligence of the human mind. Alternatively, then, we could define research into
AI as an attempt to understand intelligence itself.
Typically the tasks performed by AI involve learning and problem solving. But not all these tasks
require intelligence.55 Some, for example, merely involve vision or speech recognition. Importantly,
however, as Boden notes, they all relate to our cognitive abilities: ‘All involve psychological skills –
such as perception, association, prediction, planning, motor control – that enable humans and animals
to attain their goals.’56 Thus, although some of the operations included in research into AI are not
intelligent in themselves, they must nonetheless be included in any purview of AI, as they are crucial
‘characteristics or behaviours’ in the field of AI.57

51

Margaret Boden, AI: Its Nature and Future, Oxford: Oxford University Press, 2016, p.1. Arguably this statement is incorrect. Surely the
overall intention is to make machines do far more than minds can do. Intelligence itself is not constrained by the limits of human
intelligence.
52
John Kelleher, Deep Learning, Camb., MA: MIT Press, 2019, p. 251
53
Meanwhile Stuart Russell stresses that an important prerequisite of AI is that it should succeed in the tasks that it is given: ‘An entity is
intelligent to the extent that it does the right thing, meaning that its actions are expected to achieve its objectives.’ Russsell goes on to say
that this definition applies to both humans and machines. Stuart Russell, in Martin Ford (ed.), Architects of Intelligence: The Truth about AI
from the People Building it, Birmingham, UK: Packt, 2018, p. 40.

As such, we should accept that what we human beings have come to understand as ‘intelligence’ is merely a human version of intelligence,
alongside biological intelligence and other forms of intelligence. We could therefore view intelligence in the same light as ‘reality’. In other
words, we simply have different forms of ‘intelligence’, just as we have different forms of ‘reality’ – virtual reality (VR), augmented reality
(AR) and hyperreality.

Fat the moment are pure fiction, such as characters from the world of the cinema,
like Agent Smith in The Matrix or Ava in Ex Machina.60 Nonetheless some philosophers, such as
David Chalmers, think that development of GPT-3 by Open AI has brought the possibility of AGI
much closer.61
Classic examples of ‘narrow AI’ would be Siri, Alexa, Cortona, or any other form of AI assistant.
However sophisticated these assistants might appear, they are operating within a limited range of
predetermined functions. They cannot think for themselves any more than a pocket calculator can
think, and are incapable of undertaking any activity that requires consciousness.62
The Different Forms of AI
The term AI is often used as though it is a singular, homogeneous category. Indeed, this is how the
general public understands the term. However, there are in fact many different forms of AI, and even
these can be further divided into a series of sub-categories. In order to understand AI, then, we need to
differentiate the various forms of AI.
Within ‘narrow AI’ we should make a further distinction between the broader category of AI itself,
‘machine learning’ and ‘deep learning’. These three can be seen to be nested within each other –
somewhat like a series of Russian dolls, or layers in an onion – in that ‘deep learning’ is part of
‘machine learning’ that is itself part of AI. Early versions of AI referred to machines that had to be
programmed to process a set of data. This is also known as ‘Classical AI,’ or even, somewhat


On consciousness, see David Chalmers, The Conscious Mind, Oxford: OUP, 1996; Michael Graziano, Rethinking Consciousness: A
Scientific Theory of Subjective Experience, New York: W W Norton, 2019; Anil Seth, Being You: A Science of Consciousness, London:
Faber & Faber, disparagingly, ‘Good Old Fashioned AI (GOFAI)’. The important point here is that with early AI the
machine could only do what it is programmed to do. The machine itself could not learn.
By contrast, machine learning goes one step further, and is able to train itself using vast quantities of
data. Importantly machine learning challenges the popular myth that computers cannot do anything
that they have not been programmed to do. As the term implies, machine learning is able to learn, and
even program itself, although we should be careful not to conflate the way that machines ‘learn’ with
human learning. Like other terms used for both AI and human intelligence, ‘learning’ does not
necessarily have the same meaning in both contexts.
Russell comments, “Learning is a key ability for modern artificial intelligence. Machine learning has
always been a subfield of AI, and it simply means improving your ability to do the right thing, as a
result of experience.’63 Furthermore, learning is essential if AI is ever going to match human
intelligence. As Pedro Domingos observes: ‘The goal of AI is to teach computers to do what humans
currently do better, and learning is arguably the most important of those things: without it, no
computer can keep up with a human for long; with it, the rest follows.’64
Deep learning is a relatively recent development within machine learning and has led to many of
significant advances in the field of AI. It is deep learning that is, for now at least, the most promising
form of AI. In fact deep learning has become the dominant paradigm to the point that – somewhat
misleadingly – it has become almost synonymous with AI, at least within the popular media.65 Indeed,
whenever AI is mentioned in this book, it is invariably deep learning that is being referred to, and
certainly not GOFAI. Importantly, however, deep learning depends on a vast amount of data, so much
so that data, as is often said, has now become ‘the new oil’.
Kelleher defines deep learning as ‘the subfield of machine learning that designs and evaluates training
algorithms and architectures for modern neural network models.’66 Here we come to an important
point regarding the term ‘architecture’. Confusingly, ‘architecture’ is also used within computer
science to refer to the internal organization of a computer.67 This has nothing to do, however, with the
term ‘architecture’ used in the context of buildings. Readers should therefore be careful not to confuse
the ‘architecture’ of computer science with the ‘architecture’ of the construction industry.


Although we might trace its origins back to the neural networks developed by Pitts and McCulloch
back in 1943, deep learning has since developed at an astonishingly rate. Several factors have
contributed to this:
1. Major advances in algorithms have fueled the deep learning breakthrough.
2. Cloud services have made access to significant computational power possible.
3. There has been a significant influx of capital investment from both public and private
sectors.68
4. There are now significantly more students in the fields of computer science and data science.
5. There has been an exponential increase in the amount of data generated.69
In short, the differences between early neural networks and more recent neural networks used in deep
learning should not be underestimated. There is an enormous gulf between these two in terms of their
performance and capabilities. Think of the difference between early cars – once known as ‘horseless
carriages’ – and the sophisticated, potentially self-driving cars of today.
Training Techniques
Further, we need to distinguish the three primary training techniques used in machine learning:
supervised, unsupervised and reinforcement learning.
With supervised learning, the system is literally trained to perform certain tasks according to a desired
outcome by being fed a vast quantity of clearly identified examples. Thus, for example, many images
– over 1 million in some cases – need to be fed in, and labeled, or ‘classified’ as the process is
sometimes called. In the case of images of cats, these would need to be labeled ‘cat’. Likewise, a vast
number of images that are not of cats would also need to be labeled ‘no cat’.
This is not so dissimilar to how human beings learn. Obvious comparisons can be made with the
process by which a parent teaches a young child to identify various objects, such as animals, ‘This is a
cow’; ‘this is a horse’, and so on. Similarly comparisons could be made with architectural education,
where students are taught to identify various features and attributes of architectural design.
Supervised learning is the most popular form of machine learning, and is used, for example, in
language translation. Boden offers a helpful definition: “In supervised learning, the programmer
68

According to Stanford’s AI index report of 2017, ‘there has been a 14 fold increase in the number of active AI startups since 2000.’ Louis
Columbus, 10 Charts That Will Change Your Perspective On Artificial Intelligence's Growth, Forbes, 12 Jan 2018,
https://www.forbes.com/sites/louiscolumbus/2018/01/12/10-charts-that-will-change-your-perspective-on-artificial-intelligencesgrowth/#79ea4c284758
69
It has been claimed that data doubles every 18 months. ‘Humanity Doubles its Data Collection Every 18 Months, and It Has Powerful
Implications,’ Flux, https://www.fluxmagazine.com/data-creation-powerful-implications/

19

“trains” the system by defining a set of desired outcomes for a range of inputs (labeled examples and
non-examples), and providing continual feedback about whether it has achieved them.”70
With unsupervised learning, there are no desired outcomes. Rather the system finds patterns or
clusters that exist in unstructured data, thereby effectively discovering knowledge. Kelleher defines
unsupervised learning as ‘a form of machine learning where the task is to identify irregularities, such
as clusters of similar instances, in the data. Unlike supervised learning, there is no target attribute in
an unsupervised learning task.’71 This is one of the most challenging, but equally promising areas of
machine learning. Indeed, if machines could truly learn by themselves without human intervention,
this would be a major step towards the possibility of artificial general intelligence [AGI] – AI, that is,
that possesses consciousness and can genuinely think.
Again, this is not dissimilar to how children learn a language, simply by listening to others speaking.72
Indeed, the human mind is good at learning through an unsupervised interaction with the environment.
We could also compare it to the way in which architects and architectural students absorb a certain
design sensibility, simply by being immersed within an architectural environment.73 After all,
architectural design is seldom taught according to any overarching theory or set of principles. It is as
though architects and architectural students are expected to acquire an understanding of what
constitutes good design, almost by osmosis.
Finally, with reinforcement learning, the system does not need to be given clearly labeled examples in
order to learn, but depends entirely on feedback messages informing it whether it is correct or not. Its
knowledge evolves based on the logic of punishment or reward. This is particularly effective in game
playing and robotic control, where a game process may be repeated in simulation several million
times at an remarkably rapid rate.74
Reinforcement learning is not so dissimilar to training a dog, by giving it rewards when it obeys
commands. Indeed, a version of reinforcement learning is also at work in human learning, not least in
the training and development of an architect, in that both academia and practice are based on a
rewards system involving scholarships, awards and prizes.

70

Boden, p. 47
Kelleher, p. 255.
Supervised learning and reinforcement learning, however, also play a role in learning a language.
73
This might be compared to the role of mimesis: ‘We may see [mimesis] at work also when a child learns to speak and adapt to the world.
In fact, it is precisely the example of the child “growing into” language that best illustrates the operation of mimesis. The child “absorbs” an
external language by a process of imitation, then uses it creatively for its own purposes. Similarly, within the realm of architecture we might
see mimesis at work as architects develop their design abilities: it is this process which also allows external forms to be absorbed and
sedimented, and then rearticulated as an individual expression.’ Neil Leach, Camouflage, Camb., MA: MIT Press, pp. 21-22.
74
Merrit Kennedy, ‘Computer Learns To Play Go At Superhuman Levels 'Without Human Knowledge', NPR, 18 October 2017,
https://www.npr.org/sections/thetwo-way/2017/10/18/558519095/computer-learns-to-play-go-at-superhuman-levels-without-humanknowledge
71
72

20

AI Tribes
Approaches to machine learning can be divided into five main schools of thought: symbolists,
connectionists, evolutionaries, Bayesians and analogizers. Pedro Domingo refers to these different
approaches as ‘tribes’, a term that is perhaps not so inappropriate, given the often mutually exclusive,
competitive nature of research in this field.75
Evolutionaries put their trust in genetic programming that improves over successive generations much
like natural selection itself. 76 Bayesians believe in the principle of probabilistic inference to overcome
the problem of noise and incomplete information.77 Analogizers subscribe to the logic of analogy, and
use that logic to recognise and learn from similarities.78 However, the most significant ‘tribes’ in
terms of the history of AI in general are the symbolists and the connectionists.
Symbolists believe in solving problems through inverse deduction, by using existing knowledge and
identifying what further knowledge might be needed to make a deduction: “For symbolists, all
intelligence can be reduced to manipulating symbols, in the same way that a mathematician solves
equations by replacing expressions by other expressions.”79
Connectionists, meanwhile, attempt to reverse engineer what the brain does through a process of
backpropagation, so as to align a system’s output with the desired response.80 As Domingos observes,
“For connectionists, learning is what the brain does, and so what we need to do is to reverse engineer
it. The brain learns by adjusting the strengths of connections between neurons, and the crucial
problem is figuring out which connections are to blame for which errors and changing them
accordingly.”81 Not surprisingly, then, it is connectionism that would seem offer us the best insights
into how the human brain works.
For someone from outside the field, it might seem curious that there could be such a multiplicity of
different approaches. And yet there has always been one dominant approach. For many years it was
symbolism, but with the development of more sophisticated forms of neural networks and the
emergence of deep learning, connectionism has now asserted itself as the dominant paradigm.
Neural Networks
Neural networks are composed of information processing units that are called ‘neurons’, and
connections that control the flow of information between these units that are called ‘synapses’.83
Ethem Alpaydin defines the neural network as, “A model composed of a network of simple units
called neurons and connections between neurons called synapses. Each synapse has a direction and a
weight, and the weight defines the effect of the neuron before on the neuron after.”84
The neural networks used in connectionist AI should be distinguished from the virtual machines used
in symbolic AI. They operate in parallel, are self-organising, and can work without expert knowledge
of task or domain. As Boden puts it, ‘Sequential instructions are replaced by massive parallelism, topdown control by bottom-up processing, and logic by probability.’85 They need to be trained by being
fed a series of input-output pairs as training examples. The system then ‘learns’ over a period of time,
and tries to find the optimal weighting for each connection, so that when fed an input the output
matches – as far as possible – the training examples. Nonetheless, they are robust, good at discerning
patterns – even when incomplete – and can deal with ‘messy’ evidence. 86 Think of how you can
continue a tune, based only on the first few notes.
The simplest way for a neural network to process an image is to operate in one direction, known as
‘feed forward.’ A network consists of an ‘input layer’, an ‘output layer’, and – in between – multiple
internal layers known as ‘hidden layers’. Each layer consists of simulated neurons. These neurons
each ‘compute’ their input based on the ‘weight’ of the input’s connection, applying a threshold value
to determine its ‘activation value’. In so doing, each neuron extracts and filters out certain ‘features’,
before passing on its activation value to neurons in the next layer. 87 Each subsequent layer computes
progressively higher level features, until a classification output is generated based on its probability of
being correct.88
Neural networks are named after the neurons in the human brain. However, although certain
comparisons can be drawn between neural networks and the brain, a clear distinction should be made
between the ‘neurons’ in neural networks and the neurons in the brain. Certainly neural networks are
nowhere nearly as sophisticated as the human brain. Multiple as the layers of neural networks are in
deep learning, they are not as numerous as the countless networks in the human brain.89 Neural
networks are therefore not so much modeled on the human brain, as inspired by it. As Yoshua Bengio
comments, “While machine learning is trying to put knowledge into computers by allowing
computers to learn from examples, deep learning is doing it in a way that is inspired by the brain.”90
Melanie Mitchell prefers to use the term ‘unit’ to ‘neuron’, since a simulated neuron bears so little
resemblance to an actual neuron in the brain. Mitchell sums up the process as follows: ‘To process an
image. . . the network performs its computation layer by layer, from left to right. Each hidden unit
computes its activation value; these activation values then become the inputs for the output units,
which then compute their own activations. . . The activation of an output unit can be thought of as the
network’s confidence that it is “seeing” the corresponding digit; the digit category with the highest
confidence can be taken as the network’s answer – its classification.’91
Backpropagation
Deep learning depends on ‘backpropagation’ – sometimes called ‘backprop’. This allows a neural
network to effectively operate in reverse in order to correct earlier prediction errors. Backpropagation
refers to a process whereby information about the prediction error propagates backwards through the
various layers of the neural network, allowing the original ‘weights’ to be recalibrated and updated, so
that the system can ‘converge’ or edge closer to the correct answer, in a manner not so dissimilar to
reverse engineering. With deep learning this process is improved by increasing the number of hidden
layers. Indeed, there can be anything from 4 layers to over 1000 layers – hence the term ‘deep’ in
deep learning.92
Each individual cycle through the full training dataset, whereby the weights are recalibrated, is
referred to as an ‘epoch’ of training. Typically many epochs are required, sometimes up to several
thousand, and in principle the more epochs, the better the results, although there is no absolute
guarantee that the results will continue to improve.
Convolutional Neural Networks
There are several different types of neural networks. With deep learning, convolutional neural
networks (ConvNets) have become increasingly popular, especially for classifying images.93 The term,
89

Another important distinction is that the networks in the human brain are dynamic, which means that there is a temporal component to
how information is encoded and processed, whereas with deep learning neural networks, and specifically convolutional neural networks,
there is no temporal component.
90
Yoshua Bengio interviewed by Martin Ford, in Martin Ford, The Architects of Intelligence: The Truth About AI from the People Building
it, Birmingham, UK: Packt, 2018, p. 23.
91
Mitchell, p. 37. The term ‘digit’ here refers to ‘visual feature’ or ‘data feature’.
92
Russell in Ford, 2018, p. 42.
93
The significant breakthrough in the domain of image classification came when Fei-Fei Li, a young researcher at Princeton, realised that it
would be possible to use the principles adopted in the lexical database, WordNet, to create ImageNet, an image based processing system.
Whereas WordNet was based on nouns, and ImageNet exploited the system, by linking nouns to images that contained examples of those



convolution, refers to the calculation performed by each layer based on the preceding layer.94 This
process vastly improves the process of classifying images, so much so that ConvNets have become all
but universal.
ConvNets are modeled on the visual cortex of the human brain. Neuroscientists David Hubel and
Torsten Weisel observe that the brain has various layers of neurons in the visual cortex that act as
‘detectors’ operating in a hierarchy looking for increasingly complex features. These layers operate in
both a feed-forward and a feed-backwards way, suggesting that our perception is influenced strongly
by prior knowledge and expectations.95
ConvNets behave in a similar way to standard neural networks, but have activation maps – based on
the detectors in the brain – operating layer by layer, detecting features such as edges, depending on
their orientation.96 By the time the final layer is reached the ConvNet has detected some relatively
complex features, based on the dataset on which it has been trained. At this point, a classification
module, consisting of a traditional neural network, is deployed to evaluate the network’s confidence –
in percentage terms – that it has recognized the image.
Mitchell offers a helpful summary of this highly complex process:
‘Inspired by Hubel and Weisel’s findings on the brain’s visual cortex, ConvNet takes an input
image and transforms it – via convolutions – into a set of activation maps with increasingly
complex features. The features at the highest convolutional layer are fed into a traditional
neural network, which outputs confidence percentages for the network’s known object
categories. The object with the highest confidence is returned as the network’s classification of
the image.’
Image classification – or ‘discriminative modeling’ – has become an important application of AI,
especially in the domains of self-driving cars and facial recognition systems. From an architectural
perspective, however, an even more significant consequence of image classification is the possibility
that it affords for the generation of images – or ‘image synthesis’ – a challenge long considered the
holy grail by AI researchers.
nouns. The system depended, however, on vast resources of human labour to label images, deploying Amazon’s Mechanical Turk, often
referred to as ‘artificial artificial intelligence’. Melanie Mitchell, Artificial Intelligence: A Guide for Thinking Humans, New York: Farrar,
Straus and Giroux, 2019, pp. 82-90.
94
A convolution could be described conceptually as a 2D filter that loops over windows of pixels, looking for specific visual features. Each
neuron in a convolutional layer will learn to extract (or activate to) a different 2D visual feature, such as an edge or a curve.
95
Seth, Anil K. “A predictive processing theory of sensorimotor contingencies: Explaining the puzzle of perceptual presence and its absence
in synesthesia.” Cognitive neuroscience vol. 5,2 (2014): 97-118. doi:10.1080/17588928.2013.877880; Andy Clark, Surfing Uncertainty:
Prediction, Action and the Embodied Mind, Oxford: Oxford UP, 2016
96


DeepDream
Image synthesis is a category within deep learning.97 One of the earliest methods of image synthesis is
DeepDream, a computer vision program developed by Alex Mordvintsev of Google Artists and
Machine Intelligence [AMI] released in 2015.98 Typically ConvNets are used for recognising images.
With DeepDream, however, it is possible to generate images by reversing the flow of information,
sometimes referred to as ‘inverting the network.’ Instead of recognizing an image and categorizing it,
DeepDream can be used to start with a category and proceeds to generate an image.99 For example,
whereas a standard neural network can recognize an image of a cat, and categorize it as a ‘cat’,
DeepDream is able to start with the category ‘cat’, and generate an image that resembles a cat.100
Instead of operating ‘from image to media’, then, DeepDream operates ‘from media to image’.101
Importantly, although computational neural networks are trained to discriminate between images, they
need to have some understanding of those images. And this is what allows them to also generate
images, when operating in reverse.102 However, DeepDream often produces a somewhat ‘trippy’
picture that appears vaguely surrealistic with a multiplicity of objects generated in a variety of
poses.103 It is also possible to produce an image by starting with an arbitrary image instead of ‘noise’
or a specific embedding, and allowing the network to analyze and optimize it.104
97

Foster describes generative modeling as follows: “A generative model describes how a dataset is generated, in terms of a probabilistic
model. By sampling from this model, we are able to generate new data.” Foster, p. 1.
98
DeepDream was developed initially as a technique to visualize features that a neuron or layer would activate to or learn to extract from its
input. The program was based on earlier research undertaken by others as part of the ImageNet Large-Scale Visual Recognition Challenge
(ILSVRC) in 2014, Christian Szegedy, Wei Lu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent
Vanhoucke, Andrew Rabinovich, “Going Deeper with Convolutions”, Computing Research Repository, 2014,
https://arxiv.org/abs/1409.4842
99
The practice of generating an image, however, is more usually done using visual saliency mapping, a procedure not dissimilar to
DeepDream, but one which does not involve multiple iterations of pixel manipulations.
100
To be precise, it can only generate an image of the features that a neural network has learnt to associate with the category ‘cat’ from its
training dataset. It is not mathematically possible for DeepDream to reproduce an actual image of a cat, as there are many different kinds of
images that could satisfy the requirements for the cat category. DeepDream cannot project from the category label to one of those specific
images because there is insufficient information provided. However, if it is given an input image, it can emphasize the features associated
with the cat class, which results in a trippy, pareidolia-like image.
101
Memo Akten, Medium, ‘Background info for “#Deepdream is blowing my mind”, Medium, 9 July 2015, As Memo Akten comments
(somewhat tongue-in-cheek): ‘A very crude way of putting this is you give the network a completely random picture that looks nothing like a
cat and you ask it “does this look like a cat?”, the network says “no”. You make a few random changes and ask “what about this?”, and the
network says “no”. And you keep repeating. If the network says “yea, maybe that looks a bit more like a cat” you say “aha! ok so I’ll make
more changes in that direction, how about this?”. It’s actually not exactly like that, but you get the idea. And you can see why it takes so
long.’ https://medium.com/@memoakten/background-info-for-deepdream-is-blowing-my-mind-1983fb7420d9
102
The challenge of inverting the operation of a neural net in order to generate images is not so straightforward. The process cannot literally
be inverted, as it is a non-linear operation, and therefore some ingenuity is required. As Blaise Aguera y Arcas explains: ‘With a
convolutional net you can’t do this directly exactly, as it is not a linear operator, and therefore not invertible. But you can ‘cheat’, by
basically saying that I am going to optimize the pixels, so I’ll start maybe with noise – with pure noise – and run the same gradient ascent
algorithms that you use to learn a neural net on the pixels until the output corresponds to the embedding vector that I want.’ Aguera y Arcas,
Blaise. 2016. How Computers are Learning to be Creative, TED Talk.
https://www.ted.com/talks/blaise_aguera_y_arcas_how_computers_are_learning_to_be_creative?language=en
103
‘The problem,’ as Aguera y Arcas notes, ‘is that the convolutional nets are designed to be invariant to pose, which means that when they
are run backwards they do not know what pose to render things in. This leads to an aggregation of several poses at once.’ Aguera y Arcas,
2016. The reason behind the aggregation of poses is that a trained classification network has learnt a many-to-one mapping technique, in
that multiple images can be categorized, for example, as a ‘bird’. In this process it discards unimportant pixel information to make the
classification prediction. As a result there is insufficient information for it to shift to a one-to-many mapping. The system is therefore
incapable of generating a realistic image of a ‘bird’.
104
Mordvintsev describes the process as follows: ‘We ask the network: “Whatever you see there, I want more of it!” This creates a feedback
loop: if a cloud looks a little bit like a bird, the network will make it look more like a bird. This in turn will make the network recognize the
bird even more strongly on the next pass and so forth, until a highly detailed bird appears, seemingly out of nowhere.’ It is important,
however, to specify a layer, and ask the network to enhance what it sees. Whereas lower-level layers simply produce ‘strokes’ and ‘simple

25

Generative Adversarial Networks
Currently the most popular technique of image synthesis among architects, however, are Generative
Adversarial Networks (GANs). These were first proposed by Ian Goodfellow in 2014, but have
undergone rapid development in the intervening years.105
A GAN is a technique for training a computer to perform complex tasks through a generative process
measured against a set of training images. It represents a major breakthrough in the quest to
synthesize images. It overcomes the problem of objects appearing in a variety of poses that
compromises DeepDream. It also generates images with significantly better resolution.
A GAN is based on a competition between two different neural networks. A GAN consists of a
bottom-up generator – or ‘artist’ – that generates images, and a top-down discriminator – or ‘critic’ –
that evaluates those images.106 In the competition, the generator attempts to fool the discriminator by
producing images so realistic that the discriminator would be unable to distinguish them from a real
data set. Mishak Navak describes the process as follows:
‘[A] Generator (an artist) generates an image. The Generator does not know anything about the
real images and learns by interacting with the Discriminator. [The] discriminator (an art critic)
determines whether an object is “real” and “fake” . . . The Generator keeps creating new
images and refining its process until the Discriminator can no longer tell the difference between
the generated images and the real training images.’107
The two work in tandem and improve over time, so that the ‘artist’ trains the ‘critic’, and the ‘critic’
trains the ‘artist’.108 Once the ‘artist’ has been trained, the ‘critic’ can be removed.

ornament-like patterns’, higher–level layers ‘identify more sophisticated features in images, complex features and even whole objects’.
Higher-level layers are therefore more productive, and can potentially work by feedback loops to enhance the image that they are fed, to
unexpectedly generate a further image. Mordvintsev, Alexander; Olah, Christopher, Tyka, Mike. 2015. ‘Inceptionism: Going Deeper into
Neural Networks.’ https://web.archive.org/web/20150703064823/http://googleresearch.blogspot.co.uk/2015/06/inceptionism-going-deeperinto-neural.html
105
Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua
(2014). Generative Adversarial Networks. Proceedings of the International Conference on Neural Information Processing Systems (NIPS
2014). pp. 2672–2680. The idea initially came to Goodfellow reportedly in a pub in Montreal. Martin Gales, The GANfather: The man
who’s given machines the gift of imagination, MIT Technology Review, 21 February 2018,
https://www.technologyreview.com/s/610253/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/
106
The generator takes in a noise vector, called a latent vector, as a seed to control the rendering process of the output image. Each element
of the latent vector describes some sort of visual axis of information, such as hair length, in the case of a face. The noise vector randomly
chooses values for each visual axis of the latent space, so that the generator network can render both a face with medium length hair looking
directly at the camera, as well as a face with short hair turned to the side. The latent vector describes the distribution of real world visual
concepts in the dataset, and the noise samples this distribution to render images with different visual content.
107
Nayak, Mishak. 2018. ‘Deep Convolutional Generative Adversarial Networks (DCGANs). Data Driven Investor.
https://medium.com/datadriveninvestor/deep-convolutional-generative-adversarial-networks-dcgans-3176238b5a3d
108
As Rani Horev notes, ‘The generator input is a random vector (noise) and therefore its initial output is also noise. Over time, as it
receives feedback from the discriminator, it learns to synthesize more “realistic” images. The discriminator also improves over time by
comparing generated samples with real samples, making it harder for the generator to deceive it.’ Rani Horev, Style-Based GANs –
Generating and Tuning Realistic Artificial Faces, LyrnAI: Deep Learning Explained, December 26, 2018, https://www.lyrn.ai/2018/12/26/astyle-based-generator-architecture-for-
The invention of GANs has since led to an extraordinary explosion of research and the development
of many different versions, with their outputs becoming ever more refined.109 GANs build upon the
developments of DeepDream in interesting new ways.110 And although they are not without their
problems, the standard has improved substantially in the relatively few years since GANs were first
developed.111
The Progressive Growing of GANs (ProGAN), for example, increases the resolution of the image,
layer by layer. 112 This allows the whole process to speed up, producing far greater realism than
previously achieved. However, there is limited control of certain features in the generated image,
leading to problem of ‘entanglement’ whereby any slight tweak or amendment to one feature has a
knock on effect on the next.113
A StyleGAN offers further improvements in terms of resolution and quality, by starting with very low
resolution images, and gradually increasing the resolution.114 It treats an image as a collection of
different ‘styles’, whereby each ‘style’ controls the effect at a particular scale, whether it be a coarse
‘style’, such as pose, hair or face shape, a middle ‘style’, such as eyes and other facial features, or a
fine ‘style’ as in colour. This allows a StyleGAN to overcome the problem of ‘entanglement’, by
reducing the correlation between different features. As it learns, the system is able to morph certain
details, such as hairstyle or age, far more convincingly, by isolating specific features, and playing
them off against each other. Indeed, StyleGAN can generate artificial faces so convincing that it is
often almost impossible to tell them apart from real faces.115 Perhaps the greatest advantage of this
technique, however, is that images can simply be processed, without being tagged or classified,
thereby saving considerable time.116
Conditional Adversarial Networks (cGANs) are based on a pix2pix version of GANs that has become
very popular with the AI art community. Pix2pix effectively translates one image to another in a
109

A113
As Rani Horev observes, ‘ProGAN generates high-quality images but, as in most models, its ability to control specific features of the
generated image is very limited. In other words, the features are entangled and therefore attempting to tweak the input, even a bit, usually
affects multiple features at the same time. A good analogy for that would be genes, in which changing a single gene might affect multiple
traits.’ Rani Horev, Style-Based GANs – Generating and Tuning Realistic Artificial Faces, LyrnAI: Deep Learning Explained, December 26,
2018, https://www.lyrn.ai/2018/12/26/a-style-based-generator-architecture-for-generative-adversarial-networks/
114
Karras, Tero, Laine, Samuli. Aila, Timo. 2018. ‘A Style Based Generator Architecture for Generative Adversarial Networks’, 12
December 2018, https://arxiv.org/pdf/1812.04948.pdf
115
There is even a website that automatically generates highly realistic novel faces: https://www.thispersondoesnotexist.com/
116
As the authors note: ‘The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose
and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive,
scale-specific control of the synthesis.’’ Karras, Tero, Laine, Samuli. Aila, Timo. 2018. ‘A Style Based Generator Architecture for
Generative Adversarial Networks’, 12 December 2018, https://arxiv.org/pdf/1812.04948.pdf

27

process not dissimilar to the way that Google translates languages. Importantly they can be
‘conditioned’ by training the generator so as to produce a specific outcome, rather than a random one.
The main improvement offered by cGANs is that they can develop their own loss function, thereby
improving the capacity to predict an expected outcome, by obviating the need to hand-engineer a loss
function.117 As Philip Isola and his team comment, ‘These networks not only learn the mapping from
input image to output image, but also learn a loss function to train this mapping. This makes it
possible to apply the same generic approach to problems that traditionally would require very
different loss formulations.’118
A further version of GANs popular among artists and architects is a CycleGAN. This works with
unpaired datasets, and allows for cross domain transfers between dataset A and dataset B.119 The
network has to decide how to transfer concepts between the two datasets. A good example of
CycleGAN image to image translation is the mapping of the striped patterning of a zebra onto an
image of a horse.120 Although often referred to as ‘style transfer’, in fact what this process does is to
extract and transfer certain key features from one domain to another. 121
Usually with a GAN there is one generator and one discriminator, but with a CycleGAN there are two
generators and two discriminators. The advantage of a CycleGAN is that it avoids the possibility of
‘mode collapse’ common with StyleGANs, where the generator is not generating anything new, but
the discriminator cannot complain about the output, as the result is ‘true’.122 It is therefore capable of
learning special characteristics from one dataset and figuring out how to translate them onto the other
dataset, without needing paired training examples.123
Creative Adversarial Networks (CANs) are yet another version of GANs developed recently and used
in particular to generate art. CANs introduce a new strategy to AI generated artworks. With other
forms of GANs, the initial dataset will inevitably constrain the search space from which any output
might be generated. In other words, although any output will generate an infinite number of variations

– seemingly a kind of ‘blending’ – of data in the dataset, nothing outside that dataset can be generated.
With CANs, however, these constraints are relaxed, and the possibility of a variation beyond the
range of the dataset becomes possible: ‘The system generates art by looking at art and learning about
style; and becomes creative by increasing the arousal potential of the generated art by deviating from
the learned styles.’124
In effect the discriminator gives off two signals. The first signal operates like a conventional GAN
with a standard generator generating works that appear to fit within an accepted genre or style. But the
second signal plays off this, and attempts to generate a work that is more ambiguous:
‘If the generator generates images that the discriminator thinks are art and also can easily
classify into one of the established styles, then the generator would have fooled the
discriminator into believing it generated actual art that fits within established styles. In contrast,
the creative generator will try to generate art that confuses the discriminator. On one hand it
tries to fool the discriminator to think it is “art,” and on the other hand it tries to confuse the
discriminator about the style of the work generated.’ 125
These two seemingly contradictory impulses work together. They push the generator to create a work
that both lies close to accepted distribution of art, but also maximizes the ambiguity of the generated
work. The intention here is to open up the range of creative possibilities ‘by maximizing deviation
from established styles and minimizing deviation from art distribution.’126 The resultant work
therefore will conform closely enough to accepted canons of art, while also offering a novel variation
that is intriguing enough to stimulate interest.
Another area of development has been natural language processing. Here an image is generated from
a text. One of the first explorations of this idea came with the development of yet another GAN,
AttnGAN, which allows ‘attention-driven, multi-stage refinement for fine-grained text to image
generation.’ 127 AttnGAN starts off with a crude low-resolution image, and then gradually improves it
to generate offers what appears to be a 3D interpretation of a 2D pattern, although it remains 2D. This
has significant advantages over other GAN models, and potentially opens up the domain of natural
language processing for image generation.

A huge leap forward in terms of natural language processing, however, came with the development of
OpenAI’s GPT-3. Its already promising results in terms of language skills – compared to the early
version, GPT-2 – have been noted above. Meanwhile, Image GPT, had shown that the same type of
neural networks could also be used to generate high fidelity images. However, with the introduction
of DALL-E, a version of GPT-3 trained to generate images from texts, based on text-image pairs, and
named after the Spanish painter, Salvador Dali, this technique was taken to another level.128 DALL-E
is able to generate a relatively convincing series of images in response to a simply text based
description. Given that the role of the architect – or indeed any kind of designer – is to interpret the
instructions of a client and produce a visual representation of a design based on those instructions,
DALL-E is already signaling that it can take on the role of a designer. Nonetheless, this field remains
challenging. Working from text to image can be very constraining, and a verbal description of an
image poses considerable limitation. A picture, after all, is worth a thousand words.
From 2D to 3D
The real challenge is using a GAN is to operate in 3D. The is not simply because the computational
power required would be extremely high, but also because there are as yet no tools available for
dealing with the complexities of working with neural networks in 3D.129 Moreover backpropagation
does not work well with deep learning when operating in 3D.130 Two of the most popular techniques
for describing 3D form are voxels and point clouds.131
It is possible to voxelise a 3D model and train a neural network to understand it.132 However,
voxelised models can be extremely large. Another option is to use a multi-view convolutional neural
network to produce a synthesized understanding of the form. This has met with some success, despite
problems with mode collapse. Alternatively it is possible to use variational auto-encoders.133 However,
resolution remains low. Moreover, voxels are unable to distinguish free space from unknown space,
and do not offer enough smooth surface information for modeling purposes.
Point clouds have certain advantages over voxels, in that they are computationally efficient and not so
sensitive to noise, because of their sparse nature, and it is possible to use them in AI informed 3D
design. Research into using unsupervised deep learning to learn points and shape features in point
clouds has been reasonably productive, and has shown that an unsupervised approach using point
clouds can come close to matching the performance of supervised approaches.134 Point clouds,
however, consist of points, and do not offer any surface as such.
Object meshes, meanwhile, have certain advantages over both voxels and meshes, in that they are
more computationally efficient than voxels, and offer more visual information than meshes. However,
3D meshes can cause a problem if they are of different sizes, in that most rendering engines are not
differentiable.
At present a differential mesh renderer seems to be the most promising approach to operating in 3D.
In 2020 PyTorch3D was launched. This is an open source library for 3D learning that overcomes many
of the problems by using a differential neural mesh renderer to synthesise 3D forms. PyTorch3D
makes it possible to edit objects based on DeepDream and style transfer technique.135 Modelling in
3D, however, remains a challenging area, and one that still needs to be resolved.
ArchiGAN
From an architectural perspective, the main constraint with GANs is that they operate within the
domain of 2D representation, whereas architecture consists of 3D form. Nonetheless, architectural
drawings – plans, sections, elevations and even axonometric drawings and perspectives – are
themselves 2D representations. It is therefore their capacity to generate images, as Stanislas Chaillou
observes, that makes GANs so significant for architectural design:
‘Goodfellow’s research turns upside down the definition of AI, from an analytical tool to a
generative agent. By the same token, he brings AI one step closer to architectural concerns:
drawing and image production. All in all, from simple networks to GANs, a new generation of
tools coupled with increasingly cheaper and accessible computational power is today positioning
AI as an affordable and powerful medium.’ 136

134

Kaveh Hassani, Mike Haley, ‘Multi-Task Feature Learning on Point Clouds,’ https://arxiv.org/pdf/1910.08207.pdf
The neural mesh 3D renderer, they note, has the following advantages: ‘It is a differentiable rendering/rasterizer algorithm that can be
used as an input layer with CNNs and other forms of 2D neural networks. This framework effectively yields a mapping function (the fusion
of the differentiable renderer and neural networks) between the 3D polygon mesh and 2D image representation of objects. The Neural 3D
Mesh Renderer network is differentiable so the gradients of an image can be taken with respect to the vertices and surfaces of the input mesh.
Thus, the same principles/formulations guiding . . . 2D dreaming and 2D style transfer techniques can be used to perform image editing on
the surfaces of 3D objects.’ Matias del Campo, Sandra Manninger, Alexa Carlson, Marianna Sanche, Leetee Jane Wang, ‘Machine
Hallucinations: An Examination of Architecture in a Postdigital Design Ecology’, International Association for Shell and Spatial Structures,
2019.
136
Stanislas Chaillou, ‘The Advent of Architectural AI,’ Towards Data Science, 17 September 2019, https://towardsdatascience.com/theadvent-of-architectural-ai-706046960140
135

31

Chaillou is an architect, but unlike most architects who find themselves limited to tools developed by
others, he has developed his own tools.137 For his Masters Thesis at Harvard GSD, Chaillou designed
ArchiGAN, a version of GANs that uses a Pix2Pix GAN-model to design floor plans for an entire
building. By effectively nesting models of the furniture layout within a partitioned apartment, and
then nesting the partitioned apartment within the overall building footprint, he is able to achieve a
‘generation stack’ where each of these three layers are interrelated. Importantly also Chaillou allows
the user to amend the design at each stage.
The first step is to establish a building footprint based on the site. This is done with a model trained to
generate footprints based on Geographic Information System (GIS) data using Pix2Pix. The second
step is to introduce partition walling and fenestration so as to generate the floor plan, with the position
of the entrance and main windows specified by the user. A database of over 800 annotated plans is
used as input, and as output the system generates a layout with rooms encoded with colours to specify
program. The final step is to generate the furniture for each room based on its programme – a bed in
the bedroom, and a table in the dining room and so on. These models are ‘chained’ to each other, so
that as the user intervenes and starts modifying the footprint, for example, the partition walling and
furniture layout will adjust automatically.
There are, of course, limitations to this model. Firstly, if each floor is different, there is no way of
guaranteeing that load bearing walls on each floor will be aligned. It is therefore assumed that the
external wall is load bearing, although it is possible to introduce internal load bearing walls. Secondly,
the resolution of each drawing is currently too low, although it could be improved with more
computing power. Finally, GANs can only handle pixel information, a format incompatible with
standard computational tools in the architectural office.138 Here we should not overlook graph-based
neural networks and vector-based neural networks, which perform better than GANs and other image
based neural networks in certain specific tasks, especially when the architectural data can be
represented as vectors (CAD drawings or parameters).
Beyond Representation
It might be tempting to associate AI solely with the field of representation. After all, the datasets used
for AI often consist of representational images, and the term ‘style transfer’ is often used, especially
in connection with GANs.139 It is important to recognise, however, that a GAN constitutes a process,
137

This is not dissimilar to how Gehry Technologies customised Catia - a software developed initially in house by aircraft manufacturer
Dassault Systems to produce its Mirage fighter jet – to produce Digital Project, a computer aided design (CAD) and building informational
modeling (BIM) application to be used by architects.
138
One way to resolve this issue, however, is to transform the image from a raster image to a vector format.
139
The term, ‘style,’ is highly controversial in architectural circles. Few architects think that they design in a particular style, just as few
people think that they speak with an accent. This is because the way we design or speak constitutes our background horizon of
consciousness, and we are therefore unaware of it. However, there is a worrying tendency on the part of architectural historians, to read even
digital design in terms of style. This can be traced back to publications, such as The Digital Turn, a collection of essays edited by Mario

32

albeit a process that operates with representational images.140 Moreover, we could argue that ‘feature
extraction’ is a better term than ‘style transfer’. We could also argue that a GAN in itself is unlikely to
promote a particular style, if by ‘style’ we understand the idea of a predefined representational logic –
an aesthetic ‘template’ – according to which the work is produced, for the simple reason that it cannot
be controlled. Finally, although GANs – and image synthesis in general – are popular amongst those
working in the visual realm, they constitute a relatively minor research field within machine vision,
which is itself only one of the many categories within deep learning.141
AI, then, is certainly not limited to representational concerns. Indeed, as we shall see, performancebased concerns are likely to be the area where AI will have its greatest impact, especially in terms of
architectural practice and urban design. Indeed, at an urban scale, where data driven and performance
informed design is becoming increasingly popular, representational considerations play only a minor
role. Concerns about improving the material performance of buildings and reducing carbon emissions
have now become paramount, and go beyond considerations of mere economic efficiencies, to
become an ethical imperative in a world of diminishing resources and global warming. As a result, the
earlier obsession with form for the sake of form has given way to a more intelligent approach,
whereby form is informed increasingly by performative concerns. Performance, of course, has long
been a concern within the fields of architecture and urban design. However, with the introduction of
advanced informational systems drawing upon satellite information and data mining, there are more
opportunities to model and test performance of designs with far greater accuracy.
One key area, where AI is being used increasingly for performance driven design is structural design,
where topological optimization, an established GOFAI technique, that is now being applied
increasingly in generative design. Examples would include Project Dreamcatcher, a generative design
system developed by Autodesk, that allows designers to generate a range of designs by specifying
goals and constraints, such as functions, materials, performance criteria and costs restrictions,
allowing them to trade off different approaches and explore design solutions.142 Another example
would be Ameba, a bi-directional evolutionary structural optimization [BESO] technology developed
by Mike Xie of Xie Technologies.143 And since Grasshopper and other algorithmic design techniques
are considered basic forms of AI, plugins for Rhino and Grasshopper, such as Rhinovault, can also be
considered as forms of AI.
Carpo, where Carpo interprets the digital as a ‘style’ based on curvilinear forms, growing out of the work of Greg Lynn and Bernard Cache.
Mario Carpo, The Digital Turn in Architecture 1992-2012, London: Wiley, 2013. As we know, however, the digital has a far longer and
richer history than this, and is not associated with any particular style. Although the digital offers certain affordances, it has no agency. For
the theory of affordances see James Gibson, The Ecological Approach to Visual Perception, Hove: Psychology Press, 1979.
140
A GAN is unlikely to promote a particular style, if by ‘style’ we understand the idea of a predefined representational logic – an aesthetic
‘template’ – according to which the work is produced, as it is impossible to control the process of generating an output, still less to
guarantee a particular aesthetic, which is surely the hallmark of style-based design.
141
Marina Chatterjee, ‘Top 20 Applications of Deep Learning in 2020 across Industries,’ Great Learning Blog, 19 February 2019,
https://www.mygreatlearning.com/blog/deep-learning-applications/
142
See online information Autodesk research (check)
143
For Dreamcatcher, see https://autodeskresearch.com/projects/dreamcatcher. For Ameba, see Ameba.xieym.com.

33

Another key area, where AI has proved very effective, is in the environmentally sustainable design of
new buildings. 144 It can also de deployed, however, in monitoring and controlling the energy use in
existing buildings, and for other more general environmental issues, such as, thermal comfort, wind
comfort, lighting levels, solar radiation, pedestrian traffic and sightlines.145 Increasingly the
environmental control of a building is being achieved through the use of a ‘digital twin’, a digital
model that simulates the performance of a potential or actual building.146 Digital models, of course,
have been around for some time, but a digital twin is a relatively new invention.147 A digital twin is a
digital model that is constantly being updated with real time information from both the Internet of
Things (IoT), and direct sensors.148 As Michael Batty defines it: ‘A digital twin is a mirror image of a
physical process that is articulated alongside the process in question, usually matching exactly the
operation of the physical process which takes place in real time.’149 A digital twin can be used both
for analyzing performance in the past, but also for predicting performance in the future. And it can
operate at a range of scales from a building scale, where it can be used, for example, to model the
behaviour of occupants, through to an urban scale, where it can be used, as we shall see, to monitor
and control traffic flow.150
In recent years the range of AI assisted and AI driven applications has exploded. Here we might cite
the proliferation of generative design and topological optimisation products, such as ANSYS
Discovery AIM, Bentley Generative Components, Comsol Optimization Module, Siemens Solid Edge
Generative Design, and many others.151 The only area that remains as yet underdeveloped, however, is
the application of machine learning to tools for architecture, construction and engineering (ACE).
There are signs, however, that change is afoot, and the Austrian Institute of Technology, for example,

144

One obvious example of more advanced forms of AI, such as machine learning, have also been used in environmental control systems,
such as the domestic learning thermostats produced by Nest and Honeywell. https://nest.com;
https://www.honeywellhome.com/us/en/products/air/thermostats/. The learning techniques involved in these two systems remain trade
secrets, but reinforcement learning has been proposed as a way of training environmental control systems. Barrett, Enda & Linder, Stephen
Paul. (2015). Autonomous HVAC Control, A Reinforcement Learning Approach. 9286. 10.1007/978-3-319-23461-8_1.
145
Joseph Bien Kahn, ‘If AI Doesn’t Take Your Job, It Will Design Your Office,’ Wired, 5 April 2017.
https://www.wired.com/2017/04/autodesk-project-discover/
146
This is an issue that has been recognized by AI start-up, Helix Re, which grew out of the earlier AI start-up Flux.io. Helix Re is
developing ‘digital twins’ of existing buildings in order to monitor and control their performance. Jim Lichtenwalter, “Fireside Q&A:
Jamie Roche, HELIX RE’s CEO,” Builtworlds, 3 May 2019, https://builtworlds.com/news/fireside-qa-jamie-roche-helix-res-ceo/
147
Autodesk, for example, did not announce plans to release Autodesk Tandem until November 2020.
(https://adsknews.autodesk.com/pressrelease/tandem-brings-digitial-twin-to-bim) However, the digital twin was predicted by David
Gelernter back in 1991: David Gelernter, Mirror Worlds: or the Day Software Puts the Universe in a Shoebox – How it Will Happen and
What it Will Mean, Oxford: Oxford University Press, 1991; but it was not named until 2010: R Piascik et al., Technology Area 12: Materials,
Structures, Mechanical Systems, and Manufacturing Road Map, 2010, NASA Office of Chief Technologist.
148
The NEST thermostat, for example, not only monitors environmental conditions, but also tracks occupancy through the presence of
mobile phones. Traffic control systems also track mobile phones, although deep learning systems are now also being deployed to monitor
traffic. Mauro Fernández-Sanjurjo, Brais Bosquet, Manuel Mucientes, Víctor M. Brea, Real-time visual detection and tracking system for
traffic monitoring, Engineering Applications of Artificial Intelligence, Volume 85, 2019, pp. 410-420, ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2019.07.005.
149
Michael Batty, ‘Digital Twins,’ Environment and Planning B: Urban Analytics and City Sense, 10 September 2018,
https://journals.sagepub.com/doi/10.1177/2399808318796416
150
On the use of a ‘digital for controlling city traffic, see City Brain, pp. xxxxx
151
For a comprehensive survey of Generative Design and Topological Optimization tools, see: ‘Generative Design and Topological
Optimization: In-Depth Look at the Two Latest Design Technologies,’ Engineering.com.
https://www.engineering.com/ResourceMain.aspx?resid=826&e_src=relres-ecom

34

has produced a number of machine learning tools, such as daylightGAN, ArchElites and InFraRed.152
In fact, it is difficult to imagine an area where machine learning will not be used in the future. AI will
undoubtedly make a number of significance contributions to architectural culture. It will allow us to
design more efficiently, generate a broader range of designs, test out our designs in simulation, and
control the performance of buildings once constructed.
The future of architecture will be intelligent.

152

InFraRed (the Intelligent Framework for Resilient Design) is the world’s first real-time urban performance-design platform, leveraging
state-of-the- art AI methods to increase the speed of urban simulation by several orders of magnitude. Link: http://infrared.city/ ArchElites is
a Quality Diversity (QD) library that implements the state-of-the-art AI algorithm MAP-Elites, adjusted for inputs, design workflows and
evaluation metrics, specific to the Built Environment. ArchElites is the world’s first QD tool and enables ideas of divergent search and
exploration across behavioral dimensions of a design space, a new paradigm for design. Link:
https://theodoregalanos.github.io/ArchElites/introduction.html DaylightGAN is a bespoke Deep Learning General Adversarial Network
(GAN) model for real-time daylight performance evaluation of building layouts. daylightGAN enables performance-driven generative
design for building layout at scale. Link: https://github.com/TheodoreGalanos/DaylightGAN

35

Chapter 2
The History of AI
We could trace the origins of AI right back to the myths and legends of artificial life in classical
antiquity and beyond. Or we could trace them back to the more recent religious and literary stories of
Golem and Frankenstein.153 Likewise, we could trace them back to the development of formal
reasoning in philosophy. Without the field of logic, founded by Aristotle, we would not have the
modern computer. And without the attempts of Leibnitz to reduce human thought to some form of
calculation, we would not have computers performing human-like reasoning. Or, again, we could
trace them back to developments in mathematics. Without the algebraic operations formalized by
George Boole, we would not have Boolean logic that underpins computation.
Alternatively, if we were to limit ourselves to the domain of computer science, we could trace the
origins of AI back to figures such as the British polymath, Charles Babbage, inventor of the
Difference Engine and Analytical Engine,154 and to the mathematician, Augusta Ada King, Countess
of Lovelace – otherwise known as Ada Lovelace – who collaborated with him, and is often regarded
as one of the first computer programmers.155 It is generally agreed, however, that it was another
British polymath, Alan Turing, who was the first person to really address the potential of an artificial
form of intelligence.
Alan Turing
In 1936 Turing wrote a paper – published in 1937 – called, ‘On Computable Numbers, with an
Application to the Entscheidungsproblem’, in which he laid out the conceptual groundwork for
computation, as we know it, describing what he initially called an ‘a-machine’ or an ‘automatic
machine’.156 This has subsequently become known as the Turing Machine.157
During World War 2, Turing played a vital role during World War 2 (1939-1945), using the ‘Bombe’,
an electro-mechanical device that was used to decipher German messages. The challenge was to crack
the Enigma code, and expose the secret content of coded messages being sent to and from the German
military. Once his team had achieved this, Turing was cautious not to offer the Germans any clue
about their success, by intervening in any form of military situation based on information that could
153

Emily Bilski, ‘Artificial Intelligence Avant La Lettre: The Golem of Jewish Mysticism, Legend and Art’ in Chloe Woods with Suzanne
Livingston and Maholo Uchida, (eds.), AI: More Than Human, London: Barbican International Enterprises, 2019, p. 210.
154
These remained unbuilt. Halacy, Daniel Stephen (1970). Charles Babbage, Father of the Computer. Crowell-Collier Press; Doron
Swade, The Difference Engine: Charles Babbage and the Quest to Build the First Computer, London: Penguin, 2002; Michael Lindgren
(Craig G. McKay, trans.), Glory and Failure: The Difference Engines of Johann Müller, Charles Babbage, and Georg and Edvard Scheutz,
Camb. MA: MIT Press, 1990.
155
John Fuegi, Jo Francis, "Lovelace & Babbage and the creation of the 1843 'notes'", Annals of the History of Computing, 25 (4): 16–26,
(October – December 2003),
156
Alan Turing, ‘On Computable Numbers, with an Application to the Entscheidungsproblem,’ Proceedings of the London Mathematical
Society, s2-42: 230–265; correction ibid., s2-43: 544–546 (1937). doi:10.1112/plms/s2-42.1.230 and doi:10.1112/plms/s2-43.6.544
157
Andrew Hodges, Alan Turing: The Enigma, New York: Princeton University Press, 2012.

36

only have been gained if the German code had been cracked.158
After the war, Turing worked for the National Physical Laboratory on the Automatic Computing
Engine [ACE], an early form of stored-program computer. In 1948 he took up an academic
appointment at Victoria University of Manchester, and designed software for the Manchester Mark 1,
one of the first stored-program computers.159 During this period, Turing also worked on a computer
program that could play chess.160 Additionally, Turing later became interested in biological
morphogenesis, and developed the theory of ‘reaction-diffusion’.161 He was also the first to notice the
connection between artificial life and AI.162 The range of Turing’s intellectual interests was
extraordinary. If all this was not enough, Turing also placed 5th in the marathon in the 1947 English
national championships.163 Turing was not only one of the greatest polymaths of all time, but also a
true universal man.
In terms of his involvement with AI, the most significant moment came in 1950, when Turing
published a paper, ‘Computing Machinery and Intelligence,’ where he speculated about the possibility
of developing machines that could think.164 He described a technique by which to judge whether the
intelligence of a ‘thinking machine’ could match the intelligence of human beings. Initially named
after a popular party game, the ‘Imitation Game’, it subsequently became known as the ‘Turing
Test’.165 The clever aspect of the Turing Test is that we do not have to define terms such as, ‘a
machine’ or ‘to think’. Instead, a simple game is played between a judge, a human being and a
computer program. The challenge is for the computer program to compete against the human being,
taking part in a conversation, and answering questions set by the judge. If the computer program
manages to convince the judge that it is human, it passes the Turing Test.
As has often been observed, AI is invisible. Likewise, while Turing’s early work on the Enigma code
was about revealing secrets, it was also very secretive itself. It was literally invisible, in that it was
undertaken as part of a top-secret wartime research program in Bletchley Park, England, and was
classified information under the Official Secrets Act, so that it remained a secret until declassified in
the mid-1970s.166 As a result, the general public had no idea about the research that Turing had been

158

This scene is played out in the movie, The Imitation Game. Morten Tyldum (director), The Imitation Game, film, 2014.
Dermot Turing, Alan Turing: The Life of a Genius, Pitkin: Norwich, 2017.,
160
Liat Clark, Ian Steadman, ‘Remembering Alan Turing: From Codebreaking to AI, Turing made the world we live in today,’ Wired, 7
June 2017, https://www.wired.co.uk/article/turing-contributions
161
Jack Copeland, Turing: Pioneer of the Information Age, Oxford: Oxford UP, 2012, p. 196.
162
Op. cit., p. 198.
163
Technically the race was the Amateur Athletics Association (AAA) championships, but this was effectively the English Championships.
It should be noted that Turing’s time only 10 minutes slower than the winning time for the men’s marathon at the 1948 Olympic Games in
London. Turing had intended to run in the British Olympic Trials, but developed a hip injury. Jack Copeland, Turing: Pioneer of the
Information Age, Oxford: Oxford UP, 2012, p. 136; Pat Butcher, ‘Record Breaker,’ Runner’s World, September 1999, pp. 56-57.
164
Alan Turing, October 1950, "Computing Machinery and Intelligence", Mind, LIX (236): 433–460.
165
‘The Turing Test, 1950’, The Alan Turing Internet Scrapbook, https://www.turing.org.uk/scrapbook/test.html
166
If Turing remained largely unknown until his exploits were finally revealed, there are many other individuals – especially the female
assistants on the projects in which Turing was involved, who remain almost completely unknown even to this day. Kate Lewis, ‘Bletchley
Park: No Longer the World’s Best Kept Secret,’ BBC News, 18 June 2014. See also, Sadie Plant, Zeros and Ones: Digital Women and the
New Technoculture, London: Fourth Estate, 1998.
159

37

undertaking. It was as though his work remained even more of an enigma than the code that he had
broken.
These days, of course, Turing is well known, following the release of the movie, The Imitation Game
(2014), directed by Morten Tyldum, with Benedict Cumberbatch, passing himself off as Turing.167
Likewise, Turing now appears on every 50 GBP note, along with his famous quote, ‘This is only a
foretaste of what is to come, and only a shadow of what is going to be.’168 From once being totally
invisible, Turing has now become the high profile poster boy for computation and AI, and an icon
within the gay community.
And yet despite the secrecy surrounding much of his life, it could be argued that the tragedy of Turing
is that he failed to keep one aspect of his life a secret – his own sexuality. As Benjamin Bratton
astutely observes, Turing failed to pass his own ‘Turing Test’. He failed to convince the world that he
was heterosexual in a society where homosexuality was deemed a crime.169 Once his homosexuality
had been exposed, however, Turing was prosecuted. In 1952 he was convicted of ‘gross indecency’,
and given the choice of a prison sentence or chemical castration. He opted for the latter. In 1954
Turing took his own life, no doubt partly as a result of this highly public humiliation. The irony here,
of course, is that although Turing himself had saved the lives of millions during the war, at that time
of his own death the general public was completely unaware of many of his achievements, as they
remained state secrets.170
In the UK, there is a popular television science fiction series, Doctor Who.171 The series tells the story
of a scientist with a PhD who saves the world in every episode. In contrast to most American
superheroes, who slug it out with their foes in physical brawls, Doctor Who never gets into any
physical fight, but vanquishes evil simply through the application of science and technology.
Could Doctor Alan Turing have been the inspiration for the original Doctor Who?172
The Birth of AI
Another significant development occurred in 1943, when mathematician Walter Pitts and neurologist

167

Morten Tyldum (director), The Imitation Game, film, 2014.
This was a quote by Turing in the Times newspaper in 1949. Turing here was referring to early computer called the ‘mechanical mind’,
rather than to AI as such. Dermot Turing, Prof: Alan Turing Decoded, Norwich: Pitkin Publishing, 2015
https://quoteinvestigator.com/2019/10/12/ai-shadow
169
Benjamin Bratton, ‘Outing AI: Beyond the Turing Test,’ New York Times, 23 February 2015.
170
Estimates as to the number of lives that Turing managed to save through his invention vary widely. Colin Drury estimates that he saved
two million lives. Colin Drury, ‘Alan Turing, the father of modern computing, credited with saving millions of lives,’ The Independent, 15
July 2019. https://www.independent.co.uk/news/uk/home-news/alan-turing-50-note-computers-maths-enigma-codebreaker-ai-testa9005266.html But Jack Copeland argues that the figure might have been as high as 21 million. Jack Copeland. ‘Alan Turing: the
codebreaker who saved ‘millions of lives,’ BBC, 19 June 2012, https://www.bbc.com/news/technology-18419691
171
Steve Tribe, Doctor Who: A Brief History of Time Lords, New York: Harper Design, 2017.
172
This, however, is extremely unlikely. The first episode of Dr Who was broadcast in 1963, at which point Turing’s wartime exploits were
still classified as state secrets. However, the linear perception of time does not necessarily apply to a Time Lord, such as Dr Who.
168

38

Warren McCulloch devised an early computer using neural networks inspired by the human brain.173
In so doing, they brought together the binary logic of Turing’s computer, with the true/false structure
of the propositional logic of philosopher, Bertrand Russell, and the on/off structure of neural synapses
observed by neurophysiologist/cybernetician, Charles Sherrington.174 As Boden comments: ‘The
true/false values of logic were mapped onto the on/off activity of brain cells, and the 0/1 of individual
states in the Turing machine.’175
By the 1950s two overlapping branches of research into computer modeling had emerged, one
looking at adaptive behavior, and one working on logical thinking. Later these were to split into
distinct branches; cybernetics and symbolic computing.176 ‘Those interested in life,’ notes Boden,
‘stayed in cybernetics, and those interested in the mind turned to symbolic computing.’177
If, however, we were to isolate one particular event that was instrumental in not only cementing this
divide, but also in defining the term, AI, it would surely be the Dartmouth Summer Workshop on
Artificial Intelligence held in 1956.178 The event was proposed by John McCarthy, Marvin Minsky,
Nathanial Rochester and Claude Shannon, and was attended by many of the figures who would later
become luminaries in the field of AI:
‘We propose that a 2 month, 10 man study of artificial intelligence be carried out during the
summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on
the basis of the conjecture that every aspect of learning or any other feature of intelligence can
in principle be so precisely described that a machine can be made to simulate it. An attempt
will be made to find how to make machines use language, form abstractions and concepts,
solve kinds of problems now reserved for humans, and improve themselves. We think that a
significant advance can be made in one or more of these problems if a carefully selected group
of scientists work on it together for a summer.’ 179
The event not only helped to define the field, but also led to the adoption of the term, ‘artificial
intelligence,’ even though McCarthy himself was not fully comfortable with it.180

173

Warren McCulloch and Walter Pitts, ‘A Logical Calculus of The Ideas Immanent in Nervous Activity’, Bulletin of Mathematical
Biophysics, Vol. 5, 1943, pp. 115-133
174
Babbage, Lovelace, Turing, Ashby, Russell and Sherrington were all from the United Kingdom, which played a major role in the early
development of computation.
175
Boden, p. 10
176
One of the central figures in the field of cybernetics was Gordon Pask, who taught at the Architectural Association for several years. For
his essay on cybernetics and architecture, see Gordon Pask, ‘The Architectural Relevance of Cybernetics’ in Achim Menges, Sean Alquist
(eds.), Computational Design Thinking, London: Wiley, 2011
177
Boden, p. 17
178
James Moor, The Dartmouth College Artificial Intelligence Conference: The Next Fifty Years, AI Magazine, Vol 27, No 4, pp 87-89,
2006.
179
J McCarthy, M Minsky, N Rochester, C E Shannon, ‘A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence’,
August 1955. http://raysolomonoff.com/dartmouth/boxa/dart564prop.pdf
180
N J Nielson, John McCarthy: A Biographical Memoir, Washington DC: National Academy of Sciences, 2012.

39

What followed was a period of euphoria, and intense, well-funded research, fuelled by heady
speculation. Indeed in 1967 Minsky claimed that within a generation the problem of artificial
intelligence would be solved.181 All of a sudden, AI came into the spotlight. With time, however, it
became clear that these aspirations were unrealistic. For this and other reasons, funding dried up, and
the first ‘AI winter’ occurred.
AI Winters
AI winters could be defined as periods in which confidence in the potential of AI collapsed on the part
of venture capitalists and government funding agencies. These crises of confidence were triggered
initially by reports from within the academic community, but ultimately owe their origins to
overinflated expectations – much like the dot.com boom and bust in the 1990s – and illustrate the
volatility of public confidence in the new technology. The first AI winter occurred around 1974, and
was prompted largely by two setbacks.
One of the setbacks was that, despite huge investment by the US government into developing
instantaneous translation as part of its Cold War effort, the results did not live up to the hype. AI was
quite capable of translating words, but only if in the correct order.182 There were also other problems
that led to entertaining outcomes, such as ‘out of sight, out of mind’ being translated as ‘an invisible
lunatic;’ or “the spirit is willing but the flesh is weak” as “the vodka is good but the meat is rotten.”183
As a result, the primary source of military funding in the United States, the Defense Advanced
Research Projects Agency [DARPA], withdrew its funding from a major machine learning research
project. Meanwhile in 1973, Professor James Lighthill issued a controversial report in in the United
Kingdom, where he noted that AI had failed to live up to its somewhat grandiose aspirations.184 The
net result was a sudden loss of confidence in AI, leading to a drastic reduction in funding for AI
research – a phenomenon which then rippled throughout the rest of Europe.
The other setback was that confidence began to fade in connectionist AI and the potential of neural
networks, stemming out of the early work of McCulloch and Pitts. This was partly the result of the
publication of the book, Perceptrons: An Introduction to Computational Geometry, written Marvin
Minsky and Seymour Papert, who were enthusiasts of symbolic AI.185 The book outlined the
limitations of the connectionist approach that relied on the use of the perceptron, an algorithm for

181

Marvin Minsky Computation: Finite and Infinite Machines, Englewood Cliffs, NJ: Prentice-Hall, 1967, p. 2
Daniel Crevier, AI: The Tumultuous Search for Artificial Intelligence, New York: Basic Books, 1993, p. 203
Russell, Norvig, 2003, p. 21
184
Professor Sir James Lighthill, “Artificial Intelligence: A General Survey,” in Artificial Intelligence: a paper symposium, Science
Research Council, 1973.
185
Marvin Minsky, Seymour Papert, Perceptrons: An Introduction to Computational Geometry, Camb., MA: MIT Press, 1969; Crevier, pp.
102-105
182
183

40

supervised learning, invented by Frank Rosenblatt in 1958.186 Rosenblatt had predicted that the
perceptron would also be able to make decisions, and even translate languages.187 Indeed, the
perceptron did show some promise, and, as became clear later when deep learning was developed,
connectionist AI is quite capable of both making decisions and translating languages.
The publication of this book marked one of the most controversial episodes in the history of AI. For
the most part, competition between the various ‘tribes’ in the AI community took the form of standard
academic rivalry. However, some perceived this book as going beyond this acceptable level, and as
delivering a blistering critique of connectionism. Minsky and Papert themselves played down their
critique, claiming that it had been misunderstood: ‘We did not think of our work as killing Snow
White; we saw it as a way to understand her.’188 Two years later Rosenblatt died tragically in a
boating accident. The death of its most high profile exponent had a devastating effect on the profile of
connectionism. Without its chief spokesperson, connectionism largely disappeared from sight.
As a result, connectionism began to fall out of favour, and the rival approach, symbolic AI, came into
the ascendancy. Indeed Geoffrey Hinton claims that in subsequent years he and his colleagues
working on connectionism were forced to resort to the logic of camouflage, and scrub any reference
to neural networks, in order to get any academic papers accepted.189
A second ‘AI winter’ occurred in the late 1980s as the market for LISP machines based on the Lisp
programming languages collapsed, and workstations developed by Sun Microsystems and desktop
computers produced by IBM and Apple began to take over the market.190 A further factor was a policy
change at DARPA, whereby it was decided to attach funding to specific projects, targeted for their
likelihood of success.
Despite the apparent crises of these ‘AI winters’, research into AI actually continued to make steady
progress. It is almost as though the initial hype about the potential successes of AI, was matched only
by the hype about its failures. As Ray Kurzweil notes, "Many observers still think that the AI winter
was the end of the story and that nothing since has come of the AI field. Yet today many thousands of
AI applications are deeply embedded in the infrastructure of every industry."191 Rodney Brooks takes
a similar view:
186

Etham Alpaydin defines the perceptron as follows: “A perceptron is a type of a neural network organized in layers where each layer
receives connections from units in the previous layer and feeds its output to units in the layer that follows.” Ethem Alpaydin, Machine
Learning, Camb., MA: MIT Press, 2016, p. 179
187
Frank Rosenblatt, Principles of Neurodynamics, Washington, DC: Spartan Books, 1962.
188
Boden, p. 94. For further reading, see: Mikel Olazaran, (1996). "A Sociological Study of the Official History of the Perceptrons
Controversy". Social Studies of Science. 26 (3): 611–659. See also Crevier, pp. 102-105.
189
Russell in Ford, p. 83.
190
LISP machines were general purpose computers running on LISP software. LISP is an anchronym for Locator/Identifier Separation
Protocol. See H P Newquist, The Brain Makers, Sams Publishing, 1994.
191
Ray Kurzweil, The Singularity is Near, 2005, p. 264

41

‘There's this stupid myth out there that AI has failed, but AI is around you every second of the
day. People just don’t notice it. You’ve got AI systems in cars, tuning the parameters of the fuel
injection systems. When you land in an airplane, your gate gets chosen by an AI scheduling
system. Every time you use a piece of Microsoft software, you’ve got an AI system trying to
figure out what you are doing, like writing a letter, and it does a pretty damn good job. Every
time you see a movie with computer generated characters, they’re all little AI characters
behaving as a group. Every time you play a video game, you’re playing against an AI
system.’192
This is one of the biggest problems with AI. Although developments in AI are continuing all the time,
the general public is unaware of them. It therefore takes a high profile public event to bring AI to their
attention, and show the general public what AI can do.
Deep Blue
The challenge of beating human beings at chess has long been seen as a major objective for AI. In the
1830s Babbage mused over the possibility of building a chess playing machine, as had Turing in
1946.193 And over the years there have been many predictions as to when a computer might beat the
world champion.194 In 1990, Kurzweil had predicted that a computer would beat the world chess
champion by 2000.195
In 1997 IBM’s super computer Deep Blue took on the then world chess champion, Gary Kasparov, in
a high profile chess match reported in all the mainstream media. The match consisted of six games.
Deep Blue won two games, Kasparov one game, and three were drawn. Three years before the date
predicted by Kurzweil, a computer had beaten the world chess champion.
Despite its name, however, Deep Blue is not in fact an example of deep learning.196 It is a classic
example of machine learning. Although it was given a number of handcrafted features with a specific
set of rules and heuristics, based on information distilled from games of renowned chess experts, it
did actually ‘learn’ to play chess by playing thousands of games of chess, and was able to determine
many parameters not programmed initially. As Toby Walsh notes, ‘For example, it was not
192

Kurzweil, p. 263
‘The History of Chess AI’, Medium, 28 February 2019. https://becominghuman.ai/the-history-of-chess-ai-f8b0dcb4d6d4
Feng-Hsiung Hsu, Behind Deep Blue: Building the Computer that Defeated the World Chess Champion, Princeton: Princeton UP, 2002
195
Peter H. Diamandis, Ray Kurzweil’s Mind-Boggling Predictions for the Next 25 Years, Medium, August 22, 2018;
https://medium.com/@singularity_41680/ray-kurzweils-mind-boggling-predictions-for-the-next-25-years-ce3c9163588b
196
One of the key computational minds behind the project, Taiwanese-American computer scientist, Feng-hsiung Hsu, had named one of his
earlier computer chess-playing systems, ‘Deep Thought’. Presumably this was inspired by Deep Thought, the mega-computer that appears
in the book, novel and film, The Hitchhiker’s Guide to the Galaxy. Deep Thought had been programmed to answer ‘The Ultimate Question
to Life, the Universe and Everything’. After 7.5 million years Deep Thought comes up with the answer ‘42’. The final name, Deep Blue,
was also informed by IBM’s nickname ‘Big Blue’. Feng-Hsiung Hsu, Behind Deep Blue: Building the Computer that Defeated the World
Chess Champion, Princeton: Princeton UP, 2002
193
194

42

programmed how to weight a safe king position, compared to a space advantage in the center. The
optimal values for these parameters were determined by machine learning over thousands of master
games.’197
The success of Deep Blue shocked many people, especially within the chess community. Mark
Wieder, a chess player who is also a computer programmer, commented, "This is a historic event. The
greatest human player of all time lost to a machine."198 Kasparov himself was also so shocked by one
of the moves played by Deep Blue, that he reportedly thought that it had cheated.199 In the end,
however, Kasparov acknowledged the achievements of Deep Blue, adding that he had sensed a new
kind of intelligence and witnessed true creativity in some of its moves.200 Indeed Deep Blue has made
a huge contribution to the world of chess, revealing new strategies and moves that have since been
adopted by human chess players.
Although some might interpret his loss to Deep Blue as one of the first of a series of humiliations for
human beings at the hands of AI, Kasparov himself views the moment as a triumph for human beings.
In his book, Deep Thinking, Kasparov observes:
‘I made it clear that my loss to Deep Blue was also a victory for humans – its creators and
everyone who benefits from our technological leaps. That is, everyone. This is always the case
in the big picture, and why the book rejects the “man vs. machine” competition storyline. The
machines work for us, after all.’201
Kasparov is in no doubt, however, that – eventually – AI will be capable of outperforming human
beings in every aspect of our lives: ‘Everything we know how to do, machines will do better.’202
Anything you can do, AI can do better.

197

Toby Walsh, Machines that Think: The Future of Artificial Intelligence, New York: Prometheus Books, 2018, p. 118..
Michelle McPhee, K C Baker, Cory Siemaszko, ‘Deep Blue, IBM's supercomputer, defeats chess champion Garry Kasparov in 1997,
New York Daily Times, 10 May 2015. https://www.nydailynews.com/news/world/kasparov-deep-blues-losingchess-champ-rooke-article1.762264
199
Albert Silver, “Deep Blue’s Cheating Move, Chess News, 19 February 2015, https://en.chessbase.com/post/deep-blue-s-cheating-move
This is not surprising, perhaps, given that the history of fake chess playing automata, such as the Mechanical Turk, that was in fact
controlled by an dwarf operative, hidden in a cabinet underneath the chess board. Simon Schaffer, “Enlightened Automata”, in Clark et al.
(eds.), The Sciences in Enlightened Europe, Chicgao and London: University of Chicago Press, 1999, pp. 126-165
200
Gary Kasparov, ‘The Day that I Sensed a New Kind of Intelligence,” Time, No. 13, 25 March 1996
201
Gary Kasparov, Deep Thinking, Boston: PublicAffairs, 2017
198

202

Gary Kasparov in Elena Holodny, ‘One of the greatest chess players of all time, Garry Kasparov, talks about artificial intelligence and
the interplay between machine learning and humans,’ Business Insider, 24 May 2017, https://www.businessinsider.com/garry-kasparovinterview-2017-5

43

However, although the victory over Kasparov had a dramatic impact on the popular imagination, and
certainly gave IBM high profile publicity, Deep Blue did not contribute much to the development of
AI. Indeed, according to Russell, the match was essentially just a demonstration of techniques that
had been developed many years earlier: “Deep Blue is basically a demo of algorithms that were
designed 30 years earlier and had been gradually enhanced and then deployed on increasingly
powerful hardware, until they could beat a world champion.”203 The key advantage, then, was the
increase in computation power. This allowed Deep Blue to compute significantly faster, and thereby
analyse more possible moves in the game.
Jeopardy!
Following the success of Deep Blue over Kasparov, IBM decided that the next step would be to
develop a computer that could respond to everyday language.204 This led to the development of the
IBM Watson computer, named after IBM’s first CEO, Thomas J Watson. It was decided that the
popular quiz game of Jeopardy! would be the next high profile challenge.205
The problem with Jeopardy!, however, is that it is not a standard knowledge quiz where there is an
obvious answer. Rather it often uses subtle puns and wordplay, as in a cryptic crossword puzzle. As
such, the challenge is not to make a simple document search.206 Rather, the challenge is to take on a
question expressed in natural language, and attempt to understand it in great detail, so as to expose the
cryptic logic.
To do this, IBM needed to develop a question-answering computer capable of responding to natural
language. Initial research by a team led by David Ferrucci proved disappointing.207 The breakthrough
came, however, when the team developed DeepQA, a computer architecture whose operating method
is based on the sequence, ‘analyze the question, come up with candidate answers with search engines,
research these answers, and score these answers based on the evidence it found for them.’208
In the actual challenge, IBM Watson competed against two former champions, Ken Jennings and
Brad Rutter, in a two round competition, broadcast on 14-15 February 2011. Although Watson tied
203

Russell in Ford, p. 44.
David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya A. Kalyanpur, Adam Lally, J. William Murdock,
Eric Nyberg, John Prager, Nico Schlaefer, and Chris Welty, ‘Building Watson: An Overview of the DeepQA Project’, AI Magazine, Fall,
2010. http://www.aaai.org/Magazine/Watson/watson.php
205
Mike Hale, ‘Actors and their. Hal? Hal!,’ New York Times, 8 Feb, 2011. The challenge was reportedly floated at a dinner between IBM
executives, when they noticed that the occupants of an entire restaurant had shifted to be in front of television screens so that they could
watch the latest episode of Jeopardy!, a television quiz show that had captivated the popular imagination. Stephen Baker, Final Jeopardy:
Man vs Machine and the Quest to Know Everything, New York: Houghton Mifflin Harcourt, 2011, pp. 6-8.
206
Nonetheless Watson was able to draw upon a host of sources, including encyclopedias, dictionaries and literary works, although it did not
access the internet.
207
An adapted version of IBM’s existing question answering system – although good for its time – proved singularly inadequate for
Jeopardy! quiz questions. In an early test, for example, the system could only answer 62% of the questions, and only 13% of these answers
were correct. Garrish, p. 177.
208
Despite its name, DeepQA has nothing to do with deep learning. Garrish, p. 178.
204

44

with Rutter in the first round, it emerged a clear victor in the second round, winning $77,147 against
Jennings’s $24,000 and Rutter’s $21,600. Watson was awarded the overall first prize of $1 million,
Jennings the second prize of $300,000 and Rutter the third prize of $200,000. Jennings appended the
following comment to his final answer: ‘I, for one, welcome our new computer overlords,’ in a tongue
in cheek reference to the Simpsons.209
One of the advantages of IBM Watson is that its computer circuits allow it to respond to questions far
more quickly than the reflexes of human competitors. Watson also maintains its cool. As Ken Jenkins,
a human Jeopardy champion selected to compete against Watson, notes, ‘Watson cannot be
intimidated. It never gets cocky or discouraged. It plays its game coldly, implacably, always offering
a perfectly timed buzz when it’s confident about the answer.’210 At the same time, Watson needs to
understand a question in its entirety before it can answer, and is unable to guess the answer in advance.
Since that match, IBM has been exploring a number of potential applications for Watson, not least
healthcare. Indeed Watson had already hinted at its capacities in the medical field on Jeopardy! by
correctly answering the question, “You just need a nap. You don’t have this sleep disorder that can
make sufferers nod off while standing up,” with, “What is narcolepsy?”211
Following the popular success of Deep Mind and IBM Watson, it did not take long the next high
profile challenge to take place, this time involving the game of Go.
AlphaGo
The game of Go is simple enough in terms of its rules, but infinitely complicated, in that the number
of potential legal board positions is greater than the number of atoms in the universe.212 As a result, it
is a game that has long been considered one of the greatest challenges for AI.
AlphaGo is a deep learning computer program developed by DeepMind Technologies, a company
owned by Google. The program uses reinforcement learning and a Monte Carlo search algorithm, to
‘teach’ itself to play Go, by playing a vast number of matches against itself.213 The big advantage here
is that AlphaGo learns the game afresh, unconstrained by traditional thinking. As Demis Hassabis,
209

‘Watson Crowned Jeopardy King’, BBC, 17 Feb 2011, https://www.bbc.com/news/technology-12491688,; John Markoff, Computer
Wins on Jeopardy? Trivial, Its’ Not, New York Times, 16 Feb, 2011, https://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html
210
Ken Jennings, ‘My Puny Human Brain,’ Slate Magazine, Feb 16, 2011 https://slate.com/culture/2011/02/watson-jeopardy-computer-kenjennings-describes-what-it-s-like-to-play-against-a-machine.html
211
John Markoff, Computer Wins on Jeopardy? Trivial, Its’ Not, New York Times, 16 Feb, 2011,
https://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html
212
Christopher Moyer, “How Google’s AlphaGo Beat a Go World Champion,” The Atlantic, March 18 2016:
https://www.theatlantic.com/technology/archive/2016/03/the-invisible-opponent/475611/
213
Silver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian;
Antonoglou, Ioannis; Panneershelvam, Veda; Lanctot, Marc; Dieleman, Sander; Grewe, Dominik; Nham, John; Kalchbrenner,
Nal; Sutskever, Ilya; Lillicrap, Timothy; Leach, Madeleine; Kavukcuoglu, Koray; Graepel, Thore; Hassabis, Demis, ‘Mastering the game
of Go with deep neural networks and tree search,’ Nature, Volume 529, pages 484–489, 28 January 2016.

45

CEO of DeepMind, has noted: ‘Deep Blue is a hand-crafted program where programmers distilled the
information from chess grandmasters into specific rules and heuristics, whereas we’ve imbued
AlphaGo with the ability to learn, and then it’s learnt it through practice and study, which is much
more human-like.’214
However, this is perhaps a little disingenuous. AlphaGo cannot learn by deep learning alone. It should
be acknowledged that AlphaGo also has a few handcrafted features, and – like Deep Blue – was also
trained on a database of previous matches played by humans. As such, the two programs are perhaps
not quite as dissimilar as is often thought. As Russell comments:
“AlphaGo, and its successor AlphaZero, created a lot of media attention around deep learning
with stunning advances in Go and Chess, but they’re really a hybrid of classical search-based
AI and a deep learning algorithm that evaluates each game position that the classical AI
searches through. While the ability to distinguish between good and bad positions is central to
AlphaGo, it cannot play world-champion-level Go just by deep learning.”215
It was the high profile match between AlphaGo and Korean 9-Dan professional Go player, Lee Sedol,
held in Seoul, Korea in March 2016, that really put AlphaGo on the map. The match consisted of 5
games, with most Go experts – including Lee himself – predicting that the human player would win
easily. However, much to their surprise, AlphaGo won the first game, and went on to win the match
by 4 games to 1.
Game 2 proved to be the turning point. After Game 1, Lee was surprised, but after Game 2 he was lost
for words: "Yesterday, I was surprised. But today I am speechless. If you look at the way the game
was played, I admit, it was a very clear loss on my part. From the very beginning of the game, there
was not a moment in time when I felt that I was leading."216
The biggest talking point of the whole match, however, was a remarkable move played by AlphaGo in
this game:
‘In Game 2, Lee exhibits a different style, attempting to play more cautiously. He waits for any
opening that he can exploit, but AlphaGo continues to surprise. At move 37, AlphaGo plays an
unexpected move, what’s called a “shoulder hit” on the upper right side of the board. This
move in this position is unseen in professional games, but its cleverness is immediately
214

Demis Hassabis, as quoted in Sam Byford, ‘DeepMind founder Demis Hassabis on how AI will shape the future’, The Verge, 10 March
2016.
215
Russell in Ford, 2018, p. 43
216
Cade Metz, The Sadness and Beauty of Watching Google's AI Play Go, Wired, 11 March 2011.

46

apparent. [Go player] Fan Hui would later say, “I’ve never seen a human play this move. So
beautiful.”’ 217
Beautiful, beautiful, beautiful – it was a word that Hui kept repeating.218 What this move challenges is
the very nature of creativity. Moreover, it has also served to change fundamentally our understanding
of the game of Go, by introducing a number of previously unknown moves.219
“And Lee? He gets up and walks out of the room. For a moment it’s unclear what’s happening,
but then he re-enters the game room, newly composed, sits down, and plays his response. What
follows is a much closer game than Game 1, but the outcome remains the same. Lee Sedol
resigns after 211 moves.”220
It was this move that made Lee realize that AlphaGo could indeed be creative. As European Go
champion Fan Hui comments, ‘When AlphaGo chose that move, I assumed that it had made a mistake.
I immediately looked to see Lee’s reaction. At first, he seemed to smile – as though he too thought it
had made a mistake – but as the minutes rolled by it was clear that he was starting to realize its
brilliance. In fact, after the match, he said that when he saw this move he finally realised that
AlphaGo was creative.’221
Hassabis goes even further: ‘Anyone can play an original move on a Go board by simply playing
randomly. Yet a move can only be considered truly creative if it’s also effective. In that sense, Move
37’s decisive role in game two represents a move of exquisite computational ingenuity that not only
changed the game of Go forever, but also came to symbolise the enormous creative potential of AI.’222
AlphaGo deployed a long term strategy. It made a number of moves that were initially dismissed by
experts as ‘slack moves’ in that at first they did not seem to make any sense. In the longer term,
however, it became clear that these ‘slack moves’ had actually been carefully thought through, and
were setting the scene for a series of subsequent – and strategically devastating – moves. Indeed, such
was the brilliance of AlphaGo’s play, that Lee even began to question the creativity of moves made

217

Christopher Moyer, “How Google’s AlphaGo Beat a Go World Champion,” The Atlantic, March 18 2016:
https://www.theatlantic.com/technology/archive/2016/03/the-invisible-opponent/475611/
218
Cade Metz, The Sadness and Beauty of Watching Google's AI Play Go, Wired, 11 March 2011.
219
Greg Kohs (director), AlphaGo, 2017, https://www.alphagomovie.com/
220
Christopher Moyer, “How Google’s AlphaGo Beat a Go World Champion,” The Atlantic, March 18 2016:
https://www.theatlantic.com/technology/archive/2016/03/the-invisible-opponent/475611/
221
Demis Hassabis, Fan Hui, ‘AlphaGo: Moving Beyond the Rules,’ in Wood, Chloe; Livingston, Suzanne; Uchida, Maholo (eds.), AI:
More Than Human. London: Barbican International Enterprises. P. 89
222
Demis Hassabis, Fan Hui, ‘AlphaGo: Moving Beyond the Rules,’ in Wood, Chloe; Livingston, Suzanne; Uchida, Maholo (eds.), AI:
More Than Human. London: Barbican International Enterprises. P. 84

47

by humans that were previously thought to be creative: ‘AlphaGo showed us that moves humans may
have thought are creative, were actually conventional.’ 223
With that one comment, Lee forces us to reassess human creativity. The important question, then, is
not whether AI could be considered creative, but rather whether AI could be more creative than
human beings.224 Are we human beings quite as creative as we like to think we are?
As might be expected, DeepMind has since developed a series of iterations that further enhance the
performance of its Go playing computers.225 There followed a series of other models, AlphaGo Master
and AlphaGo Zero, each improving on the previous best model. AlphaGo Master went on to win 60
straight games against professional Go players within a one week period. Not to be outdone, AlphaGo
Zero reached the level of AlphaGo Master within 21 days, and was able to beat the previous best
version of AlphaGo 100-0 at the game of Go.226 What is amazing about AlphaGo Zero is not simply
the fact that it taught itself to play Go without being given any prior knowledge, but rather the speed
at which it taught itself is beyond human comprehension. It trained itself over 3 days, by playing 4.9
million games of Go against itself.227 That is a rate of almost 20 games of Go per second. This is truly
astonishing.
DeepMind then developed an all-purpose model, AlphaZero, that could play other games, such as
chess and shogi. In December 2017 AlphaZero beat the 3-day version of AlphaGo Zero at Go by 60
games to 40. It has also beaten a top Shogi program, at Shogi, and Stockfish, a top chess program, at
chess.228 More recently, AlphaStar has achieved grandmaster status at Starcraft 2, a video game that is
reputed to be even more complex than Go, in that some of the opponent’s pieces are hidden from
view.229 Alphastar uses multi-agent reinforcement learning.

223

Greg Kohs (director), AlphaGo, 2017, https://www.alphagomovie.com/
The question is also thrown into relief, as we shall see, by architectural designs generated by AI that expose the limitations of those
designed by humans. See p. xxxxxxx
225
The AlphaGo project actually consisted of a series of variations of the same program, starting with the initial AlphaGo version used in a
match against European Go champion, Fan Hui, in October 2015, then improved to AlphaGo Lee for a match against Sedol in March 2016.
226
Demis Hassabis, David Silver, ‘AlphaGo Zero: Learning from Scratch’, 18 October 2017, https://deepmind.com/blog/article/alphagozero-starting-scratch
227
Merritt Kennedy, ‘Computer Learns to Play Go at Superhuman Levels ‘Without Human Knowledge’’, The Two Way, 18 October 2017,
https://www.npr.org/sections/thetwo-way/2017/10/18/558519095/computer-learns-to-play-go-at-superhuman-levels-without-humanknowledge
228
David Silver, Thomas Hubert, Julian Shrittwieser, Ioannis Antonoglu, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan
Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis, ‘Mastering Chess and Shogi by Self-Play with a General
Reinforcement Learning Algorithm,’ 5 December 2017, https://arxiv.org/abs/1712.01815
229
The AlphaStar Team, ‘AlphaStar: Grandmaster level in StarCraft II using multi-agent reinforcement learning.’ DeepMind Blog, 30
October 2019, https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning
224

48

The time has long gone when human beings might expect to beat AI at a game of Chess or even Go.
And what became of Lee himself? He retired from professional Go in November 2019, on the basis
that he would never be able to beat AI in the future: “This is an entity that cannot be defeated.”230
Here we have three different reactions from three different human beings who have been beaten by AI.
Kasparov puts a positive spin on his defeat, calling it a triumph for human beings. Ken Jennings
welcomes his ‘new computer overlords’. But after conceding defeat in the match, Lee eventually
decides to also concede defeat in his career.
Is this a presage of the future? Will we all eventually come to acknowledge the superior intelligence
of AI? Or will we fail to even recognise it, much like the ‘slack moves’ of AlphaGo, because the
intelligence of AI is beyond our comprehension? In short, is AI going to make us completely
redundant, whether or not we realise it?
Sputnik Moment
A match of Go taking place in South Korea involving a professional player largely unknown in the
West, playing a game almost unheard of in the West, could hardly be expected to create much of a
stir, except perhaps within the AI community. It could be argued, however, that this match proved to
be one of the most significant events in the entire history of AI.
In China AlphaGo’s triumph over Lee was an event that triggered a huge interest in AI. After all, the
game of Go was invented in China more than 3000 years ago, and remains hugely popular there. The
Chinese nation was clearly transfixed by the match. There was an estimated television audience of
280 million for this event, a significant proportion of which were in China. 231 And the victory of
AlphaGo over Lee sent a seismic shock through the whole nation. The impact of the match on China
should not be understated. It was a huge wake up call for them. As Lee notes, ‘Overnight, China
plunged into an artificial intelligence fever.’232 In what has been described by Kai-Fu Lee as China’s
‘Sputnik Moment’, the Chinese government realized after the match that it was lagging behind the
West in a technology that held vast potential. 233 The original ‘sputnik moment’ was, of course, the
moment when the States was jolted into action in the Space Race, after being seriously embarrassed
by the success of the Soviet Union in launching a satellite into space. 234

230

‘Go master Lee says he quits unable to win over AI Go players,’ Yonhap News Agency, 27 November 2017,
https://en.yna.co.kr/view/AEN20191127004800315
231
Greg Kohs (director), AlphaGo, 2017, https://www.alphagomovie.com/
232
Lee, 2018, p. 3.
233
Tom Simonite, ‘Tencent Software Beats Go Champ, Showing China's AI Gains,’ Wired, 23 January 2018. https://www.wired.com/story/tencentsoftware-beats-go-champ-showing-chinas-ai-gains/
234
As NASA observes, ‘In general, Kennedy felt great pressure to have the United States “catch up to and overtake” the Soviet Union in the
“space race.” Four years after the Sputnik shock of 1957, the cosmonaut Yuri Gagarin had become the first human in space on April 12,
1961, greatly embarrassing the U.S. While Alan Shepard became the first American in space on May 5, he only flew on a short suborbital

49

The Chinese government promptly decided to initiate an ambitious and rapid program of investment
in AI.235 On 18 October 2017 – a year and a half after the match – Chinese President Xi Jinping
announced a new plan for China to invest in AI with a view to overtaking the States in AI
development by 2030.236 Kai Fu-Lee astutely observes, “If AlphaGo was China’s Sputnik moment,
the government’s AI plan was like President John F. Kennedy’s landmark speech calling for
America to land a man on the moon.”237 In fact some have argued that China has already surpassed
the States, if judged on the basis of the number of articles published on AI, and looks set to claim
the top spot for most cited papers by 2025.238
If, then, the original sputnik moment in the States led to the Space Race that was itself a manifestation
of the Cold War, would not the second sputnik moment in China lead to the AI race, which is itself a
new form of Cold War? “No,” says Lee, “this is not a new Cold War.”239 Although AI can be used for
military purposes, its true value lies in opening up to a new technology that will surely benefit the
whole of humanity. Instead of the Cold War, the comparison should be with the Industrial Revolution
or the invention of electricity. But it most certainly was, as Lee so aptly observes, both a ‘game’ and a
‘game changer’, at least as far as China was concerned.240
The match also had a significant impact on AI funding in South Korea. On 17 March – just 2 days
after the match – the South Korean government pledged 1 trillion won ($863 million) into research in
AI over the next 5 years. South Korean President Park Geun-Hye expressed her gratitude for the
match, “Above all, Korean society is ironically lucky, that thanks to the ‘AlphaGo shock’, we have
learned the importance of AI before it is too late.”241
AI and Visibility

flight instead of orbiting the Earth, as Gagarin had done.’ As quoted in Neil Leach, ‘Terrestrial Feedback’, in Leach (ed.), ‘Space
Architecture: The New Frontier for Design Research, AD, Profile No 232, Nov/Dec 2014.
235
Paul Mozur comments, ‘The two professors who consulted with the government on A.I. both said that the 2016 defeat of Lee Sedol, a
South Korean master of the board game Go, by Google’s AlphaGo had a profound impact on politicians in China. . . As a sort of Sputnik
moment for China, the professors said, the event paved the way for a new flow of funds into the discipline.’ Paul Mozur, ‘Beijing Wants A.I.
to Be Made in China by 2030’, New York Times, 20 July 2017, https://www.nytimes.com/2017/07/20/business/china-artificialintelligence.html
236
Nicholas Thomson, Ian Bremner, ‘The AI Cold War That Threatens Us All, ‘ Wired, 23 October 2018. https://www.wired.com/story/ai-coldwar-china-could-doom-us-all/
237
Fu-Lee continues: ‘When the Soviet Union launched the first human-made satellite into orbit in October 1957, it had an instant and
profound effect on the American psyche and government policy. The event sparked widespread US public anxiety about perceived Soviet
technological superiority, with Americans following the satellite across the night sky and tuning into Sputnik’s radio transmissions. It
triggered the formation of the National Aeronautical Space Administration (NASA), fueled major government subsidies for math and
science education, and effectively launched the space race.’ Kai-Fu Lee, AI Superpowers: China, Silicon Valley and the New World Order,
New York: Houghton Mifflin Harcourt, 2018.
238
Carissa Schoenick, ‘China May Overtake US in AI Research’, Medium, 13 March 2019.
https://medium.com/ai2-blog/china-to-overtake-us-in-ai-research-8b6b1fe30595
239
Lee, 2018, p. 227.
240
Lee, 2018, p. 4.
241
Mark Zastrow, ‘South Korea trumpets $860-million AI fund after AlphaGo 'shock'’, Nature, 18 March 2016. https://www.nature.com/news/southkorea-trumpets-860-million-ai-fund-after-alphago-shock-1.19595

50

The history of AI can be read as a history of visibility and invisibility. Most people are largely
unaware of AI, and have little understanding of what it does. And often even those who do understand
what it actually does, do not understand quite how it does it – as in the case of deep learning.
Such is the low profile of AI that it takes a high profile event to bring it to our attention. This could be
a news headline comment by a famous figure, such as Stephen Hawking or Elon Musk. Or it could be
a competition staged screened on television. And it is these moments of great visibility that really
capture the public imagination. The match between Lee and AlphaGo was not only watched by a vast
TV audience, but it also became the subject of an award-winning documentary, AlphaGo.242 By
comparison, almost no one has heard of the subsequent match between AlphaGo Master and Ke Jie,
the actual world champion. This second event was not promoted in the media in quite the same
way.243 In fact, perhaps the most spectacular achievement of all is that of the development of
AlphaZero, a program that trained itself entirely using reinforcement learning – an extraordinary feat
that that has passed by largely unnoticed. In short, AI has gone largely unnoticed by most people,
except for a series of high profile moments.
Just as AI itself is invisible, so research on AI passes largely unnoticed by the general public. In some
cases this is because there can be sound business reasons not to divulge information about research
that is still ongoing. However, in most cases the ‘invisibility’ of research into AI is simply down to
the fact that it is either not sufficiently interesting or accessible to the general public to be covered by
the press. From the perspective of the media, an event is not an event unless it is newsworthy.
Likewise, from the perspective of the general public, an event is not an event unless it is covered by
the media. The same principle applies to the many people beavering away behind the scenes who
have helped to make AI what it is today. Visibility is everything.
These high profile events might be entertaining. But the real intention behind them is to showcase AI
and raise awareness of its commercial potential, so as to impress would-be financial backers. In so
doing the invisible logic of AI is made visible. It is simply a question of marketing. Nor should we
forget that – in terms of marketing – AI itself is working invisibly ‘behind the scenes’, feeding us
advertisements for products that our previous search record suggests that we might find appealing.
Advertising by stealth.
Potentially more disconcerting, however, is the opposite tendency of using AI for branding purposes,
even when little or no AI is actually being used. For example, Hansen Electronics has been marketing
242

Cade Metz, ‘The Sadness and Beauty of Watching Google’s AI Play Go,’ Wired, 11 March 2016.
https://www.wired.com/2016/03/sadness-beauty-watching-googles-ai-play-go/
243
Demis Hassabis, Fan Hui, ‘Exploring the Mysteries of Go with AlphaGo and top Chinese Go Players,’ DeepMind Blog Research, 10
April 2017, https://deepmind.com/blog/article/exploring-mysteries-alphago

51

a humanoid robot, Sophia, with some success. Sophia not only looks human – much like the
replicants in Blade Runner, also an artificial life form – but is also presented as though ‘she’ thinks
like humans. In October 2017, Sophia became the first robot to be made a citizen of Saudi Arabia.244
And in November 2017 ‘she’ became the first robot to be named ‘Innovation Champion’ by the
United Nations Development programme.245 Sophia has been marketed as though it is a conscious,
sentient being. But in fact Sophia is anything but conscious, and has been decried by the AI
community. For Rodney Brooks, Sophia is ‘completely bogus and a total sham’ while, for Benedict
Evans, Sophia is little more than ‘a tape recorder with a rubber head on it’.246
Few would be fooled into believing that Sophia is a human being.247 But this is not the issue here.
While the Turing test is designed to test whether a computer can successfully masquerade as a
sentient human, Sophia is an automaton masquerading as AGI – a sentient robot. And the purpose of
this masquerade is to impress the general public, and to promote Hansen Electronics. Never
underestimate the power of AI to excite the general public. As Maria Dantz of Spacemaker AI
comments, ‘AI is certainly something that opens doors, because people want to hear about it.’ 248
Likewise – despite its name – the architectural practice, AI Space Factory, does not actually use AI in
any of its design and fabrication processes at the time of writing, even though it has plans to do so in
the future.249 While AI can be very good at detecting spam and other forms of marketing, it can also
be exploited in marketing. Should we be suspicious of any company with AI in its name?
This is the logic of ‘inverse camouflage’. If the logic of camouflage is to pretend something is not
there, when it is – making the visible invisible – the logic of inverse camouflage is to pretend that
something is there, when it is not. It is a question of making the visible invisible, versus making the
invisible visible. But could inverse camouflage not be a cunning marketing strategy – ‘marketing the
invisible’? Who is to know whether AI is being used or not? Might these companies pass their own
inverse Turing test, in persuading the general public that they are using AI when they are not?
In the age of AI, what is AI but the ultimate marketing opportunity?

244

Chris Weller, ‘Meet the first-ever robot citizen – a humanoid robot named Sophia that once said that it would ‘destroy humans’, Business
Insider, 27 October 2017. https://www.businessinsider.com/meet-the-first-robot-citizen-sophia-animatronic-humanoid-2017-10?r=UK
245
‘UNDP in Asia and the Pacific Appoints World’s First Non-Human Innovation Champion’, UNDP Asia and the Pacific, 22 November
2017.
246
Sinapayen, Lana. 2018. ‘Sophia the Robot, More Marketing Machine than AI Marvel.’ Skynet Today, November 20, 2018.
https://www.skynettoday.com/briefs/sophia
247
In the past there have been examples of people masquerading as an automaton, as in the case of the Mechanical Turk an ‘automaton’ that
was actually operated by a chess-playing dwarf hidden underneath. Tom Standage, The Turk: The Life and Times of the Famous EighteenthCentury Chess-Playing Machine, New York: Walker, 2002.
248
Zoom conversation, 6 May 2020.
249
This was revealed to me by David Mallard, CEO of AI Space Factory, at a conference in Shanghai in September 2019.
https://www.aispacefactory.com/

52

Beware the AI of marketing!250

250

This is a reference to the famous expression, ‘Beware the Ides of March!’, from the play by Shakespeare, Julius Caesar, Act 1, Scene 2
(1599). http://www.online-literature.com/shakespeare/julius_caesar/3/

53

Chapter 3
AI, Art and Creativity
As the daughter of the poet, Lord Byron, Ada Lovelace was no stranger to creativity. She describes
the Analytical Engine proposed by Charles Babbage in highly poetic terms: ‘The analytical engine
weaves algebraic patterns, just as the Jacquard loom weaves flowers and leaves.’251 In fact Lovelace
believed that the Analytical Engine would even be capable of composing music. She notes,
‘Supposing, for instance, that the fundamental relations of pitched sounds in the science of harmony
and of musical composition were susceptible of such expression and adaptations, the engine might
compose elaborate and scientific pieces of music of any degree of complexity or extent.’252 However,
Lovelace added that the Analytical Engine could only do what it was programmed to do, ‘The
Analytical Machine has no pretensions whatsoever to originate anything. It can do whatever we know
how to order it to perform. It can follow analysis, but it has no power of anticipating any analytical
revelation of truths. Its province is to assist us in making available what we are already acquainted
with.’253 Her point here is that a machine, such as the Analytical Engine, would be incapable of
originating anything. Any creativity would have to come from the programmer.254 But is this really
the case?
Turing begins his famous article, ‘Computing Machinery and Intelligence,’ with the question, ‘Can
Machines Think?’255 In fact Turing speculates that eventually machines should be able to do anything
that a human can do, to the point that they should be able to write sonnets:
‘We have to have some experience with the machine before we really know its capabilities. It
may take years before we settle down to the new possibilities, but I do not see why it should not
enter any one of the fields normally covered by the human intellect, and eventually compete on
equal terms. I do not think that you can even draw the line about sonnets.’256
Turing is confident, however, that machines can learn. Before machine learning had even been
contemplated, Turing speculates on the possibility of machines learning, correctly surmising that we
might not know how the process happens: “An important feature of a learning machine is that its

251

Ada Lovelace, Notes (on the Analytical Engine), 1843.
Ibid.
Teri Perl, The Ladies Diary or Woman's Almanac, 1704-1841, Historica Mathematica 6 (1979): 36-53
254
For further discussion on this, see Marcus du Sautoy, The Creativity Code: Art and Innovation in the Age of AI, Camb., MA: Belknap
Harvard, 2019
255
This, of course, is an open question. We have no answer to it as yet. And much depends on whether ‘thinking’ involves consciousness. If
it does, then machines cannot literally think, at least until we reach AGI. Alan Turing, October 1950, "Computing Machinery and
Intelligence", Mind, LIX (236): 433–460.
256
Turing adds an interesting qualification, surmising that human beings might not be able to fully appreciate these sonnets: ‘Though the
comparison is perhaps a little bit unfair, because a sonnet written by a machine will be better appreciated by another machine.’ Dermot
Turing, Prof: Alan Turing Decoded, Norwich: Pitkin Publishing, 2015 https://quoteinvestigator.com/2019/10/12/ai-shadow
252
253

54

teacher will often be very largely ignorant of what is going on inside.”257 Indeed, as Turing also notes,
machines can produce surprising results, “Machines take me by surprise with great frequency.”258
Computers can also produce novelty, as Richard and Daniel Susskind observe: ‘Contrary to
widespread belief, machines are now capable of generating novel outcomes, entirely beyond the
contemplation of their original human designers.’259 Clearly computers can learn, be innovative and
even perhaps compose sonnets. But can they be genuinely creative?
The general consensus would seem to hold that computers cannot be genuinely creative, and
creativity is often cited as one of the realms where AI is relatively weak. In this they are echoing the
argument of Lovelace, that computers can only do what they were programmed to do. They cannot
initiate anything. Much depends, however, on how we understand creativity. Can we say that a
computer is creative, for example, when it has no consciousness, and does not even ‘realise’ that it is
being creative? When it comes to generating art, Melanie Mitchell goes further, and argues that it is
also important to be able to appreciate the art that has been produced, and this is not something that
AI – for the moment, at any rate – is able to do, as AI does not have consciousness.260 As such,
Mitchell does not believe that AI can be creative.261
For sure, it is clear that AI is capable of generating novel outputs. It is also capable of recognizing
patterns, and extrapolating further material based on those patterns. But can AI also produce art?262

A Brief History of AI Art
There is an interesting comparison to be made between traditional patrons of art and contemporary
tech companies. In the past institutions such as the Church or established banking families, such as the
Medici family in Florence, Italy, supported and sponsored artists and sculptors, like Michelangelo. In
the present, however, tech companies, such as Amazon, Microsoft, Apple and Google, increasingly
play that role. It is a role that should not be underestimated.

257

Alan Turing, ‘Computing Machinery and Intelligence’, Mind, LIX, 236, 433-460, 1950.
ibid. The unpredictability of computers is potentially the biggest dangers of using machine learning algorithms lie. As Memo Akten
observes, ‘This is precisely where potentially the biggest dangers of using machine learning algorithms lie. Especially with regards
to algorithmic decision making in critical situations, and partly why we’re having the problems we have today — because we’re unable to
predict how the trained algorithms might behave, and we can’t hold them accountable. But simultaneously, this is also the biggest advantage
of machine learning systems. This is how machines can potentially help propel us to new places, to make us see things that we otherwise
wouldn’t be able to see.’ Memo Akten, ‘Retune 2016, Part 2: Algorithmic Decision Making, Machine Bias, Creativity and Diversity,’
Medium, 14 October 2016. https://medium.com/@memoakten/retune-2016-part-2-algorithmic-decision-making-machine-bias-creativityand-diversity-3c7cca21ba37
259
Richard Susskind, Daniel Susskind, The Future of the Professions: How Technology will Transform the Work of Human Experts, Oxford:
Oxford University Press, 2015, p. xi
260
Melanie Mitchell, Artificial Intelligence: A Guide for Thinking Humans, New York: Farrar, Straus and Giroux, 2019, p. 272.
261
The question of consciousness in relation to extended intelligence is addressed further in the next chapter.
262
At the time of writing, when asked the question, ‘Alexa, would you say that you are creative?’ Alexa replies, ‘Sorry. I’m not sure.’
258

55

Recently, Blaise Agϋera y Arcas, a software engineer with an interest in machine vision, set up a
group within Google, Artists and Machine Intelligence (AMI), that explores the potential applications
of machine intelligence within the realm of art. Arcas asks,
‘What do art and technology have to do with each other? What is machine intelligence, and what
does “machine intelligence art” look, sound and feel like? What are the emerging relationships
between humans and machines; what does it mean to be human; and what can we learn about
intelligence, human or otherwise, through art? How should we think about our future?’263
In March 2018 Google AMI held an exhibition in San Francisco in collaboration with the Gray Area
Foundation. The exhibition was of DeepDream generated art, and was quite possibly the first ever
exhibition of AI generated art. In his opening address, Arcas was keen to emphasize that this was not
an experiment to explore whether DeepDream would be accepted by the art community.264 He was
more confident than that: “We believe machine intelligence is an innovation that will profoundly
affect art.”265 AI is proving an increasingly popular medium for artists, even though there is still
significant resistance to it within more conservative art circles. 266
Then, later in 2018, Edmund de Belamy, a portrait generated by the Paris-based art collective,
Obvious, using Creative Adversarial Networks [CANs], was auctioned at Christie’s for the
remarkable sum of $432,500, almost 45 times the initial estimate, becoming the first AI generated art
work to be sold at auction.267 This caused outrage among some, not because it was an artwork
generated by AI, but rather because Obvious had not written the training algorithms or the data set.268
They had simply tweaked algorithms available on an open course website, and exploited the results.
Significantly, it has been found that human beings are incapable of distinguishing artworks created by
CANs from artworks created by artists. As such, it would appear that CANs are capable of passing the
Turing Test. But is this not the very purpose of GANs themselves? If the intention of the
generator/artist in a GAN is to produce an image that a discriminator/critic would think is real, is that
not precisely what CAN is doing in generating an artwork? In effect we have the Turing Test being
played out every time that a GAN – of whatever kind – is initiated. Whereas the Turing Test is about
fooling the judge, a GAN is about fooling the art critic. Perhaps the only real difference between what
263

Blaise Agϋera y Arcas, ‘What is AMI?’, Medium, 23 February 2016, https://medium.com/artists-and-machine-intelligence/what-is-ami96cd9ff49dde
264
For an overview of artists using AI see: https://aiartists.org/
265
Alex Rayner, ‘Can Google’s Deep Dream become an art machine?’, Guardian, 28 March 2016,
https://www.theguardian.com/artanddesign/2016/mar/28/google-deep-dream-art
266
Joanna Zylinska, AI Art: Machine Visions and Warped Dreams, London: Open Humanities Press, 2020, p. 50
267
Is artificial intelligence set to become art’s next medium? https://www.christies.com/features/A-collaboration-between-two-artists-onehuman-one-a-machine-9332-1.aspx
268
James Vincent, ‘How Three French Students used Borrowed Code to Put the First AI Portrait in Christie’s, The Verge, 23 October 2018.
https://www.theverge.com/2018/10/23/18013190/ai-art-portrait-auction-christies-belamy-obvious-robbie-barrat-gans

56

happens with the Turing Test and a GAN is that the GAN can learn from its mistakes and improve its
performance until such time as it succeeds, whereas in the Turing Test there is no opportunity for the
machine to improve and be reappraised.269
Another landmark in terms of the impact of AI on to the world of art was also reached that year, when
Mario Klingemann was awarded the Lumen Prize Gold Award for his work, The Butcher’s Son, also
generated using GANs.270 This is the first time that a major international art prize has been awarded to
an artwork generated by a machine. As Klingemann notes, ‘This image has been generated entirely by
a machine using a chain of GANs. In this chain a randomly generated stick-figure is used as an input
to the first GAN, which produces a painterly-looking low-resolution proto-image. In several steps, the
low resolution image is ‘transhanced’ and upscaled by another GAN increasing the resolution and
adding details and textures. I control this process indirectly by training the model on selected data sets,
the model’s hyperparameters and eventually by making a curatorial choice, by picking among the
thousands of variations produced by the models the one that speaks to me most.’271
The following year, in 2019, the first ever solo exhibition for AI art took place in the HG
Contemporary gallery in Chelsea, New York. The ‘artist’ was Ahmed Elgammal, a computer scientist
and the developer of CANs. Elgammal has now established his own art and artificial intelligence
laboratory, to produce art through a process he now calls AICAN.272 AI scientists, it would seem, are
now more street savvy and willing to cash in on the possibilities afforded by their inventions. As
Bogost puts it, ‘The AI-art gold rush is here.’273
Who Needs Gauguin?
GauGAN is a real time AI art application developed by Nvidia that synthesizes photorealistic images
from diagrammatic sketches.274 As its name implies, it evokes the potential of Paul Gauguin, the
French Impressionist painter, to create paintings that can now be simulated by style transfer
techniques. But what makes GauGAN so special is that it can create photorealistic landscape images
from crude initial brush strokes in real time. It is trained on over a million actual landscape images.

269

It could also be argued, however, that AI could fail the Turing Test if it shows itself to be too knowledgeable and to display a level of
knowledge beyond what might be expected of a human being. Hussan Hamden, “Both Turing Test and GAN Attempt to Fool a Judge,” 1
November 2019, Medium, https://medium.com/@hamdan.hussam/both-turing-test-and-gan-attempt-to-fool-a-judge-7391665ffca2
270
https://lumenprize.com/artwork/the-butchers-son/
271
Martin Dean, “Artist Mario Klingemann on Artificial Intelligence, Technology and our Future” (interview with Mario Klingemann),
Sotheby’s, 25 February 2019, https://www.sothebys.com/en/articles/artist-mario-klingemann-on-artificial-intelligence-art-tech-and-ourfuture
272
Art and Artificial Intelligence Laboratory at Rutgers: Advancing AI Technology in the Digital Humanities,
https://sites.google.com/site/digihumanlab/home
273
Ian Bogost, ‘The AI-Art Gold Rush is Here’, Atlantic, 6 March 2019
274
Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu. "Semantic Image Synthesis with Spatially-Adaptive Normalization",
in CVPR, 2019. https://arxiv.org/pdf/1903.07291.pdf

57

GauGAN has been lauded within the AI community, and received two major awards, ‘Best of Show’
and ‘Audience Choice’ at SIGRRAPH 2019. 275 The program is undeniably impressive and highly
sophisticated from a technical perspective, but its potential applications within the world of art are
unclear. Nvidia researcher, Gavril Klimov, who was part of the development team, tries to sell its
virtues: ‘“As an artist it’s extremely valuable to be able to generate content quickly because artists
need to iterate fast. GauGAN allows us to generate our ideas at a speed that was previously not
possible, and this will become a main tool for artists to use in the future.”276 The point here is that the
results are so astonishingly photorealistic, that they undercut precisely the contribution that hitherto
artists have been able to make. The question is not so much, “Why spend months on a painting, when
you can generate one in real time?” so much as, “Who needs Gauguin, when you have GauGAN?”
Surely those to whom it would appeal most would be non-artists, or at least those incapable of
painting like Gauguin. In some senses, one might even argue that GauGAN might be best suited to
those interested in producing fakes, given the history of the production of fake paintings within the art
world. Of course, in the hands of the right artist, such a technique might be open to extraordinary
inventive potential as a prosthetic extension of the artistic imagination. Here I am not referring to the
simple primary applications envisioned by the developers of GauGAN, so much as a range of as yet
unimagined open secondary applications invented by the artistic community.277 Nonetheless, the
question remains as to whether true artists would ever want to use such a tool, at least in the
straightforward manner that immediately presents itself. It would seem highly unlikely that an artgenerating product would appeal to artists themselves. Who needs GauGAN, when you have
Gauguins?
But who is the Author?
From a technical perspective it is clearly possible to use AI to generate art works of a high enough
standard to win major art prizes, and be auctioned at some of the world’s most important auction
houses. At the same time, the introduction of AI generated art works provokes a number of interesting
challenges for the art world. The incursion of AI into the art world echoes the invention of
photography. In many ways, the challenge that photography made to painting – and the outcry that it
caused – offers an interesting parallel to the challenge that AI now poses to art. Arcas refers to this,
and predicts that some will reject the possibility of AI ever producing anything that could be regarded
as art:

275

‘GauGAN Wins Major Awards at SIGGRAPH 2019’s Real Time Live Competition,’ Nvidiia Developer News Center, 30 July 2019,
https://news.developer.nvidia.com/gaugan-wins-major-awards-at-siggraph-2019s-real-time-live-competition/
276
‘GauGAN Wins Major Awards at SIGGRAPH 2019’s Real Time Live Competition,’ Nvidiia Developer News Center, 30 July 2019,
https://news.developer.nvidia.com/gaugan-wins-major-awards-at-siggraph-2019s-real-time-live-competition/
277
The parallel here is with the simple mobile phone. Intended initially for wealthy business men, the mobile phone became a viable product
from a marketing perspective once those business men started giving phones to other family members so that they could call them and have
them pick them up in the evening.

“Now, you go out in the world alone, and I can trust you that you can keep on doing what I
hoped that you would do, even if I am not sitting next [to you] and still able to change
something. So that is kind of like a hard moment for me to say, “Now I believe it’s okay to take
my hands off the keyboard, and let it out in the world.””286
And so, is Klingemann responsible for the artwork, or has he delegated all responsibility to the
machine? One way to answer this question might be to reflect on how artists have always operated.
Indeed, we should perhaps question whether the standard training at any art school is so different.
Every artist graduating from an art school has been trained – schooled – in an educational system that
arguably exerts greater influence than the traditionally liberal-minded art world would wish to admit.
How is this so different from the way a neural network is trained? Meanwhile, could we not also
argue that this is no different to the ateliers of the past? After all, many leading artists would delegate
much of their work to apprentices, and expect them to complete it in the style of the master.
This is also not so dissimilar to contemporary architectural practices where a number of junior
architects and interns are employed to produce designs in the manner of that practice. Thus, for
example, Zaha Hadid established a certain, highly recognisable aesthetic that has now become the inhouse ‘style’ for Zaha Hadid Architects (ZHA), and those working for ZHA have to work within
those aesthetic constraints, even though Hadid herself has passed away. Likewise, we have seen how
AI can hallucinate new ZHA-like designs based on a dataset of previous ZHA designs. How would
this be any different to Klingemann and his ‘children’ being unleashed into the world to ‘paint’ in a
manner in which they were ‘trained’?
Rethinking Creativity
Up until now the dominant tradition has been to judge creativity in terms of the end product. This is
based largely on the thinking of Margaret Boden, who has drawn up a series of categories by which to
classify creativity. Boden distinguishes between what she calls psychological creativity (P-creativity)
and historical creativity (H-creativity).287 P-creativity could be defined as something novel in terms of
the person who created it, whereas H-creativity refers to something that has been created for the first
time in history.
Boden further divides creativity into three distinct ‘types’ or genres of creativity – combinational,
exploratory and transformational.288 Combinational creativity ‘produces unfamiliar combinations of



Boden, Margaret, ‘Computer Models of Creativity.’ AI Magazine, 2009, p. 24.
Marcus du Sautoy also subscribes to Boden’s three types of creativity, Marcus du Sautoy, The Creative Code: Art and Innovation in the
Age of AI, Camb., MA: Belknap Harvard, 2019, pp. 7-15.
288

61

familiar ideas, and works by making associations between ideas that were only indirectly linked.’289
For Boden collage would be an example of combinational creativity. Exploratory creativity,
meanwhile, is based on a culturally accepted style of thinking, or ‘conceptual space’, defined by a set
of generative rules. Painting, architecture and music, and artistic production in general, would be
examples of exploratory creativity, and Boden cites a shape grammar study of the works of Frank
Lloyd Wright, which suggested many other possible designs that could have been produced. 290
Importantly, for Boden, exploratory creativity can also lead to transformational creativity.291 Finally,
in transformational creativity, ‘the space or style is transformed by altering (or dropping) one or more
of its defining dimensions.’292 Science offers some of the best examples of transformational creativity,
where paradigmatic shifts in knowledge can occur. This can lead to surprising – or even shocking –
results, as something might have been generated that could never have been previously imagined.
According to Boden, then, creativity can be categorized according to its ‘type’ or genre. However, the
three categories of creativity that Boden lists – combinational, exploratory and transformational –
appear to be more like creative strategies, than creativity itself. Architect, Thom Mayne, for example,
deploys what he calls ‘combinatorial design’ in the architectural design process. This sounds similar
to Boden’s notion of ‘combinational creativity’. But for Mayne this is not a form of creativity as such,
but simply a design strategy. Nor does a design strategy guarantee creativity. Boden claims, for
example, that collage is an example of combinational creativity, and collage is certainly an artistic
strategy, but an artwork generated using collage might not necessarily be so creative.
There appear to be a number of shortcomings, then, in Boden’s approach. Boden seems to categorize
creativity in terms of the outcome. But should we not understand creativity in terms of the process of
creation itself? Creativity might well be involved in generating a design, but creativity, surely, is what
feeds that process. Indeed, for many designers creativity is a question of how the design process
unfolds in relation to the affordances of the materials and tools being used.293 What applies to design,
clearly also applies to all fields of creativity. As Ben Ceverny comments, ‘Sculpture is not in the
result. The sculpture is in the process.’294 It makes little sense, then, to judge creativity in terms of the
outcome of that process. This would be akin to judging a building in terms of its ‘style’.295 IndeedBoden uses the term ‘style’ frequently in her discussion of creativity.296 An historian or an outside
commentator might judge a work in terms of the outcome, but for the designer creativity is expressed,
surely, in the very process of design.297
Boden’s approach, then, tends to reduce creativity to a limited range of outcomes. But should not
creativity be understood as a pervasive sensibility that is infused throughout the behaviour of a
creative individual, and expressed in various ways? Would creative individuals not express their
creativity in every facet of their existence, from the way that they dress and behave, through to the
actual works that they produce? Besides, we are never likely to fully comprehend the nature of the
creative process, since, as Arthur Miller has argued, much of it belongs to the realm of the
unconscious.298 Indeed, for Freud, fantasies can be expressed in sublimated form in the creative act.299
The creative individual might therefore be unaware of what is influencing the creative process.300
Moreover, we must at least challenge the notion that creativity can be judged in such an objective
fashion. Who is in a position to even judge creativity? And what if a creative act is not recognised by
that judge?301 Could we not say that van Gogh was creative, even though his creative abilities were
not recognised in his lifetime? And how are we to appraise the creativity of Move 37 in the match
between Lee Sedol and AlphaGo, if the creativity of that move is not even recognised until much later?
Might we draw a distinction between human creativity and absolute creativity, just as we have drawn
a distinction between human intelligence and absolute intelligence? Does creativity, perhaps, lies in
the eye of the beholder? Or does creativity exist in the mind of the creative individual? In order to
fully understand the creative process, should we not take into account the background sensibilities and
aspirations that feed into that process? And does it even make sense to distinguish between Pcreativity and H-creativity? What if an individual creates something without knowing whether
someone else has created it before? In short, is it not time to revisit the question of creativity?
Here is not the place, however, to offer a comprehensive redefinition of creativity. The issue of
creativity is a highly complex one – even more complex, as Anil Seth has observed, than the thorny
problem of consciousness itself.302 And yet, even if we are not yet in a position to redefine creativity



in any meaningful way, we can at least ask some provocative questions that challenge previously held
assumptions about creativity.
In the Mirror of AI
Digital simulations can often help us to understand analogue behaviours. For example, it was not until
Craig Reynolds had produced a digital model for the flocking behaviour of birds using ‘boids’, that
we were able to understand the behaviour of actual birds.303 This is not to say that AI would serve as a
‘digital model’ of human intelligence – since, for the moment at least, AI cannot track the human
brain – but nonetheless the principles that govern AI might offer some clues about the principles that
govern human intelligence. Could AI, then, provide us with a mirror in which to understand certain
aspects of human intelligence, such as learning, consciousness and even creativity itself?
Take a neural network. Although modelled only loosely on the brain, a neural network might help us
to understand how the brain actually works. Both are black boxes, in that we know that they work, but
do not fully understand how they work. But might they share certain similarities? Might the brain, for
example, also perform some form of backpropagation, as Geoffrey Hinton speculates? 304 After all,
although it had previously been assumed that the synapses in the brain operate in only one direction –
feed forward – it has now been argued that they might operate in both directions – both feed forward
and feed backwards.305 And could this principle allow the brain to critique or correct itself, just as
backpropagation allows for the neural network to correct errors? Even if the brain does not operate in
exactly the same way, it seems to be doing something similar. As Joshua Bengio observes,
“Backpropagation works incredibly well, and it suggests that maybe the brain is doing something
similar – not exactly the same, but with the same function.”306
Or let us take the logic of DeepDream. From an architectural perspective, what makes DeepDream so
fascinating is that the technique of ‘inverting the network’ reverses the flow of a neural network.
Instead of interpreting or critiquing an image, a neural network can now generate an image. What
implications might this have for architectural culture? Take the distinction between the architectural
critic and architectural designer. Typically, the architectural critic tends to be more critical, while the
architectural designer tends to be more capable of generating forms. Does the reversal in direction of
operation suggest that the process of architectural criticism is – in some senses – the opposite to the



Craig Reynolds, ‘Flocks, Herds, and Schools: A Distributed Behavioral Model’, Computer Graphics, 21(4), July 1987, pp. 25-34.
Geoffrey Hinton, ‘Can the Brain do Backpropagation?’ Stanford Seminar, YouTube video uploaded 28 April, 2016.
https://www.youtube.com/watch?v=VIRCybGgHts
305
Boden, pp. 90-91. This principle has opened up a new research initiatives, by neuroscientists such as Anil Seth, who argue for the
principle of predictive perception, whereby the brain depends as much on prediction from the inside out, as it does on receiving images from
the outside in. Seth, Anil K. “A predictive processing theory of sensorimotor contingencies: Explaining the puzzle of perceptual presence
and its absence in synesthesia.” Cognitive neuroscience vol. 5,2 (2014): 97-118. doi:10.1080/17588928.2013.877880; Andy Clark, Surfing
Uncertainty: Prediction, Action and the Embodied Mind, Oxford: Oxford UP, 2016
306
Bengio in Ford, 2018, p. 25.
304

64

process of architectural form generation? Does this phenomenon therefore help to explain why
architectural critics tend to be more inhibited when it comes to form generation, while architectural
designers tend to be less critical?
And if criticism is understood as the opposite of form generation, does this opposition not play out in
the training of a GAN, where the generator/artist and the discriminator/critic train each other? And
could we extend this model to the training of the architect, where architectural students are
encouraged to be more critical in the generation of their design and more imaginative in their
criticism? Could the role of criticism, in other words, echo that of backpropagation in correcting
errors and improving a design? Could we therefore say that genuine creativity emerges out of the
interaction of form generation and criticism? Might we even speculate, then, that creativity can be
understood as an emergent property?
Hiroshi Ishiguro remarks about robots, “The robot is a kind of mirror that reflects humanity and by
creating intelligent robots we can open up new opportunities to contemplate what it means to be
human.”307 Could we say something similar about AI?
Could AI become a mirror in which to understand human creativity?

307

Hiroshi Ishiguro (in conversation with Maholo Uchida). 2019. ‘A Reflection of Ourselves: Robots and the Journey Towards
Understanding Human Intelligence.’ in Chloe Wood, Chloe, Suzanne Livingston, Maholo Uchida, (eds.), AI: More Than Human. London:
Barbican International Enterprises, 2019, pp. 174-179

65

Chapter 4
AI, Media Art and Neuroscience
The movie, Blade Runner (1982), directed by Ridley Scott, depicts a dystopian future world involving
‘replicants’ – bio-engineered robots – manufactured by the Tyrrell Corporation to have super human
abilities so that they can survive in the hostile conditions of off-world colonies. Replicants are
therefore potentially dangerous, and as a safety measure are given a limited life span of four years. In
the movie a group of six replicants return to earth in a bid to extend their lives. Rick Deckard, played
by Harrison Ford, is a ‘blade runner’, a kind of policeman/bounty hunter, charged with hunting down
and ‘retiring’ – killing – these replicants. The problem, however, is that replicants – especially the
advanced Nexus 7 model – look almost identical to human beings, and can only be distinguished by
using the elaborate ‘Voight-Kampff’ test designed to check whether their emotional responses and
eye reflexes meet the standard of human beings. The movie is thus primarily about the difference
between human beings and replicants, such that replicants become a mirror in which to understand
what it is to be human. As the late Rutger Hauer, who plays the leader of the replicants, Roy Batty,
comments, ‘In many ways, Blade Runner wasn’t about the replicants. It was about what does it mean
to be human.’308
Fast forward to now – not so long after 2019, the year in which Blade Runner was set – and it is worth
reflecting on how prescient the movie has proved to be.309 We do not have replicants infiltrating
society, but we do have AI personal assistants, Siri, Alexa and Google Assistant, colonizing our
everyday lives, and we do have AI filtering our spam, and performing other tasks on our cell phones.
We don’t have flying cars, but we do have Maglev trains, drones and self-driving cars. We do not
have the Tyrrell Corporation, but corporate life is dominated nonetheless by hi-tech companies, such
as Google, Amazon, Apple and Microsoft. And, as predicted in Blade Runner, we do talk to our
computers, and do have LED advertising all over our buildings, especially in cities like Shanghai.
Clearly Blade Runner has proved to be highly prescient.
Although replicants are not necessarily controlled by AI, they are clearly an artificial life form
endowed with some kind of ‘intelligence’. There are other parallels too. The victory of Batty over
Tyrrell in the game of chess in Blade Runner foreshadows the victory of DeepBlue over Kasparov in
1997. Moreover, the role of the ‘Voight-Kampff’ test in detecting replicants echoes the use of the
Turing Test to determine how convincing AI can be, just as in a GAN the discriminator determines
how convincing the output of the generator is. They therefore make a productive vehicle by which to
308

Roxborough, Scott. 2018. ‘Rutger Hauer on 'Blade Runner2049' and Why Films Today "Lack Balls"’ Hollywood Reporter,
February 18 2018, hollywoodreporter.com/heat-vision/ rutger-hauer-blade-runner-2049-why-films-today-lackballs1085827
309
Blade Runner was set on 19-21 November 2019, as we find out in the sequel, Blade Runner 2049.

66

address the topic of AI, especially in the context of debates about human intelligence.
Blade Runner is based on the novel by Philip K Dick, Do Androids Dream of Electric Sheep? It is
therefore opens up a provocative question as to whether AI can dream. The theme of dreaming, of
course, runs throughout Blade Runner. With this very title, the author raises an important question
about the potential for androids/robots to ‘dream’. Indeed the theme of dreaming runs throughout both
Blade Runner movies. In Blade Runner, Deckard has a dream of a unicorn, while in the sequel, Blade
Runner 2049, Anna Stelline, whom we find out to be the daughter of Deckard and his lover, Rachael,
is a designer of dreams for replicants.310 Since replicants are not born and brought up like humans,
they need to be given dreams, just as they need to be given memories.

Dreaming Machines
The Japanese computational architect and AI expert, Makoto Sei Watanabe, has been exploring the
potential of AI in architecture since 1994.311 After a series of explorations, however, Watanabe
became somewhat frustrated, and began to realize that while human beings have their limitations,
machines also have even more limitations. Watanabe concluded that computers cannot ‘dream’:
‘Machines are better than people at solving complex problems with many intertwined conditions. In
that realm, people are no match for machines. But people are the only ones who can create an image
that does not yet exist. Machines do not have dreams.’312
We know from deep learning, however, that AI is quite capable of generating images of objects that
do not yet exist. This, after all, is the principle behind the deep learning based website, ‘This person
does not exist.’313 At one very straightforward level, then, Watanabe would seem to be wrong.
Patently, computers can generate images or images of objects that do not yet exist.
But is anything ever truly novel? Take the example of the highly innovative Move 37 made by
AlphaGo. It could be argued that the possibility of this move had always already existed. It is just that
no human beings had ever encountered it before. Or take the example of penicillin. Was penicillin
actually ‘invented’? Or had it been there are along, and was it simply discovered by human beings?
The same principle applies to architecture. The very notion that there might be a form that ‘does not
310

The dream of the unicorn, and the origami figures of unicorns made by Gaff, a police officer with the LAPD in Blade Runner, have been
cited as reasons why Deckard himself might be a replicant, a possibility left dangling as a fascinating idea in Blade Runner, and confirmed
as being correct in Blade Runner 2049. Murray Chapman, ‘What is the significance of the unicorn?’, Blade Runner Insights, 1998,
https://br-insight.com/library/significance-of-the-unicorn/
311
Makoto Sei Watanabe, “AI Tect: Can AI Make Designs?” in Neil Leach, Philip Yuan (eds.), Computational Design, Shanghai: Tongji
University Press, 2017, pp. 68-75. Tracking the development of AI within the domain of architecture is far from easy. Many AI researchers
post their research on online platforms, such as Medium. But there is no single site dedicated to research on AI and architecture. Nor indeed
is there any research journal as yet dedicated to AI and architecture. As such, any overview of developments in this field risks overlooking
some of the key players, especially when they are publishing their work in other languages apart from English.
312
Makoto Sei Watanabe, ‘Can AI Make Designs?’ in Neil Leach, Philip Yuan (eds.), Computational Design. Shanghai: Tongji UP, 2017.
313
www.thispersondoesnotexist.com. So too, it is the principle behind the architectural website, ‘This building does not exist.’
www.thisbuildingdoesnotexist.com. This website has since been removed.

67

yet exist’ is itself contentious. According to Kostas Terzidis, for example, what AI establishes above
all else is that every possible form is already out there, and it is simply a matter of searching for it.314
According to this logic, the idea that architects are genius creators constantly ‘dreaming up’ new
forms is clearly absurd, in that it would be simply impossible to invent forms that do not yet exist.
Arguably, then, we could claim that when we design something novel, we are not inventing anything,
but merely finding out about something whose potential has always already existed.
Dreaming Buildings
One of the important figures in introducing AI to the realm of architecture is Refik Anadol. To be
clear, Anadol is not an architect. He is a media artist, often described as an ‘AI artist’ or ‘data
sculptor’, who uses AI to hallucinate images and videos. But he addresses architecture in much of his
work. Not only does he use architectural images as his raw data, but he also often projects his work on
to buildings. If Christo and Jeanne-Claude made their names by wrapping buildings and other objects,
Anadol has made his name by projecting images on to buildings. For Anadol buildings are both his
canvas and artistic material.
Anadol was brought up in Istanbul, Turkey. At the age of 8, he was given a video cassette of Blade
Runner by his mother. It was a gift that had a profound effect on him: ‘I clearly remember being
mesmerized by the stunning architectural vision of Los Angeles, a place that I had never seen before.
That vision became a kind of staple of my daydreams.’ 315
When Anadol moved to LA in 2012 to begin his studies in the Department of Design Media Arts at
UCLA, he was hoping to encounter the city of Blade Runner. What he encountered, however, fell
well short of his expectations.316 He did not encounter a high tech city of flying cars and massive
megastructures like the headquarters of Tyrell corporation. And if, as Rem Koolhaas has claimed, ‘A
city is a plane of tarmac with some red hot spots of intensity,’ LA is a sprawling, largely suburban
plane of tarmac, with little, apart from Downtown, that could be described as a red hot spot of
intensity.317 There was, however, one building that could never disappoint him, and that was the Walt
Disney Concert Hall (WDCH), designed by his architectural hero, Frank Gehry, even though it
seemed weird and dark, when he first encountered it in the early hours of the morning, completely
unlit:
314

Kostas Terzidis, Algorithmic Architecture, London: Routledge, 2006, p. 11; Terzidis, Permutation Design. London: Routledge, 2014, p.
85. This also begins to suggest that certain more conservative approaches to creativity, such as that of Martin Heidegger, need to be
reconsidered. For example, Heidegger’s notion of the work of art is linked to the Greek term ‘aletheia’, which means ‘not forgetting’. In
other words, in producing the work of art the ‘artist’ merely uncovers – or ‘remembers’ – an already existing ‘truth’. On this see: Leach (ed.),
Rethinking Architecture,
‘When I first moved to L.A., the first building I came across was the Walt Disney Concert Hall,
the home of the L.A. Philharmonic. Having arrived in L.A. at 2:15 in the morning, I saw a
weird dark thing with no lights instead of that shiny bright Walt Disney Concert Hall. The
building seemed incredibly alone and isolated. Apparently they shut off the lights at night to
save energy. I would have never guessed that. I remember regarding the building as an entity
that could make a sound, think and learn from itself.’318
The opportunity arose, however, to bring the WDCH to life, when Anadol was commissioned to
produce a data sculpture in 2018 to mark the 100th anniversary of the LA Philharmonic. Additionally,
this project also offered Anadol the chance to operate with public space, which, for him, holds a
special allure. Not only does public space expose his work to a far broader audience, but it is also not
limited by the constraints of the interior of a building: ‘Public space is an important field for me. A
public space doesn’t have a door, a ceiling or a floor. There’s no beginning or an end. It’s an idea
that’s open to anyone, anytime.’319
The project became a study of dreams and memories. One source of inspiration for the WDCH project
was an earlier project, Melting Memories, where Anadol had collaborated with neuroscientists from
the Neuroscape Laboratory of the University of California San Francisco, to understand how
memories are based on brain signals, in order to create a data sculpture based on EEG data: ‘Can we
witness the moment of remembering? . . Can we transform it into a 3D surface with the help of
machine intelligence?’ 320
Another source of inspiration was the scene in Blade Runner, when Rachael realizes that she has been
given someone else’s dreams. This prompted him to ask the question, ‘What can a machine do with
someone else’s memories? . . . If a machine can process memories, can [it] also dream? Hallucinate?
Involuntary remember, or make connections between multiple person’s dreams?’ 321
‘When we dream,’ notes Google AMI, ‘our minds process memories to form new combinations of
images and ideas.’322 This was the impulse that led to the central idea behind the project, the idea of

gathering all the archived ‘memories’ of the 100 years of the LA Philharmonic and the records of the
WDCH itself:
‘To answer this question, we decided to collect everything recorded in the archives of the LA
Philharmonic and WDCH. To be precise, 77 terabytes of digitally archived memories. By using
machine intelligence, the entire archive, going back 100 years, became projections on the
building’s skin, 42 projectors to achieve this futuristic public experience in the heart of LA,
getting closer to the LA of Blade Runner. If ever a building could dream, it was this
moment.’323
The intention behind this projection is to give ‘consciousness’ to the WDCH in three distinct
stages.324 The first stage – ‘Memory’ – involves the ‘training’ of a neural network by classifying
thousands of images and sound recordings of events from the archives of LA Philharmonic.325 This
data is then processed by the network.326 The second stage – ‘Consciousness’ – involves the use of a
neural network to categorize and rearrange the material, by finding similarities within the material.327
The third stage – ‘Dreaming’ – is when the full ‘hallucination’ takes place, and is the most spectacular
of the three stages.
“It is completely a machine hallucination. An architectural cultural beacon reconstructs its own
skin, and even reconstructs a memory. . . The building makes an artificial sea, an artificial
ocean on its own skin by using data points. And at the end, we land in a moment that the
building even starts to dream hallucinations. And we realize that we were actually witnessing
the entire cognition of a building, going from opening the operating system to a point that it
imagines. The journey between these two is the story.
On the evening of 28 September 2018 a series of 42 powerful projectors were eventually switched on,
and the WDCH was lit up by a data sculpture projected on to its exterior. The data sculpture had been
generated by Anadol, in collaboration with Google AMI and computational sound engineer, 

Mital.329 This was not the first time that Anadol had projected his work onto buildings. Nor was
Anadol the first to explore the use of AI within the realm of architecture. But nonetheless, the
symbolic significance of projecting a data sculpture of such magnitude onto such a prominent
architectural masterpiece marked a threshold moment in the introduction of AI to the world of
architecture. It was also, arguably, the moment when a sense of Blade Runner was brought to the
architecture of LA. Anadol and his team had not only succeeded in bringing the WDCH alive:
‘Architecture is not any more alone, dark in the late night.’ 330 Finally, it was also the moment when,
arguably, a sense of Blade Runner was genuinely brought to LA. As Alejandro Iñárrito commented,
‘It was the first time that I could touch ‘science fiction’.’ 331
The projection of the data sculpture on to the WDCH was not the first time that Anadol had projected
data sculptures on to buildings. In fact Anadol had begun to attract attention with a series of data
driven works projected on to interiors of buildings. His early work Infinity Room (2015) draws upon
his childhood dreams and memories, two domains that play a significant role in his work.332 As such,
Infinity Room (2015) opens the door to not only memories and dreams, but also to the potential of
hallucinating about a space. Likewise his Virtual Depictions: San Francisco, (2015) a data-based
work projected on to a wall in the entrance lobby of a building designed by Skidmore Owens and
Merrill (SOM) in San Francisco. This artwork was based on a real-time data sculpture pipeline by
combining geo-location-tagged Twitter activities and 3D point cloud data of the city. Other
installations, such as Wind of Boston (2017) based on weather data, and Bosphorus (2018), based on
radar data, continued this series of data sculptures displayed on the walls of buildings.333
Anadol’s Infinite Space (2019) project for Artechouse in New York is a further development of AI
based techniques developed for his WDCH project.334 Here, however, he uses them to simulate the
effect of synthetic architectural ‘memories’ of the city of New York. Anadol and his team
downloaded more than 213 million publicly available photographs of buildings in the city. They then
introduced an algorithm to remove any photos with people in them, reducing the number to 9.5
million images. And they then introduced another algorithm to allow the machine to ‘dream’ based on
this dataset, and projected the resulting 30 minute movie on to the interior space, a disused boiler


room turned into an exhibition space.335 A further development from this the Quantum Memories
project (2020), based on 200 million images
Anadol is also responsible for generating the image on the front cover of this book, using a
customized version of StyleGANs.336 As is self evident, the image resembles a design by Zaha Hadid
Architects (ZHA). This is hardly surprising, in that it was ‘hallucinated’ by AI, based on a dataset of
images of designs by ZHA. The output is clearly influenced by the input of ZHA images. Importantly,
it is not a copy of any one of those images, but an interpolation based on the overall dataset.
Importantly also it is not an image of anything that already exists, but a hallucination of something
that could exist.
Machine Hallucinations
The term often used to describe AI generated images is ‘machine hallucinations’. Although we might
think that ‘machine hallucinations’ are fundamentally different to human hallucinations, there are
surprising similarities, and we can make direct comparisons between how AI operates and we
ourselves operate.337 In fact AI sees the world through the lens of the data on which it has been trained,
just as we also see the world through the lens on which we have been trained. For example, if we were
to ask anyone how many colours there are in a rainbow, the chances are that they would reply, ‘seven’,
even though there are an infinite number of colours in the spectrum that constitutes a rainbow.338 This
is because we are trained at school to understand that there are seven colours in a rainbow. And, if we
were to ask any architect what a ‘functionalist’ building looks like, the chances are they would
describe a white building on piloti with a flat roof, even though flat roofs are not very functional in
most countries because they tend to leak. This is because we are trained at architecture school to
understand that functionalist buildings have flat roofs.
The idea that we are conditioned to see the world in a certain way comes under the theory of
‘predictive perception,’ a theory that is beginning to gain some traction in neuroscience.339 According
to neuroscientist, Anil Seth, the brain is locked into a boney skull without any light or sound, and has
little information about the outside world apart from electrical impulses. As such, the brain tries to
offer its ‘best guess’ as to what is happening out there, based on sensory information and previous
experiences. Perception is therefore not as objective as it might seem. Nor is it simply a question of
the brain receiving signals from the outside. The brain actively partakes in trying to make sense of
what it is sensing:
‘Instead of perception depending largely on signals coming into the brain from the outside
world, it depends as much, if not more, on perceptual predictions flowing in the opposite
direction. We don't just passively perceive the world, we actively generate it. The world we
experience comes as much, if not more, from the inside out as from the outside in.’340
Seth argues that the brain therefore makes predictions – or ‘hallucinations,’ as he calls them – about
what it is perceiving. But these hallucinations need to be reined in so as to prevent incorrect
predictions. There needs to be a degree of control involved. Seth illustrates this with a video
processed using a DeepDream algorithm that shows how overly strong perceptual predictions can lead
to weird hallucinatory perceptions, where the viewer comes to read images of dogs into everything
that they see.341 This leads Seth to conclude that if hallucination is a form of uncontrolled perception,
then perception itself must be a form of “controlled hallucination”:342
‘If hallucination is a kind of controlled perception, then perception right here and right now is
also a kind of hallucination, but a controlled hallucination in which the brain’s predictions are
being reined in by sensory information from the world. In fact, we’re all hallucinating all the
time, including right now. It’s just that when we agree about our hallucinations, we call that
reality.’343
What is interesting here is that Seth also uses DeepDream to illustrate the way in which we see the
world through a form of predictive perception. Moreover, just as we use the expression ‘machine
hallucinations’ to describe the images generated through deep learning, Seth uses the expression,
‘controlled hallucinations’ to describe the process of predictive perception on the part of humans.
According to this logic, when we look at the world we are actively hallucinating, similar to how
machines are ‘hallucinating’ when they generate images. There is an implicit parallel being drawn,
then, between human perception and computational image generation. The two would appear to be
not as dissimilar as at first we might imagine.

Similarly, computational artist, Memo Akten, uses artificial neural networks to illustrate how we are
trained to see the world:344 In his ‘Gloomy Sunday’ interactive experiment, Akten offers an
illustration of how an artificial neural network interprets objects based on how it has been trained.
Thus, if trained on a dataset composed solely of images of flowers, the artificial neural network will
read images of flowers into everything that it sees. As Akten observes, “The picture we see in our
conscious mind is not a mirror image of the outside world, but is a reconstruction based on our
expectations and prior beliefs.”345 By extension, previous experiences act as a kind of filter to
subsequent experiences. They distort and colour how we see the world. In other words, Akten’s
notion that perception is based on ‘prior beliefs’ appears to be remarkably similar to Seth’s notion that
it is based on ‘previous experiences’. Similarly, the ‘Gloomy Sunday’ experiment that Akten makes
using trained neural networks is remarkably close to the experiment that Seth makes using
DeepDream. In short, Akten appears to be corroborating Seth’s theory of predictive perception.
Equally, we could compare Seth’s notion of the ‘controlled hallucination’ at work in our perception of
the world with Slavoj Zizek’s notion of ‘fantasy’ that serves as a lens through which we perceive the
world. Zizek’s thinking is grounded in Lacanian thinking. According to Lacan, we do not access the
‘Real’ except in moments of jouissance.346 What we take for the real is not the real in itself, but an
appearance of reality.347 In fact our perception of reality comes to us ‘via a detour through the maze of
the imagination’. It is coloured and distorted by our imagination, no less than our outlook on the
world is distorted by the way that we have been trained to view the world, as the two ‘experiments’ by
Seth and Akten illustrate. Moreover, for Zizek, our perception of reality is a fantasy of reality.348
Fantasy, then, plays a key role in how we understand ‘reality’. In fact fantasy, for Zizek, is literally
‘constitutive of how we see reality’:
‘Far from being a kind of fragment of our dreams that prevents us from ‘seeing reality as it
effectively is’, fantasy is constitutive of what we call reality: the most common bodily ‘reality’
is constituted via a detour through the maze of imagination.’349
Zizek goes further, and speculates whether, as we use computation to simulate human thought ever
more closely, an inversion might take place, such that human thought begins to emulate a computer
program, and our own understanding of the world itself becomes a model:

‘What if this ‘model’ is already a model of the ‘original’ itself, what if human intelligence itself
operates like a computer, is ‘programmed’, etc.? The computer raises in pure form the question
of semblance, a discourse which would not be a simulacrum: it is clear that the computer in
some sense only ‘simulates’ thought; yet how does the total simulation of thought differ from
‘real’ thought?’350
In other words, Zizek is speculating that we might be living in a simulation, an argument originally
floated by sociologist, Jean Baudrillard, and made famous in the movie, The Matrix, but since
supported by other more recent philosophical arguments.351 Likewise, we can draw comparisons
between this view and the way that Seth and other neuroscientists understand our conception of the
world as a constructed one, based on prior beliefs and experiences, such that what we perceive is also
a model – a simulation – of the world.
This leads Zizek to conclude that it would be wrong to denigrate ‘virtual reality’ as a lesser form of
reality. What virtual reality reveals is not how ‘virtual’ virtual reality is, but rather how ‘virtual’ our
understanding of ‘reality’ is: ‘The ultimate lesson of virtual reality is the virtualization of the very true
reality.’352
Architecturalisations
Turning to architecture, could we not also compare the way that we are trained as architects to the
way in which artificial neural networks are trained? In 2020 FIU architectural student, Fernto see the world in a certain way, just as a neural network is trained to see the world?
To claim that this is the case would be to mount an argument based on pure analogy. In and of itself,
this experiment does not prove anything. Nonetheless it is tempting to pursue this line of enquiry
further. Might this experiment not offer us insights, for example, into the nature of inspiration itself –
the ‘act’ of reading the world through a particular lens and then re-expressing that vision in the design
itself?
We could describe this process as a form of ‘architecturalisation’. In effect architects tend to
‘architecturalise’ whatever they see, and read the world in architectural terms.356 This allows them to
be inspired by any number of non-architectural items – biological entities, animals, insects, geological
formations and indeed potentially anything – and incorporate them into their architectural
expressions.357 This might explain, for example, how Jorn Utzon was inspired by the billowing sails
of yachts, and went on to read them as potential vaults for an opera house overlooking Sydney
Harbour. This might also help to explain why architects so often misinterpret philosophical concepts,
such as the ‘fold’ promoted by Gilles Deleuze, and assume they are references to architectural forms,
even though they have nothing to do with form, or architecture as such.358 It might also explain how
some architects and architectural commentators make the mistake of taking terms referring to the
digital – terms such as ‘discrete’ or ‘pixelation’ – and assume that they are referring potentially to
architectural forms, even though the digital itself is immaterial and has no form.359
By extension, it would also explain why architects tend to ‘aestheticise’ everything that they see,
reading the world in terms of aesthetic concerns, and rinsing it of any economic, or social and
political considerations.360 Why is it, for example, many architects have a tendency to privilege design
concerns over economic factors, even though economic factors are the driver of any design? Indeed,
why are there so few references to economic considerations in books on architecture, apart from the
cost of the book on the back cover? It is as though architects always tend to see the world with a
certain gaze, as though through rose-tinted, aestheticising lenses.
It is important to understand, then, that the gaze of the architect is not neutral. It has been trained, no
less than a neural network has been trained. Whether we understand this conditioned outlook in Seth’s
terms as a form of ‘controlled hallucination’ or in Zizek’s terms as being constituted through ‘fantasy’,

it is clear that architects see the world not as it is, but as they are trained to see it. But is this not so
dissimilar to the message behind the term ‘deconstruction’ coined by Derrida?
Derrida argues that our perception of the world carries with it certain biases, just as the data used in
AI carries with it certain biases.361 Our perception of the world is therefore ‘constructed’. And this
‘constructed’ perception is a distorted one, as we have seen with the standard interpretation of a
rainbow. What needs to be exposed, then, is how our understanding of the world has been
‘constructed’. And this ‘constructed’ way of understanding the world itself needs to be
‘deconstructed’. The same issue applies to architecture.
‘Let us never forget,’ writes Derrida, ‘that there is an architecture of architecture.’362 Put another way,
our understanding of architecture is itself ‘constructed’, as we have seen with the standard perception
of ‘functionalism’ as referring to buildings with flat roofs. Our understanding of architecture therefore
needs to be ‘deconstructed’. The irony here is that architects largely misinterpret Derrida. They tend
to think that the term, ‘deconstruction,’ refers in some way to the construction of architecture,
whereas in fact it is simply an architectural metaphor.363
What is this misinterpretation, then, but yet another example of architecturalisation?
Can Machines Dream?
Is Watanabe correct, then, to argue that machines do not have dreams?364 Arguably, we could claim
that machines can now ‘dream’. The term, ‘dream’, after all, appears throughout Anadol’s
descriptions of his work. It also appears in the name of the technique, DeepDream, and the Autodesk
software, Dreamcatcher. We can also find references to other dream-like ways of generating images,
such as ‘hallucinations’. Mitchell, of course, argues that AI would require consciousness in order to
appreciate the artistic quality of anything that it generates. Consciousness, for Mitchell, is therefore
the hallmark of creativity.365 But do dreams themselves necessarily depend on consciousness?
According to Freud, dreams have many roles. For example, repressed feelings can be expressed in
dreams, just as they can erupt involuntarily in speech through the process of parapraxis, or can be
expressed in sublimated form in any creative act. Equally dreams offer a ‘royal road’ to 

unconscious, as Freud puts it, as they give access to parts of the mind inaccessible during conscious
thought.366 In other words, dreams themselves do not necessarily have anything to do with
consciousness, and they can be present in sublimated form in the creative act of designing. Seen from
this perspective, dreams do not depend on consciousness.
Alternatively, we could argue that in terms of the discourse of ‘extended intelligence’, the generation
of AI work does indeed involve consciousness. It is just that the human being, and not AI, possesses
consciousness. In fact we could even argue that this is always the case in any computational operation,
in that the computer is never acting on its own. Ultimately the user remains in charge.367 Despite the
seemingly objective nature of the computational process, the output must always satisfy the subjective
user. And if the output does not satisfy the user, then the algorithms can always be tweaked until they
produce a result that does satisfy the user.
As such, it is almost meaningless to talk about AI in isolation. For the moment at least, it is always a
question of a form of human-AI collaboration. Less artificial intelligence per se, more ‘extended
intelligence’. And, since the user has consciousness, by definition, this collaboration itself involves
consciousness. Seen in this light, it is simply a matter of the user dreaming through AI, or of the user
adopting AI as an extension of the human imagination. Moreover, as many have pointed out, there is
only one entity superior to AI, and that is ‘humans plus AI’. And clearly ‘humans plus AI’ are
superior to humans without AI. Watanabe’s question, then, should not be ‘Can machines dream?’ so
much as, ‘Can humans use machines to enhance their own dreams?’
If we put Watanabe’s comments in their full context, however, it is clear that this is actually what
Watanabe means. For Watanabe, the secret is not to read AI in isolation, but in terms of a potential
AI-human symbiosis. Watanabe refers to AI in this context as a ‘capability expanding AI’ or an AI
that ‘can expand the imagination.’
For Watanabe, the working of the brain – in other words, ‘intuition’ – is always a ‘black box’.368 We
cannot understand how it works. Meanwhile AI can also be a ‘black box’. In the case of deep learning,
for example, even computer scientists don’t know quite how it works. This symbiosis between
machines and humans, then, amounts to a form of ‘collaboration’ between two black boxes.
Interestingly, Watanabe sees the potential of machines having dreams in terms not of a competition


between humans and machines, but of a synthesis, where humans and machines complement each
other:
‘Will this answer always be true? Will the day come when machines have dreams? Preparing
for that day will involve exploring the path of potential cooperation between the brain and
machines. This will require work in both areas – white boxes, in other words, the scientific
approach or algorithmic design, and black boxes, towards collaborative methodologies, or, in
other words, AI Tect. This is similar to how our left and right brains handle different functions
and collaborate in delivering an outstanding performance.’369
And so, do robots dream? And does it even make sense to think of robots in isolation? Or should we
only be thinking of robots in collaboration with human beings? Watanabe, at any rate, is interested in
this collaboration. Working with robots can help architects to dream up a far greater range of options
than their own imagination might allow. Traditionally, we have seen robots as being mechanical
devices that can only perform mechanical tasks. But working together with human beings, they can
open up space for the imagination. For Michael Hansmeyer this is the crucial step: ‘We’ve been using
computers to increase our efficiency and precision. Let us view the computer as our muse, as a partner
in design, and as a tool to expand our imagination.’370
In 2019 there as an exhibition on AI held at the Barbican in London, called, AI: More than Human.371
The premise behind the exhibition was that the concept of AI has to be seen within a broader context
as a continuation of a desire to artificially create intelligent life. The exhibition was certainly
convincing in making this argument.
The title of the exhibition, however, appears to imply that AI could somehow be ‘more than human.’
But is it a question of comparison? Should we see the relationship between AI and humans as being
one of competition? Is this title not fear mongering? Or should we see the role of AI as being
complementary to the role of humans? Is not one of the roles of AI to free us from the drudgery of
certain repetitive operations, and allow us to expand our own all too human imagination?
Is the role of AI to allow us to become more human?
AI, be my muse!

AI and Architecture
The exhibition, The Architectural Beast, curated by Hernán Díaz Alonso and designed by Casey
Rehm, opened in the FRAC Centre, Orléans, France on 11 October 2019. This was the first exhibition
using AI at a major architectural gallery.372 The exhibition comprised the work of 17 architects and
artists from the Southern California Institute of Architecture (SCI-Arc).373 Each day the work was
gradually transformed by being manipulated against an internet search of the most popular online
architectural images on Instagram, Flickr and other platforms, based on their number of ‘likes’. As
such, the initially progressive images gradually became more conservative over time. The intention
was that the initial work would gradually be contaminated through this process, so that after two
months it would reach a tipping point, and the initial content would constitute less than half of the
resultant, hybrid entity.
For Díaz Alonso, the exhibition attempts to mimic the process of cross-contamination at work within
architectural culture that echoes that evolution of culture itself. Thus architecture itself is treated as a
species that mutates over time in response to both technological and cultural changes:
In every process of evolution, there is a period of extreme contamination that lends the
possibility for the trajectories of species to begin to mutate. In the last 30 years, design has
experienced multiple paradigm shifts generated by an eruption of new methodologies. These
were derived mainly from new technologies, but also from a series of cultural changes, each
prompting a reorganization in the culture of design, architecture, and art, and violating an old
order, rendering it historical, obsolete.374
The hybrid images are accompanied by texts that change each day. The texts are based on captions
generated by a network trained on the published work of those exhibiting, and then expanded by a
second network trained on theoretical and critical writings by Rehm, Damjan Jovanovic and Liam
Young. At first sight they seem to make sense. On closer inspection, however, it becomes clear that

372

Rehm describes the technology behind the installation: perspective, ‘The Architectural Beast is based on 6 neural networks linked
together. . . It has 2 image classifiers, a StyleGAN. . . It has an image serving capability. It has an image to text analyzer which generates
descriptive text based on the image, and it further uses another text generator to expand on those short phrases. . . It was trained on
theoretical and critical texts from different people participating in the show. To generate this thing that would kind of hover around on the
internet, consume it, produce new images continuously over a 3 month period. . . but also to write about it, because we wanted to start to
bring together and produce a coherent and cohesive multiple representations of this aesthetic shift that was happening in the machine.”
Casey Rehm, Goldsmiths Lecture, 3 February 2020, https://vimeo.com/389542895
373
The artists/architects were: BairBalliet, Hernan Diaz Alonso, Griffin Enright, Damjan Jovanovic, Alberto Kalach, Ferda Kolatan, Elena
Manferdini, Fabian Marcaccio, Lucy McRae, P-A-T-T-E-R-N-S, Florencia Pita, Casey Rehm,
Ruy Klein, Servo LA-Stockholm, Testa & Weiser, Tom Wiscombe, Liam Young
374
Hernán Díaz Alonso, ‘The Architectural Beast’, FRAC, http://www.frac-centre.fr/_en/biennale/years-solitude/landscapes/thearchitectural-beast/the-architectural-beast-1163.html

80

they are utterly nonsensical examples of ‘architecture discourse’. Here is an example of one of the
texts generated:
‘We had the opportunity to move into a new office and I would go in through the hallway to go
into the office to look around. We had a very clean, simple and clean office with a great staff
and a great client. We became very good friends working on this project and it was always the
way that the project was progressing. So it helped that for me coming over to this location was
just that much more special.’375
What are we to make of these nonsensical texts? In many ways, the texts – much like the growth of
AI generated poetry – evoke the tradition of automatic poetry practiced by the Surrealists, that was
intended to liberate the creative process and free it of conscious control. Indeed Rehm acknowledges
the absurdity behind this exercise. But it is also as though these texts are deliberately meaningless,
and intended as a general parody of the often overly pretentious nature of architectural discourse in
general. 376 They can also be read as a critical commentary on the discourse of meaning so pervasive
in architectural design culture during postmodernity. 377
What makes the process of generating the images in the exhibition so poignant, however, is that it
uses AI to mimic a process that already happens within architectural culture. AI can be used to crosspollinate datasets with other datasets, just as the discipline of architecture mutates by being crosspollinated with ideas from other disciplines. No longer discrete, architecture becomes a mix where
ideas are shared between different disciplines, leading to a hybrid, contaminated mix of different
impulses obscuring the origins of any single idea. Díaz Alonso again:
‘Today, perhaps as never before, we share a technical language that flows from discipline to
discipline, altering the paths of previously discrete branches of knowledge. Many practices—
art, architecture, fashion, film, music—explore similar ambitions, ideas rippling across and
among them. The notion of authorship itself is in flux.’378
But what if the exhibition were not merely parodying the process by which architecture is generated,
but also replicating that process in some way? Indeed, the very use of AI in this architectural
exhibition is itself a form of cross-contamination


Architects have always been receptive to ideas from the outside, and have a reputation of acting
somewhat like magpies, stealing the latest glittering ideas and technologies from other disciplines. In
terms of ideas, philosophers have often been a source of external influence, whether the more
conservative philosophers, such as Heidegger, or progressive ones, such as Jacques Derrida or Gilles
Deleuze. Indeed philosophy is often treated as a fashionable intellectual veneer to help promote a new
architectural theory.379 Have philosopher, will theorise.
The same goes for technology. Architects have always had a tendency to appropriate technologies
from other disciplines. Maya software was not designed for architects. Nor was Unity. Nor indeed
were Kuka robots. In some cases, architects adapt software designed for other disciplines, as in the
case of Digital Project, customized by Gehry Technologies from Catia, a software developed by the
French company Daussault for use in the aircraft industry. But very few technologies originate from
within architectural culture.
If AI really is to have an impact on architectural culture, however, we should look beyond the
experimentation of academic design studios, workshops and conferences to architectural practice
itself. How might AI be used to not only to generate images for a fascinating exhibition about
architectural culture, such as The Architectural Beast, but also contribute to the designs of actual
buildings?
Coop Himmelb(l)au
Wolf Prix, the Design Principal and CEO of Coop Himmelb(l)au, the progressive architectural design
practice based in Vienna, Austria, has been one of the first to explore the potential of AI. Initially,
however, Prix was somewhat suspicious of AI.380 Indeed, Prix was sceptical of computation in general,
and parametricism in particular, because it represented a closed system.381 But he now recognises that
AI can open up possibilities, rather than close them down.
Prix, of course, is no stranger to experimentation, from his early days of burning wings, writing
provocative manifestos, and exploring automatic drawing, Prix has always sought to challenge the
status quo, and to open up architecture to new possibilities.382 Alongside Frank Gehry, Rem Koolhaas,
Peter Eisenman, Zaha Hadid and others, he was also one of the progressive architects included in the



exhibition, Constructivism, held at MOMA in New York in 1988, and has remained at the forefront of
radical experimentation in architecture.383 We should also bear in mind that Prix has always been in
favour of openness and freedom of expression. Indeed Karl Popper, author of The Open Society, and
its Enemies, is one of his heroes.384 Whatever promotes openness is to be celebrated, and whatever
closes down opportunities is to be challenged. For Prix, then, we should always be open to the
possibilities afforded by AI: “Don’t exclude it! You should integrate it and use it.”385
Prix tries to impress on his team how important AI is: “AI is just a tool. But the most important coworker in our office is AI.”386 For Prix, the real benefit of AI is that it can make the design process
more efficient, and leave more time to explore new languages. For Prix, this comes at a time when
architecture is in crisis. Architecture is on ‘shaky ground’ right now: “There is almost no gravity.”387
Architecture is very insecure. The old structures are dying, and ‘new structures’ are coming up.
Although these ‘new structures’ are not ready yet, there is a possibility that AI might play a role in
influencing their development. For Prix, students of architecture need to explore its potential. But AI
is not useful if it limits a student’s thinking. AI should support their thinking. Without any content,
there will be no shape.
At the same time, Prix remains somewhat cautious about AI: “Is it just a fashion? Will it kill us?”388
And certainly AI has its limitations. In fact, Prix likes to cite the neuroscientist, Singer, who observes
that AI is linear, whereas the human brain is multi-dimensional. And Prix also warns us against being
controlled by an algorithm: “Be suspicious! Be critical!”389 Architects should remain in control: “The
architects should be in the front seat, and AI in the back.”390 Above all, Prix warns us against the zeros
and ones of computation leading to a ‘zero-zero architecture’. And the ultimate analogy for Prix? Not
surprisingly, perhaps, for an architect from Vienna, Prix recognises the risk that AI might lead to a
kind of ersatz architecture, just like decaffeinated coffee: ‘It looks like coffee. It smells like coffee.
But no coffee.”391
But Prix is also amazed by the potential of AI. The most significant foray into AI undertaken so far by
Coop Himmelb(l)au is the project, DeepHimmelb(l)au, an attempt to use CycleGANs and other forms
of GANs to ‘hallucinate’ potential buildings.392 As mentioned earlier, CycleGANs work with two
unpaired datasets. In this case dataset A is based on reference images of geomorphic formations, and
383


dataset B is based on actual Coop Himmelb(l)au projects. The outcome is a video of a journey
through an imaginary landscape of Coop Himmelb(l)au-like building forms. The important point to be
stressed here is that these buildings do not actually exist. They are merely ‘machine hallucinations’.
DeepHimmelb(l)au has shown us that it is quite possible to ‘hallucinate’ relatively convincing designs
using GANs. Moreover, while there is considerable work that needs to go into preparing the datasets,
and many epochs are required to generate a high quality final product, eventually GANs are capable
of generating designs very rapidly. Daniel Bolojan is the computational architect responsible for
generating DeepHimmelb(l)au.393 As Bolojan notes: “As young as it is, within a clearly defined
domain, DeepHimmelb(l)au outperforms designers with regards to the speed of interpretation and
representation, and the amount of coherent interpretations that it can generate.”394
The intention behind DeepHimmelb(l)au is to find a way of ‘augmenting’ design processes, and of
adding a layer to already existing designs. The project should also be understood as part of a larger
vision for augmenting the design processes in the office. As Bolojan points out: “Those design
processes span from physical models interpretations to real time analysis, real time render, domain
translations 2D and 3D, design space explorations.”395
DeepHimmelb(l)au, however, also exposes a couple of challenges that need to be addressed before
GANs can play a really significant role in an architectural office. Although the images generated by
DeepHimmelb(l)au appear to be in perspective, they remain 2D images extracted from a video. In
order to develop a more convincing and holistic approach, the office would need to move into 3D, and
that entails developing more data, and using rendering so as to differentiate depth, materiality, layers
and so on.396 One of the most significant challenges of working with most GANs at the moment is
shifting from 2D to 3D. Another significant challenge is to develop a technique of controlling images
sufficiently, for them to be worked up into architectural drawings.
Morphosis




Bolojan outlines some of the constraints: “We cannot just take the video input and ask the network to generate the analysis and display it
on the physical model. Because the video output is a 2D information the network will see just that. The goal with the renders that we are
creating at the moment, is to be able to extract more than just the visual layer of the render but also the depth layer, contours etc (we extract
about 18 layers of information at the moment). We can use, for example, the depth layer to augment the network’s ability to see objects and
the depth of those objects, so that when the network will generate the analysis, it will be aware of 3D characteristics and be capable of
generating a correct interpretation and afterwards correct analysis. Rendering also allows us to generate labeled data, regarding materiality,
different building elements, that later will give us more ways of how to enhance or diminish certain features that the network sees or that the
network outputs. This is not to say that we don't build different datasets. For all the buildings that we render, we also create clean 3d models
that are organized with one unifying strategy.” WhatsApp conversation, 27 November 2019.
Pritzker Prize winner and director of Morphosis, Thom Mayne, is also fascinated by the possibilities
of AI, although his office has made less progress in the exploration of its potential. Indeed, Mayne has
always embraced technological innovation because of the opportunities that it affords. But, for Mayne,
no tool – not even AI – is a miracle tool, and human thinking still remains essential. And certainly
Mayne sees himself as an analogue person, grounded in the material world, who depends upon others
in the office to do the computational work. But computation is important, for Mayne, because it
promotes a broader approach to thinking. And it has already opened up the office to more flexible
approaches to design: ‘Digital design allowed us to expand rapidly and allowed us to make some
really interesting things to push architecture in terms of potentiality. It opened us up and broke us
away from very simplistic, Cartesian fixed systems into dynamic ones.’397 This is precisely why
Mayne is now so enthusiastic about pursuing the potential contributions of AI in his office.
According to Mayne, if we just leave everything to human intuition, we soon run out of ideas. Take
Fumihiko Maki, for example, someone whom Mayne admires greatly, and who taught him as a
student in Harvard GSD. However, Maki has not designed anything in 20 years, because he has been
unable to reinvent himself – like Le Corbusier – and remain fresh. This is where strategic thinking
plays such an important role.
Like Bernard Tschumi, Peter Eisenman and others in his generation, Mayne is interested not so much
in the object, but in the relationship between objects, and in developing a strategic approach to design.
In particular, Mayne is interested in any approach that challenges a priori thinking: “A priori thinking
is only based on what you know and have seen.”398 Instead of a priori thinking, we should focus on
operational strategies, so as to generate output that could never be predicted: ‘What became
interesting is that you are producing something that is not known. That was infectious. Once you
started designing that way, I was only interested in something that I couldn’t conceive.’399
Mayne has always been impressed by the way that computation can speed up the design process in an
architectural office: ‘Technology came along, and it replaced that incredibly tedious, in a mechanical
sense, process of drawing. . . What technology did was to give us a tool that does that in nanoseconds
from incredibly complicated designs that – prior to the adoption of digital technology – had required
immensely skilled drafts-people.’400 Computation, for Mayne, has always been a question of being
open to new ideas, and new iterations of existing ideas. “You’re looking for new contemporary

processes that rejuvenate you, that give you new material to invent stuff.”
Mayne is also interested in contingency and ‘combinatorial design’, and the contribution of even a
relatively straightforward tool, like Grasshopper (which can be understood as a form of AI in the very
broadest sense), is that his office is able to generate a multiplicity of different options in very little
time. When I visited his office, Mayne pointed out some of his iconic formal studies on display,
virtuoso works of astonishing sensitivity. What astounds Mayne, however, is that an architect in his
office, Daniel Pruske, was able to write a Grasshopper definition for one of them, and then very
quickly generate 100 different versions of the same study, by tweaking the constraints, and producing
iteration after iteration. Mayne again: “I’m looking at these, and I’m saying, “Damn, this is
interesting!” This is something that we’ve got to pursue. Now we are talking about
differentiation. . .”402 Mayne has always been against idealism from a theoretical perspective, but now
the computer is allowing him to challenge that notion from a very practical design perspective:
“It is interesting to look at this, because it opens up my brain. It doesn’t matter if I like it or
don’t like it. And the idea of ‘liking it’ or ‘not liking it’ is kind of thrown away. I’ve taught
theoretically about being against the idea of idealism. There’s no such thing as an ideal. There’s
no utopia. There are only options within a contingent world. I now look at this, and say, “Those
are only words.” And now I absolutely cannot tell you there’s a favourite scheme. They’re
different, and they have different qualities. And I’m in a Sophie’s choice. I’m looking at two
characters. Do I love one more than the other? No, I love them differently. Or I’m looking at
faces, and it’s not a classically beautiful face. But it’s a compelling face, and it’s actually more
interesting than the classically beautiful one, meaning that you are challenging the notion of
beauty.”403
It is precisely this strategy of combinatorial design – of avoiding any singularity, of opening up
beyond the boundaries of intuition, and of cycling through different iterations – that has encouraged
Mayne to explore the use of AI in his office.404 While Grasshopper can generate multiple outcomes,
these have to be produced manually one-by-one over a period of time, whereas the beauty of more
advanced AI tools is that they can generate an almost infinite number of options instantaneously. But
the challenge for Morphosis, is not only how to generate these forms in 3D – the problem that Coop
Himmelb(l)au is also facing – but also how to control them sufficiently to make them useful within an
architectural framework.


Traditional design is inherently intuitive, and therefore subjective.405 As Watanabe observes,
“Architects are normally not conscious of the mental processes they use to arrive at judgments and
selections.”406 As such, the opportunity afforded by working computationally is to make the design
process more objective, by externalizing it.407 The promise of AI techniques is therefore to make
design more scientific: “They make the act of designing – which up to now has been done through
experience and intuition – a scientific act.”408
The problem, however, with GANs is that there is no way to tell how or why they are performing
certain operations. In this sense they are little different to intuition. Both GANs and human intuition
are black boxes, as observed earlier. From this perspective, it seems pointless to look for any
scientific objectivity in the use of GANs. Satoru Sugihara, a computational architect who has himself
worked for Morphosis, summarises the issue as follows:
“While the results of these systems may make sense to us, if we precisely traced the signaling
process of neurons and connections one by one, we wouldn’t necessarily understand the
systems’ behavior throughout the entire process. This lack of understanding could be compared
to our many hypotheses about human intelligence, in that we still don’t understand how our
brain activities determine our behavior, even though we can now trace the precise activities of
brain neurons.’
GANs might be more suited for experimental design, an approach that is searching for novel,
surprising and inspirational results that jolt the imagination, and open up new possibilities. This in
itself is no small contribution. However, the challenge for architects working within professional
practice is to design a building operating within a precise controlled set of constraints. After all,
architecture is nothing without constraints.
Zaha Hadid Architects
Patrik Schumacher, principal of Zaha Hadid Architects (ZHA), has also been exploring the potential
of AI in both the ZHA office and the AA Design Research Laboratory (DRL). Schumacher’s interest

in AI, however, is motivated by different concerns. Unlike Prix and Mayne, Schumacher is not
interested in speeding up the design process or to generate a multiplicity of design options. Rather he
is interested in simulating how spatial organization might influence social behavior and – vice versa –
how social behavior might influence spatial organization, by using populations of AI informed ‘agents’
to model the behaviour of occupants in Utility AI:
“In both arenas – and they actually feed into each other – ZHA and AA DRL, the use of AI is
involved in the development of advanced simulations of occupancy and life processes in built
environments and designs we create. We believe that on the level of complexity and dynamism
of contemporary social institutions particularly in the world of corporate headquarters and
campuses and maybe universities and research campuses. . . that this can no longer be handled
with a fixed schedule of accommodation but must involve a more complex sense of what an
architectural brief is, namely parametrically variable event scenarios. So these will be simulated
with agent populations.
Schumacher refers to his research in this area as ‘agent-based parametric semiology’. He uses the
term, ‘semiology’, because these environments are ‘information rich’: “They are not just physical
barriers, and channels and opportunities, but they are full of semantically encoded social protocols,
and the societal and situational meanings are embedded and inscribed in these built environments.”
The agents therefore need to have the capacity to respond differentially to these semiological codes:
“For instance, for a corporate domain we look at various departmental affiliations, team associations,
whether they are outside consultants or internal staff, hierarchy level(s). So they are highly
differentiated agents.
Why does Schumacher use AI for this? Technically, it is quite possible to analyse video footage of
actual people in real spaces, in order to try and identify the various types of social interaction and the
factors that drive that interaction. However, there are limitations to this approach. Not only would it
raise privacy issues for those being observed, but it would also be difficult to reconfigure the furniture
in order to test out alternative spatial configurations. As a result, computational models are much
more suitable, as they can be used to simulate various social scenarios and spatial organizations. This
allows data to be collected regarding the type, location and duration of interactions, the characteristics
and spatial configuration of the location and so on. And this in turn provides information about the
types of social interaction either afforded or prevented by a particular spatial organization. Finally,
machine learning can then be used again to test the intensity of social activity based on a revised spatial organization.413 This is another example of how simulations can provide a huge amount of data
for subsequent research.414 It also highlights the potential of using a ‘digital twin’ to test out the
performance of an existing building.415
Here, then, we have three contemporary architects with different motivations, each exploring different
approaches to the use of AI in their design practices. While Prix is interested in speeding up the
design process, Mayne is interested in the potential of differentiation, and Schumacher is interested in
testing out the relationship between spatial organization and social behaviour.416 This highlights how
AI should be understood not as a singular, monolithic technique, but rather as a range of techniques
that can be deployed in a variety of different ways.417
AI Fabrication
Deep learning is very effective in tasks involving perception. But its capacity to operate in other
domains remains relatively limited, as Stuart Russell points out:
‘While perception is very important, and deep learning lends itself well to perception, there are
many types of ability that we need to give an AI system. This is particularly true when we’re
talking about activities that take place over a long time span. Or very complex actions like
building a factory. There’s no possibilities that those kinds of activities can be orchestrated by
purely deep learning black-box systems.’418
To illustrate his point, Russell describes the challenges of trying to use deep learning to build a
factory, an example that is highly relevant for architects:
‘Let’s imagine that we try to use deep learning to build a factory. (After all, we humans know
how to build a factory, don’t we?) So we’ll take billions of previous examples of building
factories to train a deep learning algorithm; we’ll show it all the ways that people have built
factories. We take all that data and we put it into a deep learning system and then it knows how
to build factories. Could we do that? No, it’s just a complete pipe dream. There is no such data,
and it wouldn’t make any sense, even if we had it, to build factories that way. We need
knowledge to build factories. We need to be able to construct plans. We need to be able to
reason about physical obstructions, and the structural properties of the building. We can build

AI systems to work out these real world systems, but it doesn’t achieve it through deep learning.
Building a factory requires a different type of AI altogether.’419
In fact, in and of itself, AI is unable to fabricate anything. The reason for this is straightforward
enough. Materials are analogue – and, by extension, so too are buildings – whereas the digital is
immaterial. From this perspective, there is no such thing as a digital building.420 And even when we
refer to ‘digital fabrication’, the actual fabrication relies on analogue processes have been around
since the beginning of time.421 For what is 3D printing, but a form of additive manufacturing, no less
than brick laying? And what is Computer Numerically Controlled [CNC] milling, but a form of
subtractive manufacturing, no less than carving, chiseling and sawing?422 As such, the term ‘digital
fabrication’ is misleading. Strictly speaking, we ought to be using the expression, ‘digitally controlled
fabrication,’ as the term, Computer Numerically Controlled (CNC), makes clear.423
By extension, there is no such thing as ‘AI fabrication’, although there can be ‘AI controlled
fabrication’. AI consists of algorithms, and algorithms are simply instructions. Algorithms do not
fabricate anything. All they can do is to control the fabrication process.424
But the issue of ‘control’ goes further. It can also apply to the questions, such as perception and motor
skills, in unstructured environments. Although AI controlled robots are good at most repetitive tasks,
they struggle to deal with relatively simple physical tasks, such as selecting a brick and placing it on
top of another. Although this is a relatively simple task for a human, it is quite a challenging one for a
robot. As yet – somewhat surprisingly perhaps – robots simply do not have a high enough level of
dexterity. As Rodney Brooks wryly observes, ‘Everyone’s saying robots are coming to take over the
world, yet we can’t even answer the question of when one will bring us a beer.


‘Although the design and fabrication of . . . architectural forms might involve the use of digital tools, in and of themselves the forms are
not digital. There is no such thing as a digital material, if by ‘digital’ we understand the opposite of ‘analogue’. By extension, there cannot
be any such thing as digital architecture, if by ‘architecture’ we understand material buildings. This is not to say that there cannot be digital
designs of buildings, but these designs are in effect immaterial models.’ Source?

As I have noted previously, ‘Although there is a continually expanding list of digital fabrication technologies, with new
technologies being developed all the time, especially in the area of 3D printing, at their core these processes have existed for millennia.
After all, what is brick construction other than a form of additive manufacturing? What are carving, chiseling, and sawing other than forms
of subtractive manufacturing? And what are processes, such as the stacking of bricks, bending of pipes, or folding of sheets of lead but
analog versions of processes now often undertaken using robotic tools? As such, we might recognize that what digital fabrication can do is –
in some senses – nothing new.’ Neil Leach, ‘Introduction’, in Philip Yuan, Achim Menges, 

And yet this is precisely the challenge that Autodesk is now addressing. Its new AI research team has
been looking at how a robotic arm might learn how to build. The initial challenge was how to get the
robotic arm to recognise and pick up Lego bricks, and eventually stack them up to form a structure.
The answer here is to train the robotic arm not in the physical world, but in a simulated environment
by developing a ‘digital twin’. Just as AlphaGo ZERO was able to teach itself to play go through
reinforcement learning, by playing games against itself at the extraordinary rate of 20 games per
second, so too the Autodesk AI research team has trained the robotic arm in a digital simulation, after
many millions of iterations.426 This opens up a range of possibilities from a robotic arm sorting and
stacking bricks completely on its own, to an entire assembly line being reconfigured literally
overnight.
The ultimate challenge, however, would clearly to get a robotic arm to stack actual bricks on a
construction site. How long will it be before we are able to ask a robot to fabricate something?
Kuka, build me a wall.



The Future of the Architectural Office
What role will AI play in the future of the architectural office?
From the perspective of the standard architectural office, the most common application of AI is likely
to be through AI based software developed by existing architectural software companies, such as
Autodesk. In fact much of Autodesk’s software, including Fusion 360, is already AI-enabled. The
vision at Autodesk – like everywhere else – is not ‘AI versus humans’, so much as ‘AI assisting
humans’. AI will take the form of AI assistants – at least for the foreseeable future.
Mike Haley, Senior Director of the Machine Intelligence AI Lab at Autodesk Research, offers his
personal prediction of what it will be like to work in the office of the future. According to Haley, we
will literally be talking to our computers, and giving instructions based on what we can see on the
screen:427
Haley: “OK, Autodesk, I want to design a chair.”
Autodesk: “Here are some popular chairs. Scroll through them and select some examples to
give me an idea of the type of chair you would like.”
Haley: “OK, I’m making some selections now. Can you show me those together?”
Autodesk: “Alright, here are the chairs you selected.”
Haley: “OK. Those chairs are interesting. Could you combine all possible pairs between those
chairs. Find out what’s in between them.”
Autodesk: “Alright. There are 15 possible pairs. I’m morphing the form between all pairs,
generating a large range of combinations.”
Haley: “OK, Autodesk. I’d like to explore the space between these shapes. Could you combine,
mix and mesh these designs for me.”
Autodesk: “Here are 5 possibilities between each of the 15 pairs. There are a total of 75
possible designs.”
And so on.
This is not an unrealistic vision. After all, much of the technology for this scenario is already
available. We already talk to Siri, Alexa and other AI assistants. So why wouldn’t we also be talking
to our computers?


There is, however, one aspect of this that is a little less convincing. In this simulated scenario
Autodesk displays a range of ‘popular chairs’. But could we not argue that sometime in the not too
distant future Autodesk will already know our preferences, and be able to customize the selection?428
Just as our mobile phones know what news we prefer, Spotify knows what music we prefer, Pinterest
knows what images we prefer, and Amazon knows what kind of books we prefer, so in the future
surely our computers would surely know what designs we prefer. Algorithms would be able to track
our every design decision, and record them.429 As such, Autodesk would already know what chair
designs we prefer. Instead of saying, “Here are some popular chairs,” it would be more likely to say,
“Here are some new designs that you might like.” Not only that, but eventually AI would surely be
able to generate new design options tailored to our known aesthetic preferences. The next step, then,
is to ask AI to simply design a chair for us:
“Autodesk, design me a chair.”
Superusers
Randy Deutsch offers a slightly different vision. He believes that the office of the future will be
dominated by what he calls ‘Superusers’ – ‘high-performing, high-functioning, highly connected, and
highly motivated’ – design technology specialists who, he believes, ‘represent the near future of
architecture’.430 Certainly, in recent years we have witnessed the growth of computationally advanced
research units operating in many of our leading offices – the Specialist Modelling Group within
Foster + Partners, Gehry Technologies within Gehry and Partners, and ZHCODE within Zaha Hadid
Architects, to name but a few examples. In many cases, these teams have proved indispensible in their
use of advanced computational skills to address design challenges in the increasingly complex
architectural world of today.
But would the introduction of AI into the architectural office necessarily lead to a further expansion
of this trend? The paradox of technology is that it might depend on increasingly complex computation
– and certainly AI is no exception to this – but, as far as the average user is concerned, in general it is
becoming ever easier to use. Take the way that we can ‘swipe’ our phones. Or take the way we can
now use facial recognition to switch them on. In fact facial recognition will soon mean that we will
not need to carry around passports, keys, credit cards or money. In fact in China it is already possible




to pay for goods using facial recognition. Paradoxically computationally complex technology often
makes life simpler, rather than more complicated.
This is not to say that it is easy to engineer such seemingly effortless technological advances. On the
contrary, it is extremely challenging. The logic here is not dissimilar to that of minimalist architecture.
In order to make minimalist architecture look simple and effortless, considerable effort must be
invested in resolving complexities. Details need to be controlled obsessively, and connections
concealed.431 Simplicity and effortlessness do not come easily.
It is likely, then, that AI will actually make life easier and simpler. Here a parallel can be found in the
introduction of Grasshopper. Anyone who has spent hours or even days laboriously writing code in
RhinoScript, MEL (Maya Embedded Language), Visual Basic, 3dMaxScript, or any other computer
programming language, will know how much easier it is now to work with Grasshopper, the plug-in
for Rhino that bypasses code by using pictographic forms of information. And, arguably, working
with AI will make it even easier still. This is in line with Haley’s view that we will simply talk to our
computers.
Autodesk v the Superuser
Here, then, we have two radically different scenarios unfolding. On the one hand, Haley believes that
companies such as Autodesk will develop user friendly AI applications for making the design process
easier, to the point that the user might not even need to draw anything, let alone have any advanced
understanding of the technology. On the other hand, Deutsch believes that the office of the future will
be populated by computationally advanced ‘superusers.’
In the end, however, both situations are likely to prevail. Most users will find AI-based tools
extremely easy to use. But some will wish to customize them in order to exploit their full potential. In
short, although Haley is obviously correct to assume that AI will make life easier for the average user,
Randy Deutsch is equally correct to assume that the office of the future will be dominated by digital
technologies and that superusers will play an increasingly significant role.
Developer AI
Real estate services have woken up to the potential of AI and AI-assisted operations for selling real
estate. AI has been used to predict property values and potential price fluctuations, to personalize and
tailor customer applications, to target potential clients based on their tastes, online activity and
purchase history, to fact check listings, and in general to introduce efficiencies and cost savings, such


The same situation obviously applies to writing. To make a text easy to read, considerable effort must be made to ensure that the words
flow naturally.



that one company claims to have reduced the cost of commissions to 2 per cent of the price of the
property.432
But what about the design and development of real estate itself? How might AI help architects when
working for developers? Here AI can play a significant role, in dealing with the relatively complex
range of factors that inform real estate development, and finding design solutions that realize the
maximum profit of any given site. Out of the many startups to address this issue are two companies
that stand out in terms of their size, and the investments that they have attracted, Spacemaker AI
(Spacemaker), based in Oslo, Norway, and Xkool Technology (Xkool), based in Shenzhen, China.
Spacemaker AI
Spacemaker was launched in Oslo in late 2016 by architect, Håvard, computer engineer, Carl
Christensen, and financial analyst, Anders Kvale. Spacemaker soon started breaking into the market.
In its first significant round of venture capital funding it picked up $25 million. By the end of 2017,
Spacemaker was named as one of the 500 most interesting startups by Hello Tomorrow.433 In 2018 it
was named the ‘hottest place to work’ by Norway’s leading business newspaper, Dagens
Næringsliv.434 And by 2019 Spacemaker was named Norwegian ‘Start Up of the Year’.435 Spacemaker
has 100+ employees, and recently set up additional branch offices in Barcelona, Stockholm, and
Cambridge, Massachusetts, close to Harvard and MIT campuses. In November 2020 it was announced
that Spacemaker had been acquired by Autodesk for $240 million.436
The primary intention of Spacemaker is to find the smartest way to realize the potential of any
building plot. Spacemaker is intended to be used primarily by property development professionals. As
Steve O’Hear puts it, ‘Described as “the world’s first” AI-assisted design and construction simulation
software for the property development sector, Spacemaker claims to enable property development
professionals, such as real estate developers, architects and urban planners, to quickly generate and
evaluate the optimal environmental design for any multi-building residential development. To achieve
this, the Spacemaker software crunches various data, including physical data, regulations, environmental
factors and other preferences.

The premise behind Spacemaker is that the design of buildings in an urban setting is becoming
increasingly challenging for architects. There is simply too much data and complexity. And this is
where Spacemaker comes in. The Spacemaker team sees its role as translating architecture to
mathematics. To this end Spacemaker has developed an engine that generates, optimises and analyses
buildings of different solutions based on input data and preferences defined by the user.
Once the site has been defined, and the various constraints and parameters have been inputted, the AI
engine is then engaged, and the architect is presented with a range of optimized solutions. “So that
means that architects are now able to explore a really wide variety of alternative solutions for a site,
instead of only a handful of solutions. And at the same time the solutions that they are looking at are
aimed at maximizing space utilization while also satisfying requirements and regulations in the area.
This means that the architect can work in a completely different way, in a much more informed and
iterative process.”438 What results is not simply a change in the design process itself. It also represents a
change in the way that architects design, whereby the AI becomes an ‘invisible assistant.’
Spacemaker also offers a platform that uses the cloud to allow the various stakeholders in a project to
come together to study ‘surrogate models’ of the proposed building. This allows them to ‘trade off’
various performance factors in real time, so that they can quickly find the solution that suits them best.
In this sense Haukeland sees the platform as offering ‘customer value,’ that has a particular appeal to
developer clients. Indeed, as Haukeland observes, developer clients are beginning to insist that
architects use AI in the design process, so that they find the most effective and efficient solution for
their client: ‘The developers really want architects to use Spacemaker. That technology is something
they want. It is a requirement from their clients.’439
This seemingly throwaway comment should not be underestimated. This surely is the single most
important factor that will lead to the AI revolution in architectural profession. Clients will want
architects to use AI in order to maximise their Return on Investment (RoI) and optimise the
performance of their buildings. It is as simple as that. Forget progressive aesthetics, forget
experimentation. The lasting impact of AI will be guaranteed, once the majority of clients start to
insist on their architects using AI. Thereafter we could predict that architects will begin to brand
themselves in terms of their practice-based use of AI, in order to attract clients, much as they now
brand themselves as being LEED or BREEAM certified in terms of environmental sustainability.
Importantly, the platform allows users to explore different options. Hence the name of Spacemaker’s
recently released generative platform, Explore. Kara Vatn describes how their platform, Explore,
operates: ‘With Explore, architects and urban planners can continuously generate and review different
site proposals, and focus in and iterate at both a macro and micro level. Users can make changes at any
point in the planning process and immediately see the impact and alternative options for their site, all
in one fast and uninterrupted workflow.’440
Not only does their platform serve to increase the range of options, but it also suggests options, some
of which might not be immediately apparent. In fact on occasions the platform can come up with
suggestions that no architect would ever have imagined, but that nonetheless offer the best solution.
Haukeland cites a particular example of a project, affectionately known as their ‘Giraffe’ project,
where the computer was able to find the complete opposite of what an experienced architectural mind
might have thought appropriate:
‘The places where the architects thought that it would be smart to build tall buildings, and the
places where they thought it would be smart to build a dense wall, all the things that they
intuitively thought would be smart – because they had hundreds of projects of experience –
were flipped around. Because when you get the complexity of thinking of a multi-objective
organizational problem. . . you are really not able to see the patterns that a computer can find.
So what happened was that the computer was able to find a pattern as to how to solve that site
that you would never come up with yourself.’
Again, the possibility had always existed, but – like move 37 in the AlphaGo match – no one had
thought about it before. What this suggests is that from a strategic point of view, planning and the
game of Go might have more in common, than might first seem apparent.
The platform serves an AI-based assistant, intended not to displace the architect, but to serve as a
prosthetic extension of the designers’ abilities: ‘Explore isn’t replacing creativity. Instead, it provides
inspiration. It uses AI to deliver a vast number of options but it is up to the user, using their experience,
to select those that they wish to investigate further; the user is in control, with Spacemaker supporting
their decision-making.’

Christensen describes their approach as being similar to how a self-driving cars works. A self-driving
car relies on AI, but it also relies on many other technologies. Spacemaker is experimenting with a
number of different technologies, including deep learning, with a view to incorporating more
advanced AI. Although the Spacemaker team does not disclose full details of what they use, for the
moment it would seem that their primary focus is on topological optimisation and machine learning,
rather than deep learning:
“It’s a real mix-up of different things, because the core idea is to bring everything together in
one platform. So we do use a lot of machine learning, but we do use other algorithms and ways
of modelling the world as well. And we generally say that it is AI like a self-driving car is an
AI. It’s a lot of different things coming together to create a result. So we do use generative
design. We use optimization. We use simulation models of the world. We use machine learning
models for many things, like surrogate models for understanding the physical environment - for
example, how you would change a design to make it better for many factors at once.”443
Indeed, Christensen sees the role of AI as resting ‘on the shoulders of humans’ both to guide them and
also to give them superpowers, so that humans remain firmly in control: ‘To make AI successful, it
needs to be on the shoulders of humans, giving them superpowers, and not telling them what to do.
That would be like a self-driving car driving where it wants to go.’444 Nonetheless, as Maria Dantz
explains, ‘We are an AI platform, but we do want to empower our users. So we do not believe that AI
is going to replace anything. But we do firmly believe that in the workplace of the future architects
using AI will replace architects that don’t.’445 This is one of the core beliefs at Spacemaker, and one of
potentially huge significance. It is worth repeating: ‘In the workplace of the future architects using AI
will replace architects that don’t.’446
One factor that might cause this to happen is a rise in insurance premiums. Just as insurance
premiums for human drivers will likely rise in the age of the self-driving car, as human driving skills
diminish – making human driving prohibitively expensive – we could imagine that the same might
happen with architectural design. AI is able to provide a necessary check not only in terms of risk
management, but also in terms of error minimalisation, making it an invaluable tool from an insurance
perspective. Might we not therefore find that professional indemnity insurance for architects not using AI will skyrocket, forcing architects to use AI, and making good on Spacemaker’s prediction that
architects using AI will replace those not using AI?
Cedric Price once famously asked, ‘Technology is the answer, but what was the question?’447 By
contrast, for Haukeland, ‘Technology is just a lever to solve a customer problem.’448 Haukeland sees
their platform as a ‘performance driven tool for the masses’.449 This raises two important issues. On
the one hand, it illustrates how AI can be seen not only as an aesthetically driven design tool,
generating some visually striking designs, as we have seen in the previous chapter, but also as a
performance driven design tool, generating cost efficient and performance-based solutions. On the
other hand, it highlights how easy it is for everyone to use in an architectural office.
The problem with parametric tools has been that they are often too advanced for many architects to
use: ‘It was only the parametric geeks in the office that were able to use them.’450 With AI, however,
computation becomes so much easier to use. It is not simply about intelligent trade-offs. It is also a
question of recognising the importance of the whole package in offering smart sketching tools and the
integration of the whole design process on to one consolidated platform. “I think that you can never
make AI the new way of working without really understanding all of the customer needs, and all of
the problems, and once you understand that complexity, and what really drives the value, then AI is
just empowering that. . . And that’s also why I personally really like Carl’s analogy of the car,
because it’s really just about making it easier to drive.’451 The aim is to provide everyone with tools
that are extremely easy to use, and accessible to anyone, no matter how little background experience
they have in computation. From this perspective, the Spacemaker model is closer to Haley’s model of
‘Autodesk, design me a chair’ than to Deutsch’s model of the superuser.

XKool Technology
Xkool Technology (Xkool) was founded in 2016 by two architects, Wanyu He and Xiaodi Yang.
Xkool, is a contraction of ‘ex-Koolhaas’, and refers both to He’s previous experience of working
under Rem Koolhaas for OMA in Rotterdam and Hong Kong, and to the popular term, ‘Xkool’,
which, according to the Urban Dictionary, refers the highest level of ‘coolness’ that can be
achieved.452 Xkool claims to be ‘the world's first innovative technology company that uses cuttingedge technologies such as deep learning, machine learning and big data to successfully apply artificial
intelligence to urban planning and architectural design, is based on its own core algorithm technology and in architectural design.’453 Xkool has also been highly successful in attracting investment. By
early 2020 Xkool had secured a joint investment of 100 million RMB from a private equity firm,
Vision Night Capital and a state-owned capital investment firm.454 Xkool is a 100+ person startup,
based in the Vanke Design Commune in Shenzhen, known as the ‘Silicon Valley’ of China, but with
further branches in Beijing, Shanghai and Chongqing.
Xkool has developed a cloud-based platform for using AI across a range of scales from interior design
to urban planning that can even be accessed from a mobile phone. Like Spacemaker, Xkool also
caters for the property development market, although 70% of its users are architects. And like
Spacemaker, XKool also sees its AI-based technology not as a replacement of the architect, but rather
as an ‘AI assistant’, a prosthetic extension to empower the architect. The idea is to hand over the
routine and repetitive work to the computer – work that the computer is probably capable of doing
faster and more accurately – so as to leave the architect more time to devote to the creative process.
The role of AI here is to tirelessly adapt to the ever-changing requirements of the design process, and
to come up with informed suggestions. As He notes, “There is no doubt that future cities will still be
created by the human will, but in a different way, empowered by technologies.”455
Unlike Spacemaker, however, Xkool focuses on deep learning. Its objective is to streamline the
design process and make it more efficient and creative by using deep learning to not only search
through a vast range of possibilities, but also automatically generate designs based on the trained
models, and then, evaluate and return the outcomes from various evaluation models. In effect Xkool
uses generative adversarial networks (GANs) to produce a range of potential solutions. It can also
take account of site conditions and environmental factors so as to evaluate possible outcomes and
identify the best potential solution.
The story of Xkool can be understood as a story of constantly evolving design processes. He and
Yang first used AI back in 2011 for an entry for the international competition for the Shenzhen Bay
Eco-Tech City, that subsequently became one of the first AI assisted designs to be actually built. The
breakthrough came, however, when they developed a GAN based technique involving a “design
brain” and an “evaluation brain”, with the formation of Xkool in 2016. Broadly put, the role of the
“design brain” was to generate a range of possible design solutions based on a massive dataset of
previous designs. The role of the “evaluation brain” was to evaluate and rank these designs based on
land value and other local data. In effect, the “design brain” and the “evaluation brain” worked together, with the “design brain” generating possible designs, and the “evaluation brain” evaluating
them.456
This first set of tools, however, had their limitations. Although useful in speeding up the design
process and reducing costs, they did not provide sufficient ‘references’ to be really practical.457 The
situation was improved with improvements in machine learning that Xkool subsequently incorporated
into its working method.458 This led to the launch of Xkool’s “Rosetta Stone” research initiative, so
called because it looked at the possibility of generating a range of design outcomes based on different
styles of architecture, where these styles were seen as the equivalent of different languages.459 They
then developed a large database of different design styles, based on material extracted from previous
architectural designs.
The real breakthrough, however, came as a result of the success of the AlphaGo ZERO initiative.
Xkool developed a new technique using reinforcement learning that meant they did not need to rely
on datasets of existing buildings. Instead the system was capable of extracting its own rules from
previous examples, and generating options that were genuinely innovative and creative:
‘In 2017, the official publication of AlphaGo ZERO showed research results that promoted the
application of reinforcement learning technology in developing intelligent design tools. It freed
design tools from the limitations of the database of real cases towards a direct use of initial
models generated by rules they have learnt in confrontation and iteration. By repeating this
process, a model that best meets (or even exceeds) human designers’ expectations and has a
true potential for exploring the unknown is finally generated.’460
In their latest stage of development, Xkool now sees the role of AI as being broken down into four. 

distinct stages: recognition, evaluation, reconstruction and generation.461 ‘Recognition’ is used to
search for complex and hidden patterns in the data generated by cities. Of course, humans are also
capable of recognising patterns, but the sheer amount of data makes it impossible for them to do so
effectively, and there are often ‘blindspots’ in any analysis undertaken by humans. The next step,
‘evaluation’, involves detecting patterns in this data, such as pedestrian movement or traffic flow.
This can help to reveal problems, such as traffic congestion or a lack of public facilities.462
After that comes ‘reconstruction’, a background process that helps to form a basic understanding of
the challenge. The development of this technique allowed Xkool, for example, to launch a platform,
“Non-Existing Architectures,” in 2019, that was able to generate relatively convincing ‘hallucinations’
of buildings based on a massive dataset of building images.463 Xkool has also developed a technique,
called AI-chitect, for constructing a complete image of a building based on an outline sketch, a
technique first displayed in the Eyes of the City exhibition in the 2019 Shenzhen Biennale of
Urbanism/Architecture.464 This brings the vision of Xkool closer to the vision of Spacemaker, making
AI exceptionally easy to use.
However, reconstruction can only operate at a relatively basic level, to produce little more than
impressionistic designs. It therefore depends on the final step, ‘generation’, to provide a more detailed
and refined output. ‘Generation’ is similar to the process of turning a rough sketch into a detailed
design. Xkool has developed two tools for this. Firstly, at an urban scale they have developed their
Intelligent Dynamic Urban Planning and Decision-Making Platform, an integrated dynamic platform
which allows the overall plan for urban planning proposals to be modified, as each component part is
itself modified. This platform has already been used in the planning of Xiong’an New Area, a new
urban development in the Beijing-Tainjin-Hebei economic triangle. Secondly, at an architectural scale,
they have developed their “AI Design Cloud Platform.” As the name implies, this platform operates
through the cloud, and does not require any software to be installed.
The latest development in this platform has been the introduction of Koolplan, an AI assistant to
generate more detailed floor plans and elevations. Koolplan offers designers a range of possible
options from which to choose their preferred solution, a significant improvement on earlier shape
grammar techniques that only offer designers a single solution.465 Xkool is now not far from developing a fully automated process for generating actual architectural drawings.
Spacemaker v Xkool
Spacemaker and Xkool were both launched in 2016. Both claim to be the first company in the world
to develop an AI-assisted platform for architectural design and construction. Both have a particular
focus on property development. Both have attracted significant funding. And both believe that – for
the moment at any rate – the architect still plays an important role in the design process. But are they
in fact so similar?
When it comes to comparing Spacemaker to Xkool, many factors need to be taken into account. For
example, Spacemaker caters primarily for a Western market, whereas Xkool technology is currently
available only in China.466 But when comparing the two companies, we need to examine exactly how
they operate. After all, it is not always obvious how much AI is involved, or indeed what kind of AI.
There is, for example, a significant difference between GOFAI techniques, such as topological
optimisation, and deep learning.
Although Spacemaker uses AI, it also uses a range of other technologies. As Maria Dantz comments,
AI is not necessarily the main driver of their processes, as least as far as their customers are concerned,
‘Our current website is very much about an AI centered platform, but AI is just one part of the entire
platform. A big part of what our users actually like are the analyses. It’s the analytics. It’s being able
to use data in a way that they weren’t able to use and combine data before, in a model. And then you
can basically integrate that with the optimisation of plans and the AI part. So that is just one aspect,
but it’s not necessarily the driver for every one of our customers.’467
By contrast, Xkool makes extensive use of machine learning, especially deep learning, although the
company leaves open the opportunity for human intervention with KoolPlan and other features. The
problem with deep learning, of course, is that it consumes vast amounts of data. But this is where
Xkool has something of an advantage, in that it obtains its data from local clients and collaborators,
such as real estate developers, legal urban data suppliers and government companies. Indeed, China
produces significantly more data than any country, and has fewer concerns about privacy issues. As
has been observed, ‘If data is the new oil, China is the new OPEC.


Importantly, Xkool also obtains data from data labeling companies. China’s fast growing AI
industries cannot do without high-quality and well-labelled learning data that is highly specified and
targeted for specific applications. Although open-source, labelled data is available from other
countries, it is still unsuitable for specific applications. For example, labelled housing data from Japan
is incompatible with China’s housing market. However, Chinese ‘data farms’, the equivalent of
Amazon’s ‘Mechanical Turk,’ are capable of supplying compatible data for specific applications. This
is the new industry that is silently supporting AI startups and enterprises in China.
Although they are not in direct competition, it would be interesting to see whether Xkool’s investment
in deep learning gives Xkool an advantage. Or will Spacemaker’s use of a range of tools in addition to
AI make its platform easier to control and more user friendly? And what will happen to Spacemaker
now that it has been acquired by Autodesk? Only time will tell.
Re-Designing Design
It is worth reflecting on how computation in general and AI in particular have changed how we
operate these days. For example, how do we go about writing an essay or article in the age of Google?
Chances are that we will start by making a Google search of a few key words associated with the
subject matter. This is how we access knowledge these days. The astonishing improvement in the
speed of search engines over the past few years has meant that within a fraction of a second we can
search all available information online. As such, the traditional method of ‘browsing’ through books
in a library has now become if not totally redundant, then at least downgraded to a recreational past
time.
Or how do we take photos in the age of the digital photography? In the old days of manual
photography we would carefully set up the camera for one ideal shot. In the age of digital
photography, however, we take a burst of sample shots. We then review them, and select our favourite
shot, and enhance it using editing techniques available on every smart phone. It is no longer a
question of the expert photographer setting up the ideal shot, but rather of the informed user taking an
array of sample photos, and then selecting and enhancing the best one.
In the age of AI, this process of ‘sampling’ or ‘searching’ has also become the first step in the design
process. Instead of developing a single design, the tendency now is to define the constraints, and
conduct a search, in order to generate a range of possible outcomes. With Grasshopper this amounts to
writing a definition, and adjusting sliders to generate as many options as needed. With AI a range of
options can be generated automatically. The assumption here is that all possibly solutions already
exist, and that it is simply a question of searching for them:


‘If we think through the logic of the search in the context of ‘design’, what such an approach
suggests is that if all possible solutions already exist, it is simply a question of defining a set of
constraints and conducting a search, and then selecting one of the many outcomes. The
potential implications of this are far reaching. Not only does it challenge the traditional notion
of, but it also suggests that if there is still any creativity in the ‘design’ process, it should lie,
firstly, in defining the constraints that generate the range of possible solutions to a problem,
and, secondly, in developing an effective method of filtering or evaluating them.’469
This has major implications for the logic of design itself. The top down architect form maker of the
past gives way to the architect as controller of processes. This shifts the emphasis from the ‘creativity’
of the designer towards the rigor of the search itself, and challenges the whole notion of the ‘creative
genius’. However, we can still use our traditional aesthetic sensibilities – our architect’s ‘eye’ – to
evaluate the outcomes. Indeed the architect’s eye remains one of the most valuable assets in the
design process, and can be surprisingly quick at making an evaluation. As a result, we can observe
how some architects and designers deploy highly sophisticated software to generate possible solutions,
and then simply use their ‘eye’ to judge the most attractive.470
As a corollary to this, we need to rethink the terminology that we use. If the notion of a singular
design is being replaced by a range of potential sample options, should we not refer to them as
“outcomes?” And if the notion of designing is to be replaced by a search for possible outcomes,
should we not refer to this process as “searching”? Surely the designer here is merely the instigator of
a process, and the result of that process is more of an outcome than a design in the traditional sense.
The introduction of AI into architectural design also allows for a more exhaustive and comprehensive
search of the solution space. In the traditional design process we tend to start by thinking about a
range of possible solutions. But our own human biases often limit that range.471 AI, however, helps us
to expand the range of solutions.472 In other words, AI exposes us to solutions that otherwise we
would not have thought about.
Interestingly, Larry Page, co-founder of Google, goes so far as to claim that AI aspires to be the ultimate search engine, ‘Artificial Intelligence would be the ultimate version of Google. The ultimate
search engine that would understand everything on the web. It would understand exactly what you
wanted, and it would give you the right thing. We’re nowhere near doing that now. However, we can
get incrementally closer to that, and that is basically what we work on.’473
‘Google, what is the answer to life, the universe and everything?’474
In 2018 I was so amazed that almost 90% of my students were writing essays about AI – and good
essays, on the whole – that I seriously wondered whether they might have been using an AI program
to generate them. As it happened, the essays had not been generated by AI. But it is now possible for
GPT-3 to generate highly convincing texts.475
AI, write me an essay.
Eventually the same will also be true for design. Soon we will also generate designs with a simple
voice command, and those designs will not only be of the highest standard, but they will also
completely match our aesthetic preferences.
AI, design me a building. 476

AI and the City of the Future
What will the city of the future look like? Will it look strikingly different to cities of today? Will it
look like something out of the Jetsons, complete with flying cars and space age buildings? Or will it
look much like our contemporary cities, with a few new buildings, but with much of the existing
building stock retained and simply retrofitted with the latest AI technologies? In other words, will the
primary driver of change be a language of novel architectural forms? Or will it be the introduction of
ever more sophisticated AI based technologies?
For Patrik Schumacher the city of the future will consist of novel architectural forms designed using
the latest computational tools. In his article in ‘Digital Cities,’ an issue of Architectural Design (AD)
published in 2009, ‘Parametricism: A New Global Style for Architecture and Urban Design,’
Schumacher outlines the design logic of Parametricism, which, he maintains, has now superseded
Modernism and other contemporary styles as the new global style of architecture. Schumacher begins
by describing parametricism as being rooted in advanced computational techniques, ‘There is a global
convergence in recent avant-garde architecture that justifies its designation as a new style:
parametricism. It is a style rooted in digital animation techniques, its latest refinements based on
advanced parametric design systems and scripting methods. Developed over the past 15 years and
now claiming hegemony within avant-garde architecture practice, it succeeds Modernism as the next
long wave of systematic innovation.’477
It is a style, moreover, with its own quite recognizable characteristics: ‘Aesthetically, it is the
elegance of ordered complexity and the sense of seamless fluidity, akin to natural systems that
constitute the hallmark of parametricism.’478 And it is a style that, although it can be expressed at any
scale from interior design to urban design, is most effective in large scale urban developments: ‘So
pervasive is the application of its techniques that parametricism is now evidenced at all scales from
architecture to interior design to large urban design. Indeed, the larger the project, the more
pronounced is parametricism’s superior capacity to articulate programmatic complexity.’479
Schumacher illustrates his article with a series of large scale urban proposals for Istanbul, Singapore
and Beijing. For Schumacher the cities of the future will look decidedly futuristic, and bear the
hallmark of parametricism.


It is now more than ten years since the publication of the ‘Digital Cities’ issue of AD, and it is worth
enquiring whether any cities designed according to the logic of parametricism have ever been built.480
Even in China, the one country whose scale of development has exceeded that of most other
countries, we can see little evidence of this. Admittedly, there are a number of large scale housing
developments – and even complete cities – that have been built, but none that subscribe to the logic of
parametricism. And although collectively the many buildings designed by ZHA across the globe
would perhaps constitute an entire city, so far no individual city has been designed exclusively
according to the logic of parametricism. It is as though developers and policy makers have not been
persuaded to adopt novel forms – and novel forms alone – when developing a city.481
Nor has there been much evidence of any large-scale developments – progressive or otherwise – in
existing cities, such as New York, London, Paris and Moscow. This is for obvious reasons. After all
the plots left vacant in these already established cities are relatively small, and seldom does it makes
economic sense to demolish existing buildings to make way for new ones. Moreover, any new
development is often constrained by building preservation orders and planning restrictions. In short,
renovation, refurbishment and interior redesign are often the preferred strategies in existing cities.
iPhone City
In his own contribution to the same issue of AD, ‘iPhone City,’ Benjamin Bratton takes a completely
different approach.482 Forget futuristic architectural forms. Think informational processes.483 Bratton
observes that there is an advanced computational device that is already changing our experience of
cities: the simple iPhone. Although the iPhone has had little impact as yet on the design of new cities,
it has already had a profound impact on how we operate in our existing cities. The development of
smart navigation apps, for example, has allowed us to navigate and understand cities in new ways,
while the introduction of roaming has allowed the car to become the new office, as a hybrid ‘car +
phone’ platform.484
In 2009 the transportation interface, Uber, was launched as ‘UberCab’, although the app for mobile
phones was not released until the following year. As such, Bratton wrote his essay before Uber came
into existence. However, it is worth considering how even more insightful his analysis of the car



Against the primacy of material form, we might therefore posit an alternative logic, and make a distinction between form – as in ‘form
for the sake of form’ – and information. If, over the past few decades we have seen a shift away from an obsession with pure form towards a
set of more performative considerations, such as structural or environmental factors, whereby form is informed by performative constraints,
should we not be recognising a further shift towards pure information?
484
It is now illegal to hold a cell phone while driving. Initially, however, most cell phones were known as ‘car phones.’ The name of one of
the most prominent British outlets for cell phones, Carphone Warehouse, bears testimony to this early history.

becoming ‘car + office’ would have been, had he been aware that the domestic car would itself
become a potential source of employment. Uber has now spawned a number of competitors, such as
Lyft, in a process that has been described as ‘uber-ification’, and ride sharing apps have now become
endemic in major cities throughout the world.485 In China companies like DiDi have proved so
successful that they have effectively forced Uber out of the market.486 The secret, as the success of
Uber has shown us, is to harness the capacity of informational interfaces to generate new kinds of
employment. In other words, computation has not given us new seductive forms, but rather new ways
of operating.
This challenges the claim made by architectural historian, Mario Carpo, in his book, The Second
Digital Turn, that big data gives us another style of architecture.487 Carpo argues that the sheer amount
of ‘messy’ data available today has led to a new messy, ‘voxelated’ style of architecture.488 Surely,
this is another example of the problem of ‘architecturalisation’ – of reading non-architectural concepts
as though they are referring to architectural forms.489 What big data has to do with architectural form
remains something of a mystery. Big data relates to information and not to form. Has the introduction
of ride sharing services actually changed the appearance of anything? In fact, if we look at Uber cars
themselves, they look identical to ordinary cars. This is because they are ordinary cars. Despite what
Carpo might claim, Big Data does not promote any particular aesthetic. It simply allows ride-sharing
companies such as Uber to operate in a more effective and efficient manner than the straightforward
taxis of the past.
The Information Architect
In his essay, Bratton includes a provocation, calling for half of all architects to abandon the traditional
model of the architect-form-maker to effectively become what we might call ‘information architects’,
drawing upon their design skills and computational abilities to develop not new designs, but new
software that could be used to rework existing structures and systems:


For ‘architecturalisation’, 
‘An experiment: one half of all architects and urbanists in the entire world should, as of now,
stop designing new buildings and new developments altogether. Instead they should invest the
historical depth and intellectual nuance of their architectural imaginations into the design and
programming of new software that provides for the better use of structures and systems we
already have. It is a simple matter of good content management. The other half, the control
group, may continue as before.’490
One architect who has seemingly risen to the challenge to become an ‘information architect’ is Shan
He. Trained as an architect at Tsinghua University and MIT, she was the founder of Uber’s data
visualization team, where she developed Uber’s kepler.gl software. Since then she has set up her own
geospatial analytics and visualization company, Unfolded.491
For He, big data does not change the forms that we design, as Carpo seems to believe, but the way
that we design. ‘How is big data changing the way we design cities?’ asks He.492 For some time now,
architects and urban planners have been using ESRI and other data mining techniques to inform their
designs, but it is the sheer quantities of data available, and the range of new tools and techniques that
is providing so much more information to inform designs:
‘Rapid developments in spatial data-mining, analytics and visualisation mean that urbanists
now have a collection of open data, advanced tooling and analytic models at hand to tackle
complex urban issues. Granted geospatial data have always been used in the planning process
to facilitate decision making, but it is the explosive volume, variety and resolution of it,
alongside increasing analytic capacity, that has fundamentally changed the horizon of urban
studies.’493
But He is not asking architects and urban designers to completely abandon their traditional skill set.
Rather she is calling on them to adopt a hybrid approach, much like the ‘extended intelligence’ model
outlined above. Here technology becomes an extension to the designer’s imagination, empowering the
designer of the future:
‘A city is not only a machine that delivers goods and services; it is a place that facilitates
human experiences. Urban designers need the basic skills to achieve both these functions, to use data as a means of designing sustainable cities while at the same time using their
craftsmanship to create enchanting city forms.’ 494
Bratton’s essay has proved to be extraordinarily insightful. The future city, for Bratton, cannot be
based on innovative forms alone. It also needs to embrace new informational systems. And we need to
rethink the logic of architectural practice, shifting away from the all but exclusive model of the
architect form-maker of the past, and opening up to also embrace a new model of the ‘information
architect’. In hindsight, Bratton’s essay on the impact of new technologies on our cities stands out as
by far the most perspicacious in the entire Digital Cities volume.
The Informational City
The idea of the informational city is not new. Manuel Castells published the book, The Informational
City: Information Technology, Economic Restructuring and the Urban-Regional Process, back in
1989.495 Castells followed this up with a trilogy of books on ‘the information age’, where he
celebrates the ‘network society’, which operates not through integrated hierarchies but through
organizational networks, and which depends upon the constant flow of information through
technology.
More recently, we have seen the development of the ‘smart city’, equipped, as Michael Batty
comments, with ‘constellations of instruments across many scales that are connected through multiple
networks which provide continuous data regarding the movements of people and materials and the
status of various structures and system.’ 497 Batty adds, however, that in order to be smart these
systems need to be integrated into an effective whole, so as to provide some overall benefit: ‘Cities
however can only be smart if there are intelligence functions that are able to integrate and synthesise
this data to some purpose, ways of improving the efficiency, equity, sustainability and quality of life
in cities.

More recently still, Bratton has published The Stack, where he extends the model of the networked
society and the smart city.499 Instead of being limited to a single horizontal layer, Bratton describes
the networked society in terms of a vertical aggregation of horizontal layers. Bratton therefore extends
Castell’s 2D model to 3D space.500 And instead of seeing the various forms of planetary scale
computing as differentiated components, Bratton sees them as layers of a consolidated metaplatform
that takes the form of an ‘accidental megastructure’. Bratton refers to this as ‘The Stack’:
‘The Stack refers to a transformation in the technical infrastructure of global systems, whereby
planetary-scale computation has so thoroughly transformed the logics of political geography in
its own image that it has produced new geographies and new territories that can enforce
themselves. Unlike modern political geography, which divided up horizontal maps, Stack
geography also vertically layers spaces on top of one another. Instead of surveying all the
various forms of planetary-scaled computation – cloud computing, smart cities, ubiquitous
computing, massive addressing systems, next-generation interfaces, nonhuman users, and so on
– as different genres or species of computing, each off on its own, this model locates them on
layers of a consolidated metaplatform, an accidental megastructure.’501
The Stack is composed of 6 layers: the Earth layer, Cloud layer, City layer, Address layer, Interface
layer, User layer. The Earth layer that ‘provides a physical foundation for the Stack; the Cloud layer
that consists of ‘vast server archipelagos’; the City layer that ‘comprises the environment of
discontinuous megacities and meganetworks’; the Address layer that ‘examines massively granular
universal addressing systems’; the Interface layer that provides ‘imagistic and linguistic mediation
between Users and the Addressable computational capacities of their habitats’; and finally the User
layer that includes both human and nonhuman users.502
The key here is connectivity. The Stack represents the interconnected, informational pathways around
the world today in terms of either vertical or horizontal interfaces, where each layer constitutes not a
discrete separation but a form of connectivity with other layers; the City layer, for example, might
interact with the next vertical – the Cloud layer or the Earth layer – or indeed it might skip a layer and
interface with the Earth layer, or it might interface with another city on the same layer. Likewise a
city can also be understood as a city within a global network of cities. Whether we refer to the
‘informational city’, the ‘smart city’ or the ‘city layer’ of the stack, however, it is clear that cities of
today are becoming the sites of informational interfaces, where AI and AI-based apps are playing an
increasing role.



Ambient Intelligence
The impact of AI on the city does not need to be viewed at the scale of the overall city. Indeed, the
secret to understanding the city, as Jane Jacobs reminds us, is to perceive it in terms not of top down
major changes, such as master planning, but of incremental behaviours at a street level.503 The city
could therefore be understood as constituted by a multiplicity of users, no less than flocks of birds or
schools of fish are constituted by individual agents. The city might be significantly larger in scale than
individual agents; but the city is constituted precisely by individual agents. In this way, we can
understand that the city is already populated with AI-informed devices. After all, as Bratton astutely
observes, the city wears us, as much as we ourselves wear our devices.504 By extension, the city itself
can be understood as wearing our intelligent devices. Meanwhile Bratton’s notion of the Stack
highlights the interconnected operations. In the informational city of today intelligence is fast
becoming pervasive through the medium of the individual inhabitants and their personal AI-informed
devices.
We live in a world of ‘seamless intelligent devices’ that are sensitive and responsive to occupants, and
not dependent on manual control. Another way to describe this landscape of interconnected devices is
as a space of ‘ambient intelligence (AmI).’505 The spaces in which we now live conform less to Le
Corbusier’s notion of as ‘a machine for living in’ and more to Mark Weiser’s notion of ‘ubiquitous
computing.’506 Soon we will not even need to carry our devices around with us. Computation will be
seamlessly embedded in the urban environment, as freely available as the air that we breathe, and we
will be able to communicate with our environment through speech and gestures. 507 With this shift, as
technology is absorbed within the fabric of the city itself, life in the city is no longer dominated by
explicit forms of computation. The environment itself would become intelligent.
We could even imagine this intelligent environment responding interactively to our moods and
comfort levels. It would be able to stimulate us when lethargic, and soothe us when agitated;508 cool
us down when hot, and warm us up when cold. It would become an adaptive, sympathetic, nurturing
environment of ambient intelligence, responsive to our individual needs.


Examples in everyday life include aquariums of fish are often to be found in waiting rooms of dental surgeries, for the specific purpose of
calming patients down, and differential lighting used in the cabin of long haul flight aircraft to wake passengers up, although these are
simple one-way interactive processes.

Of course, there are potentially negative consequences too. We could imagine that such an
environment would be quite capable of tracking our every move and monitoring our behaviour. It
would also be capable, no doubt, of bombarding us with customized advertisements. We should not
overlook, then, the dark side of AmI. In the wrong hands, it could be highly detrimental.509 At the
same time, however, we should avoid the technological determinism that often dogs attitudes towards
technology.510 No technology is inherently bad.511 Used in the right way, AmI can be highly beneficial
to society.
Swarm Intelligence
In Emergence: The Collective Lives of Ants, Brains, Cities and Software, Steven Johnson outlines the
theory of emergence.512 To be clear, Johnson is not the first to mention this theory, and is greatly
indebted to the work of others, but the success of his book has done much to popularise the theory of
emergence.

Emergence can be observed, wherever two or more agents interact in a bottom-up manner.514 But it is
most evident in a multi-agent system whose interaction leads to a global behaviour. As the subtitle of
the book suggests, Johnson makes an explicit connection between the emergent behaviours of a range
of multi-agent systems – such as ants, brains, cities and software – no matter how incommensurable
their constituent elements.We can therefore make direct comparisons between the operations of a
city and the behaviour of a brain.

Emergence has become a highly popular term in recent architectural discourse, but it is worth
recalling that the term itself does not necessarily refer to contemporary design issues.517 On the
contrary, it could be argued that emergence could be viewed most clearly in traditional urban
formations. For it is precisely the less self-conscious forms of urban aggregation that characterise the
development of traditional settlements, from medieval villages to Chinese hutongs or Brazilian
favelas, that fits best the simple rules of emergence, such as ‘ignorance is useful’ or ‘pay attention to
your neighbours’. These forms of urbanism constitute a relatively homogeneous field of operations,
where individual components do not stand out, but conform to the pervasive logic of their surrounding
environment.
Another way to think about emergence is through the logic of swarm intelligence. This is expressed in
the decentralized, self-organising behaviour of multi-agent systems.518 As Roland Snooks observes:
‘Swarm Intelligence operates through the local interaction of autonomous agents that gives rise to
emergent collective behavior within decentralized self-organising systems.’519 A common everyday
example of ‘swarm intelligence’ can be observed when a flock of birds, such as starlings, comes in to
roost in the evening. The complex aerial gymnastics of these birds are defined not by any top-down
logic imposed from above, but rather by a bottom-up logic that ‘emerges’ out of the simple
interactions between the individual birds. As the flock swoops, soars or veers in any direction, it is not
being directed or controlled by any one particular bird. Rather each individual bird is following a
certain set of basic rules related to principles of cohesion, separation and alignment – keeping a
certain distance from the birds in front and on all sides, while flying at the same speed and travelling
in the same basic direction – and it is this that dictates the overall behaviour of the flock.

Importantly, however, a collective intelligence arises out of these individual behaviours that is not
pre-determined and fixed, but self-regulating and adaptive: ‘Constantly mutating, emergent systems
are intelligent systems, based on interaction, informational feedback loops, pattern recognition and
indirect control. They challenge the traditional conception of systems as predetermined mechanisms
of control, and focus instead on their self-regulating adaptive capacity.’520 The intelligence exhibited
in these displays of swarm intelligence, might be a relatively low level form of intelligence – such as the intelligence of slime mould foraging for food – but it is a form of intelligence nonetheless. Swarm
intelligence can be understood as a basic form of AI.

Progressive architectural culture is constantly in search of novel architectural forms. It is therefore no
surprise that the logic of the swarm has been appropriated increasingly by experimental practices as a
referential metaphor and an organizational analog for embracing complexity and developing nonlinear design methodologies that operate through multi-agent algorithms. Architects, such as Snooks
and Alisa Andrasek, have used Processing for generating such forms, while others, such as Daniel
Bolojan, have written their own multi-agent software programs. These systems are certainly capable
of generating attractive and strikingly novel forms. 521 As such, they have had a significant influence
on architectural design culture.
Once a multi-agent system has been frozen into a static architectural form, however, its complex
behaviours are necessarily curtailed and its full potential unrealized.522 And yet, as Deleuze and
Guattari have observed, a city should be understood as ‘deterritorialized’ rather than ‘territorialized’,
smooth rather than striated. It is a function of dynamic circulations and circuits, and can never be
reduced to a singular, static form:
‘The town is the correlate of the road. The town exists only as a function of circulation and of
circuits; it is a singular point on the circuits which create it and which it creates. It is defined by
entries and exits: something must enter it and exit from it. It imposes a frequency. It effects a
polarization of matter, inert, living or human; it causes the phylum, the flow, to pass through
specific places, along horizontal lines. It is a phenomenon of transconsistency, a network,
because it is fundamentally in contact with other towns. It represents a threshold of
deterritorialization because whatever the material involved, it must be deterritorialized enough
to enter the network, to submit to the polarization, to follow the circuit of urban and road
recoding.’
Arguably, then, we can glimpse the potential of swarm intelligence informing the logic of the city, if
we lose less on the static buildings, and more on the dynamic behaviour of agents within a city. A
city, after all, can never be reduced to a collection of buildings. A city is nothing without its
inhabitants. We need to distinguish between a city as a site of material deposits – as an amalgam of traces of construction – and a city as the site of spatial practices. The former can be read in terms of
an accretion of material deposits that form the built environment, and the latter can be read in terms of
choreographies of human agents whose freedom of movement is constrained by that environment.524
The city, then, is constituted not only by physical buildings but also by human agents, and must be
understood as a human-mineral hybrid system. This has major implications for how we can
understand the impact of swarm intelligence on the city.
In his book, Out of Control: The New Biology of Machines, Social Systems, and the Economic World,
Kevin Kelly has extended the principle of swarm intelligence, and shown how it can also offer us a
convincing model for dynamic behaviour of the economy, in that the economy itself also operates in a
bottom up, out of control fashion.525 As one customer copies the purchasing habits of another
customer – much like a bird following another bird in a flock or an ant following a pheromone trail –
consumer patterns begin to emerge, so that the purchasing habits of individual customers appear as a
collective whole. These behaviours, however, are bottom-up based on individual choices. They are
not controlled from above in any way. The market, then, is potentially volatile – ‘out of control’ – and
fueled by trends.
With the real estate market, these trends become spatialised across the fabric of the city. Certain
businesses begin to cluster together in particular districts of the city, as one business owner follows
the example of other business owners. Likewise, as the popularity of certain neighbourhoods begins to
wax and wane, certain districts come into vogue and others fall out of favour. Understood in these
terms, the economic behaviour of our cities could be compared to the operations of a meteorological
system. As registers of popularity and appeal begin to shift and mutate over the fabric of the city, like
high and low pressure systems, they generate an undulating economic landscape, creating points of
intensity, but so too zones of depression, reflected in real estate values. Seen in this light, the entire
city is governed by the logic of the swarm.
The Self-Regulating City
John Holland describes how the city somehow manages to maintain a form of dynamic equilibrium,
despite the constant changes that it experiences. He likens it to a ‘standing wave’ in a stream. A city can be seen as a ‘pattern in time’:


‘Cities have no central planning commissions that solve the problem of purchasing and
distributing supplies. . . How do these cities avoid devastating swings between shortage and
glut, year after year, decade after decade? The mystery deepens when we observe the
kaleidoscopic nature of large cities. Buyers, sellers, administrations, streets, bridges, and
buildings are always changing, so that a city’s coherence is somehow imposed on a perpetual
flux of people and structures. Like the standing wave in front of a rock in a fast-moving stream,
the city is a pattern in time.
After all, according to the logic of emergence, cities are physical traces of patterns of social behavior
operating over time. They are governed by principles of self-organization. For cities and towns
themselves must be understood as amalgams of ‘processes’, as spaces of vectorial flows that ‘adjust’
to differing inputs and impulses, like some self-regulating system. But how does a city manage to
maintain this equilibrium?527 Could the model of the ‘city as brain’ help us to understand this
mechanism?

The brain, as we know, does more than just think. It also serves to regulate the body. This mechanism
is often referred to as ‘homeostasis’.528 Homeostasis (or homoeostasis) is the property of a system,
which maintains a constant equilibrium when faced with internal or external variables. It is a concept
that has been used in a number of fields including biology and mechanical systems, and – more
recently – in the field of neuroscience. In the context of neuroscience, homeostasis can here be
understood as a kind of equilibrium on which the body depends for its survival.

William Ross Ashby, one of the pioneers in cybernetics, and author of Design for a Brain, developed
a device that he called the ‘homeostat’, a balancing mechanism – much like a thermostat – that
maintains some kind of equilibrium through negative feedback.529 The purpose of this device was to
model the way in which the brain achieves its own form of dynamic equilibrium.530 Significantly,
Ashby’s work caught the attention of Turing, who wrote to him suggesting that he use his Automatic

Computing Engine (ACE) to simulate the process rather than building a special machine. In his letter
to Ashby, Turing confessed: ‘I am more interested in producing models of the action of the brain, than
in the practical applications of computing.’ 531 With this, the connection between homeostasis,
computation and the operations of the brain had been established.

More recently, neuroscientist, Antonio Damasio, has argued that the primary function of the brain is
to maintain our homeostatic condition, and preserve our dynamic psychic equilibrium.532 Thus the
brain can be seen to operate less as a ‘command control center’ and more as a corrective mechanism
that keeps the body within a safe range of emotional impulses. As Damasio comments, ‘Survival
depends on the maintenance of the body’s physiology within an optimal homeostatic range. This
process relies on fast detection of potentially deleterious changes in body state and on appropriate
corrective responses.’533 While the brain itself highly adaptive, it can also serve as a mechanism of
adaptation.
The self-organisation of cities can therefore be compared to the dynamic equilibrium of the brain.
After all, cities are governed by both positive and negative feedback, much like the brain itself. At a
very basic level, then, we can see parallels between Damasio’s understanding of the homeostasis of
the brain and the principles of self-organisation that underpin a city, that could be reflected potentially
in the behaviour of any multi-agent system, such as a neural network.
Could the city be understood literally as a brain? In strict, neuroscientific terms, it obviously could not
be. One is a human-mineral hybrid system, and one a biological organism.534 Nonetheless a city could
be described as a kind of brain, albeit perhaps not a human brain. Brains and cities, it would seem,
have much in common. Both are multi-agent systems. The same could be said of certain software
systems. A neural network, after all, is composed of individual neurons which contribute to an
emergent collective behaviour. As Kelleher comments, ‘The overall behavior of the network emerges
from the interactions of the processing carried out by individual neurons within the network. Neural
networks solve problems using a divide-and-conquer strategy: each of the neurons in a network solves
one component of a larger problem, and the overall problem is solved by combining these component

solutions.’536 This means that we can extend the paradigm of emergence from relatively dumb
creatures, such as ants, to the sophistication of the brain, and on to cities and the operations of neural
networks themselves. The opportunity therefore presents itself for using neural networks to model –
and potentially augment – the operations of a city as a form of brain.

City Brain
Perhaps the most extensive exploration application of AI to the city has been the City Brain initiative
developed by Alibaba, a leading Chinese ecommerce company at the forefront of machine learning
development.537 City Brain is effectively a ‘digital twin’ of the city itself. The idea behind the City
Brain project is to develop a cloud-based system that stores information about the city in real time,
and uses machine learning to process that information in order to control the operations of the city and
improve its performance.
Liu Feng, one of the computer scientists behind the City Brain project, offers us a definition of the
City Brain:
“The City Brain is a new architecture of the Smart City based on the model of the Internet
Brain. Under the support of the city central nervous system (cloud computing), the city sensory
nervous system (Internet of Things), the city motor nervous system (Industry 4.0, Industrial
Internet) and the city nerve endings (Edge Computing), a city can achieve the human-human,
human-things and things-things information interaction through the city neural network (Big
SNS) and achieve the rapid smart response to city services through the city cloud reflex arcs, so
as to promote the organic integration of all components of a city, realizing the continuous
progress of city wisdom. Such a brain-like smart city architecture is called “City Brain”.”538
Initially, the City Brain initiative focused solely on traffic in the city of Hangzhou, where Alibaba is
based, understandably perhaps, given that Hangzhou used to suffer some of the worst traffic problems
in China.539 It has proved surprisingly effective in improving the operational efficiency of the city. A
pilot study showed that City Brain could increase the speed of traffic by 15 percent, and detect illegal
parking. Moreover, by constantly monitoring traffic in the city it can detect any signs of a potential
collision or accident and detecting accidents, and alert the police, thereby improving emergency very differently from computers, but it functions in a manner similar to the way that the Internet
works.”550 Whereas the computer merely represents a system of neurons, the Internet operates as a
brain.551 The hardware of the Internet is composed of millions of computers all connected in a manner
not dissimilar to how neurons in the brain are themselves interconnected, while the software is
effectively the web itself.
‘When I look at Google and the other search engines, I see more similarity to how memories are
stored and retrieved in the mind than I do to the underlying computer architecture. When I look at
websites, I think memes and memories, not hypertext. When I look at Classmates.com, MySpace,
and Facebook, I see social networks that are developing the way neural networks develop, a way
that is different than Metcalfe’s Law of Networks.
When I look at Internet computing clouds, I see the beginnings of a parallel processing machine
that has the ability to go beyond brute calculations, toward the loopy random prediction power of
the brain. But as I look out further into the future– as the electronic neurons multiply–I see in
cyberspace a replication of biological growth itself, like the evolutionary growth of the brain of an
insect, or an animal or even a human being.’552
Recent neuroscientific research would seem to support this comparison. According to neuroscientists,
Saket Narlakha and Jonathan Suen, the Internet and the brain are not only structured in the same way,
but also operate in a similar way:553
“While the brain and the Internet clearly operate using very different mechanisms, both use
simple local rules that give rise to stability. I was initially surprised that biological neural
networks utilized the same algorithms as their engineered counterparts, but, as we learned, the
requirements for efficiency, robustness, and simplicity are common to both living organisms
and networks we have built.
Once we reach this stage, we could expand our comparison between the city and the brain. It is not
simply that the city displays a form of self-regulating intelligence, much like the brain. Rather, once
the various sensors and devices in a city are connected to form an ‘Artificial Internet of Things’
(AIoT), they will be locked into the secondary logic of an overall system that shares further
similarities with the brain. 555
Whether or not we can make literal comparisons between the city and the brain, it is clear that the city
shares certain characteristics with the brain. Both display a form of intelligence. It is important to
point out, moreover, that there is no universal definition of ‘intelligence’. The intelligence of the city
might not match the intelligence of the brain, but it is a form of intelligence nonetheless, just as the
swarm intelligence of a slime mold is a form of intelligence.556
How, then, are we to understand the intelligence of the AI assisted city? As Wang Jiang comments:
‘With the evolution of the city, the city has its own intelligence. It’s not artificial intelligence.
So, you can’t put human intelligence into a city. The city is going to have its own
intelligence. . . The city is going to start its own thinking.’557
It could be argued, however, that the city already has a form of intelligence – although possibly not
the capacity to actually ‘think’ – through the logic of swarm intelligence. As such, AI can be seen to
operate as a form of auxiliary intelligence to an intelligent system constituted by the city itself. The
role of AI can therefore be seen as a supplementary one, to regulate and improve the performance of
the city, much as a pacemaker serves to regulate and improve the performance of the heart. From this
perspective, we can perhaps compare the role of AI-based technology in augmenting the operations of
a city to the role of AI in augmenting human intelligence. Seen in this light, the city of AI can be
understood as a city whose performance is augmented by AI.
Brain City – the city of the future – is the city of augmented intelligence.


No account of AI would be complete without a few predictions about its future. AI, after all, is all
about predictions. It recognizes patterns and predicts the future. And its success lies in the accuracy of
its predictions.
Equally, the history of AI can be read as a history of predictions about the future of AI. From Turing
onwards there have been a number of predictions about its potential. Of course, on occasions these
have proved to be hopelessly unrealistic.558 And it could be argued that inflated optimism about the
potential of AI was in part responsible for the various AI winters. Nonetheless, many predictions
about the potential of AI have proved surprisingly accurate.
Likewise, we human beings are also good at making predictions. Our brains might be quite weak at
some tasks, such as logical argumentation, memory and making calculations, but they are extremely
strong in the field of pattern recognition, and making predictions based on those patterns. Our brains
are inherently predictive. In the simple act of catching a ball, for example, our brains are constantly
updating their own calculations and predictions about the flight of the ball.559 We make predictions to
avoid both large-scale natural disasters, such as hurricanes, tsunamis and epidemics, and smaller scale
hazards – and this, it has been claimed, is one of the main reasons why we have a brain in the first
place.560 But we also make predictions to profit by gambling and investing in the stock market.
Moreover, as we have seen, neuroscientists now claim that perception itself is predictive.561 ‘Brains,’
as Andy Clark notes, ‘are essentially prediction machines.’562
What predictions, then, have human beings made about the future of AI? Many predictions about AI
could be described as mere extrapolations based on existing weak signals and emerging trends. In
Machines that Think: The Future of Artificial Intelligence, for example, Toby Walsh offers a series of
predictions about the year 2050, many of which appear quite straightforward. Walsh predicts that
cybercrime will become a major problem, that our health will be monitored by our phones, and that news will be generated by AI. In short, perhaps the most surprising aspect about some of Walsh’s
predictions is how unsurprising they are.
Some of his other predictions, however, are perhaps less obvious. Walsh predicts, for example, that
we will be able to ‘live on’ after our deaths through a personalised AI chatbot: ‘It will talk like you, it
will know the story of your past, it will comfort your family after you die.’563 Walsh’s most
interesting prediction, however, relates to the future of driving. He predicts that driving will
eventually be banned, as a result of the introduction of self-driving cars. 564 As self-driving cars
become more available, Walsh argues, we will drive less and less. As a consequence, our driving
skills will diminish, so that insurance premiums will increase. Gradually, we will become resigned to
not driving, to the point that young people might not even bother to learn to drive. Finally, driving
itself will be banned.
Change, of course, is often incremental, just as the development of the self-driving car is happening
gradually over time. In the case of a Tesla car, for example, this takes the form of regular software
updates.565 What is perhaps most interesting about Walsh’s prediction, however, is his comment about
our change of attitudes: ‘We won’t be allowed to drive cars any more, and we will not notice or even
care.’566 Human beings are good at adaptation to technologies, but what are often overlooked are the
change in social attitudes that result from this adaptation. In a culture of pervasive amnesia, as
Andreas Huyssen has described our current epoch, it is remarkable how quickly we forget what life
was like in the past.567 How many of us even remember what life was really like in the days before the
Internet and mobile phones?
But what if we were to push the implications of some of Walsh’s ideas still further? Walsh, for
example, predicts that by 2050 we will talk to our rooms. This is hardly much of a prediction in that
many of us already talk to our rooms through Alexa, while researchers, such as Behnaz Farahi, have
developed walls that respond to human speech.568 Meanwhile both Haley and Kurzweil have already
predicted that we will talk to our computers. But what if we were to think through the consequences
of the increasing use of voice commands? Would we not start to privilege speech increasingly over
writing, once speech-based informational systems have become sufficiently advanced? Would pens,
pencils, and even keyboards go out of fashion?


We might also surmise that language itself will change with the increasing popularity of speech
recognition systems, just as writing changed with the introduction of texting. Speech, after all, is quite
different to writing. Anyone who has transcribed a spoken conversation will surely vouch for this. It is
remarkable how often, when speaking, people fail to complete a sentence, branching off mid-sentence
on to a different topic, much like L-systems in computation, and yet still somehow managing to make
sense. Moreover rhetorical strategies, such as calculated pauses, intonation, increase in volume,
oratorical flourishes, or repetition to reinforce a point – strategies that resonate in spoken language –
are lost in writing. As William Hazlitt observes, ‘The most dashing orator I ever heard is the flattest
writer I ever read.’569
But what if we were to combine this insight with Walsh’s prediction about self-driving cars? What
would be the impact on literacy? Would standards of literacy gradually diminish with the increasing
use in speech-based information systems, just as driving skills might diminish with the advent of selfdriving cars? Would we gradually lose our ability to even spell, just as neat handwriting declined with
the advent of the keyboard? Indeed, let us not forget that in the 14th Century 80% of English adults
were not even able to spell their names, and prior to the development of the printing press, only 30%
of European adults were literate.570 And, if we were to gradually lose the capacity to write, would we
even notice or care?
What if we were to push the implications of this even further? What if Haley is correct, and we start
to design using voice commands and hand gestures, instead of by drawing? Would drawing go out of
fashion? And what if, as a consequence, we were to gradually lose our capacity to draw? And if so,
would we even notice or care?
Kurzweil’s Predictions
If there is anyone who has made a name for himself by going out on a limb with often seemingly
outrageous predictions, it is surely Ray Kurzweil. His predictions, nonetheless, about technology in
general and AI in particular have proved to be remarkably accurate. Indeed, Kurzweil himself claims
that 86% of his predictions have been correct.571
Although he acknowledges that many cultural events are impossible to predict, Kurzweil believes that
“fundamental measures of information technology follow predictable and exponential trajectories,


belying the conventional wisdom that “you can’t predict the future.”572 Kurzweil used to subscribe to
the logic of Moore’s Law in his earlier predictions.573 Moore’s Law is derived from a comment made
in 1965 by Gordon Moore, then CEO of Fairchild Semiconductor, and later to become the co-founder
of Intel, that the number of transistors on an integrated circuit board would double every year, while
unit costs would fall correspondingly.574 Moore subsequently revised this forecast to that number of
doubling every two years.575 He then developed this observation into a theory of exponential growth,
that Kurzweil himself applied to not only semi-conductor circuits, but also other forms of
technology.576 The simple laptop, for example, has conformed broadly to these principles.
Exponential growth, however, cannot go on forever. As Murray Shanahan notes, the laws of physics
dictate that every technological trend must meet a plateau eventually.577 Rodney Brooks argues that
the whole idea has been ‘oversold’.578 Meanwhile, Kurzweil himself came to believe that Moore’s
Law would not hold true beyond 2020. He has therefore developed his own ‘Law of Accelerating
Returns’:
‘An analysis of the history of technology shows that technological change is exponential,
contrary to the common-sense 'intuitive linear' view. So we won't experience 100 years of
progress in the 21st century—it will be more like 20,000 years of progress (at today's rate). The
'returns,' such as chip speed and cost-effectiveness, also increase exponentially. There's even
exponential growth in the rate of exponential growth.’579
In 1990, Kurzweil published The Age of Intelligent Machines, a book to which a number of other
significant futurists and computer scientists contributed. Here Kurzweil speculates about the
possibility of computers achieving a level of intelligence comparable to human intelligence.580 He
goes on to make a series of other predictions, such as the fact that a computer would beat the world
chess champion by 2000, as noted above;581 that there would be driverless cars ‘by well into the first
half of the twenty-first century;’582 that planes would become pilotless;583 and that laser weapons

would be developed.584 Importantly, Kurzweil also predicts that, as computers will begin to compete
with human beings, paradoxically they will begin to reveal what it is to be human.585
Perhaps the most stunning prediction that Kurzweil makes in this book, however, relates to the use of
laptops with wi-fi, and the possibility for students to have to access all the libraries in the world ‘from
their school bags’, and to send ‘love notes’ by wi-fi:
‘Wireless networks will allow the easy sharing of courseware, submissions by students of
papers, exams, courseware responses, and other creations, electronic mail and other
communications (e.g. love notes). By being plugged into international networks of information,
students will have immediate access to all the libraries of the world right from their school
bags.’586
Let us not forget that this prediction was made back in 1990.
In The Age of Spiritual Machines: When Computers Exceed Human Intelligence, published in 1999,
Kurzweil makes a series of further predictions for the year 2009.587 His predictions about computers
in particular have proved to be surprisingly accurate: ‘Portable computers,’ notes Kurzweil, ‘will have
become dramatically lighter and thinner than the notebook computers of ten years earlier.’ 588 Here
one thinks of the MacBook Air launched in 2008, which is significantly lighter than bulky, early
laptops available at the time of his prediction. Indeed he predicts that we will even be able to ‘wear’
our computers.589 Now, of course, we have become so used to iPods, FitBit watches, mobile phones
and Bluetooth headsets, that it is difficult to recall a time when such everyday items did not exist. And
he predicts that they will have no keyboards;590 and he predicts that cables would disappear and that
we would be using wi-fi. 591 In an age of touchscreens on mobile phones, and universal wi-fi, it is
difficult to even recall that there was a time when these facilities were not available. Kurzweil also
successfully predicts the introduction of facial recognition for our devices;592 and the use of AR

goggles.593 Again what stands out, then, about Kurzweil’s predictions is how accurate they have
proved to be.
On a few occasions, however, some of Kurzweil’s predictions have failed to materialise.594 It is as
though Kurzweil underestimates how long these developments would take to become commercially
viable, although they might be technically possible in the laboratory.595 In 1990, for example,
Kurzweil claims that by 1999, ‘Consumers will be able to sit down at their home computers and design
their own clothes to their own precise measurements and style requirements using friendly, computerassisted design software.’596 Likewise Kurzweil predicts that by 2009 translating telephones will allow
users to speak to each other in different languages, and that most text will be created using speech
recognition.597 Although there are now apps that can do this, they were not available in 2009.
Likewise, on other occasions Kurzweil is only partially correct. For example, he predicts that by 2009
most long distance travel would be made using ‘cybernetic chauffeurs,’ a form of auto-pilot, although
traditional transportation would be used for local travel.598 He is careful to distinguish these from full
self-driving cars, and, while we already have cruise control and automatic warnings when we stray
out of our lane, by 2009 we did not have ‘cybernetic chauffeurs’ as such.
The Singularity
Kurzweil’s most famous prediction, however, relates to what he calls the ‘Singularity’. In 2005 he
claims that by 2029 we will achieve a level of AI that will match human level intelligence.599 Not so
long after this, according to Kurzweil, we will reach the Singularity. His most recent prediction for
the date of the Singularity is 2045.600
The term, ‘singularity’, comes from physics, and refers to a moment, such as the Big Bang, when
mathematics begins to break down, and so does our comprehension.601 John von Neumann
subsequently relates the term to the accelerating pace of technological development, which Stanislaw
Ulam paraphrases as the moment when, ‘the ever accelerating progress of technology. . . gives the
appearance of approaching some singularity in the history of the race beyond which human affairs, as we know them, could not continue.’602 Vernon Vinge later further expands this definition, coining the
term, the ‘technological singularity’:
‘What are the consequences of this event? When greater-than-human intelligence drives
progress, that progress will be much more rapid. In fact, there seems no reason why progress
itself would not involve the creation of still more intelligent entities – on a still-shorter time
scale. The best analogy that I see is with the evolutionary past: Animals can adapt to problems
and make inventions, but often no faster than natural selection can do its work – the world acts
as its own simulator. We humans have the ability to internalize the world and conduct “what
if’s” in our heads; we can solve many problems thousands of times faster than natural selection.
Now, by creating the means to execute those simulations at much higher speeds, we are
entering a regime as radically different from our human past as we humans are from the lower
animals. From the human point of view, this change will be a throwing away of all the previous
rules, perhaps in a blink of an eye, an exponential runway beyond any hope of control.”603
Kurzweil builds upon these earlier descriptions, and describes the Singularity as an explosion of
intelligence, a moment of technological change so rapid that it amounts to a ‘rupture in the fabric of
human history’ with enormous consequences for the future of the human race:
‘Within a few decades, machine intelligence will surpass human intelligence, leading to the
Singularity—technological change so rapid and profound it represents a rupture in the fabric of
human history. The implications include the merger of biological and nonbiological
intelligence, immortal software-based humans, and ultra-high levels of intelligence that expand
outward in the universe at the speed of light.’604
From a philosophical perspective, David Chalmers agrees with Kurzweil that the Singularity is indeed
possible.605 Meanwhile, although some are ambivalent – or even negative – about the impact of these
developments, Kurzweil himself is unequivocally positive. Machines have already improved our lives,
and Kurzweil believes that they are likely to improve them still further: ‘What’s actually happening is
[machines] are powering all of us. They’re making us smarter. They may not yet be inside our bodies, but,
by the 2030s, we will connect our neocortex, the part of our brain where we do our thinking, to the
cloud.’606 Kurzweil is convinced that machines will not only make us more intelligent. They will also


bring other benefits to humanity: ‘We’re going to be funnier, we’re going to be better at music. We’re
going to be sexier.’ 
AGI and Beyond
Following the Singularity, the next stage would be for machines to achieve Strong AI or Artificial
General Intelligence (AGI). To achieve AGI, it is not simply a question of a computer passing the
Turing Test.608 To pass the Turing Test, after all, a computer only needs to appear to be more than a
chat bot trained to give automatic responses. Rather, to achieve AGI, a computer must be genuinely
capable of thinking for itself. This is not so straightforward.609 To do so, it needs to be sentient and
have consciousness.610 Perhaps the biggest problem with AGI, however, is that as yet we still do not
fully understand human consciousness. Until such time as we can actually understand consciousness,
it is difficult to speculate when AGI might ever be achieved.
Clearly we are still a long way from reaching AGI. Nonetheless, most working in the field of AI
believe that AGI is achievable. David Chalmers, one of the leading philosophers of consciousness, is
certainly confident that it can be achieved.611 He also believes that the development of GPT-3 by
Open AI has brought the possibility of AGI much closer.612 Indeed, OpenAI, like other leading AI
companies, such as DeepMind, is dedicated to developing AGI. Certainly, for Kurzweil, there is no
question that – eventually – we will achieve AGI. His latest prediction for the advent of AGI is the
year 2045.
Once AGI has been achieved, it is a relatively short step to superintelligence or artificial
superintelligence (ASI). As soon as machines become capable of thinking for themselves, they would
also be able to improve themselves, and their full potential would be unleashed. Superintelligence can
take many forms.613 Nick Bostrom defines it as ‘any intellect that greatly exceeds the cognitive
performance of humans in virtually all domains of interest.’614 The possibilities of ASI are seemingly

endless:
‘By definition, an ASI can perform better than us in any conceivable task, including intellectual
skills. It could engage in scientific research and teach itself new abilities, improve its own code,
create unlimited copies of itself, choose better ways of deploying its computational resources,
and it could even transform the environment on Earth, or colonise other planets.’615
Closely aligned with superintelligence is the notion of ‘ultraintelligence’, a term that Good coined
back in 1965:
“A machine that can far surpass all intellectual activities of any man however clever. Since the
design of machines is one of these intellectual activities, an ultraintelligent machine could
design even better machines. There would then unquestionably be an “intelligence explosion,”
and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is
the last invention that man need ever make.’616
The question remains, of course, as to whether we would even be able to recognise the intelligence of
a superintelligent or ultraintelligent machine, in that the intelligence that it would display would be far
beyond our comprehension. As Musk comments, ‘The biggest mistake that I see artificial
intelligence researchers making is assuming that they're intelligent. Yeah, they're not, compared to
AI. And so like, a lot of them cannot imagine something smarter than themselves, but AI will be
vastly smarter—vastly.’617
The biggest issue, however, is that the ultraintelligent or superintelligent machine would effectively
be the last invention that human kind would ever need to make, in that once we reach that point,
superintelligent machines would be able to design even more intelligent machines, and human beings
would never be able to compete.
Game over.
Prediction Errors

‘Prediction is very difficult,’ Niels Bohr remarks, ‘especially about the future.’618 Get it right, and
everyone will tell you that it was obvious that it would happen. Get it wrong, and everyone will tell
you that it was equally obvious that it would never happen. Predictions also tend to be strewn with
errors.619 This is why techniques, such as backpropagation, are used to correct errors and improve the
accuracy of predictions in AI. But predictions about the future of AI itself seem to be particularly
problematic.
Dates themselves are difficult enough. Take predictions about ‘human level intelligence’. Turing
predicts that we would reach this stage by 2000, while Kurzweil predicts that we will reach it by
2029.620 Martin Ford conducts a survey, with the median date being 2099. 621 But in fact there have
been many different surveys of timelines, none of which agree.622
Or take predictions about the Singularity. Kurzweil predicts that it will happen by 2045. But in the
catalogue for the recent AI: More than Human exhibition at the Barbican in London, AI specialists,
Kanta Dihal, Andrew Hessel, Amy Robinson Sterling, and Francesca Rossi, are invited to predict the
date of the Singularity, and, significantly, none of them can agree on the date.623
Or take predictions about AGI. Although Kurzweil expects AGI to be achieved by 2045, Rodney
Brooks thinks that we still have a long way to go, and does not expect that we will see AGI until 2200:
‘Any AI program in the world right now is an idiot savant living in the sea of now.’624
The real problem, however, is that there is even less agreement about the actual definition of these
terms. Rossi conflates the Singularity with AGI.625 Likewise, Ford conflates ‘human level AI’ with
AGI.626 Meanwhile Russell considers that the quest for AGI is really just the quest for AI itself: ‘AGI
is actually what we have always called artificial intelligence. We are just not finished yet, and we
have not created AGI yet.

By contrast, Kevin Kelly believes that the entire project of AGI is misconceived.628 Hassabis even
argues that intelligence and consciousness do not even depend upon each other: ‘You can have
intelligence without consciousness, and you can have consciousness without human-level
intelligence.’629 Roger Penrose concurs with this view.630 Seth also agrees: ‘Consciousness and
intelligence are entirely different things. You don’t have to be smart to suffer, but you probably have
to be alive.’ 631 Meanwhile, as Kurzweil observes, a machine might act as though it has a mind,
regardless of whether it has a mind or not.632 This is born out by the development of GPT-3 by Open
AI, which is quite capable of claiming that it is sentient, when asked, even though it is clearly not.633
This is not to say that GPT-3 is actually ‘lying’. In fact it is not aware of anything, still less whether it
is lying or not. It is simply selecting the most appropriate answer from the vast dataset of human
operations on which it has been trained.634 Revealingly, however, this also suggests that human beings
themselves are perhaps not as honest as they like to think they are.
Consciousness, as Max Tegmark remarks, is probably all that humans beings will be able to cling on
to, once computers exceed the intellect of human beings: ‘We humans have built out identity of being
Homo sapiens, the smartest entities around. As we prepare to be humbled by ever smarter machines, I
suggest that we rebrand ourselves as Homo sentiens!’635 Besides, if we see the world in terms of
extended intelligence, as a coupling between human and machine, the need for a machine to also have
consciousness, seems less imperative. Indeed, as Musk observes, thanks to the prosthetic logic of
extended intelligence, humans are already superhumans. 🦸‍♂️ 
In short, the Singularity and AGI remain difficult to define, let alone to predict.637 There is little
consensus as to what they might be, still less as to when they might happen. The same could be said
of superintelligence. Despite Kurzweil’s optimism, it seems that superintelligence is also still a long
way off. As Rodney Brooks observes, ‘We don’t have anything near as good as an insect, so I’m not afraid of superintelligence showing up any time soon.’ 638 In some senses, however, these questions
are purely academic, or as Brooks puts it, ‘Predicting an AI future is just a power game for isolated
academics who live in a bubble away from the real world.’639
The Future of Intelligence
How will AI be perceived once it has been completely integrated into our lives?
Back in 2002 Bill Gates predicted that the first decade of the third millennium would be known as
‘The Digital Decade’ in that, by the time that it would come to an end, the impact of the digital realm
would be so far-reaching that there would scarcely be any facet of human existence that would remain
untouched by it.’640 His prediction has proved largely accurate.641
Similarly, back in 2010 it was also predicted that by 2020 we would stop using the term ‘digital’ in
architectural design circles.642 This would not be because we would no longer be using digital design
tools, but for precisely the opposite reason. Almost everyone would be using digital tools. For this
very reason, the term itself would disappear. The digital would be everywhere and nowhere.643 We
would therefore stop referring to ‘digital design’. This prediction has also proved largely accurate. In
many aspects, ‘digital design’ has become simply ‘design’.
This is echoed in the way that we refer to drawings. Initially, when most drawings were drawn by
hand, they were referred to as ‘drawings’, and CAD drawings were called ‘digital drawings’. Once
most drawings became CAD drawings, the term ‘drawing’ came to refer to CAD drawings, while the
term ‘hand drawings’ came to refer to drawings drawn by hand. In other words, not that the tipping
point has been reached when more drawings are produced computationally than drawn by hand, CAD
drawings became simply ‘drawings’.
A similar analogy could be made in relation to cars. In the very early days, when there were relatively
few cars on the road, they were referred to as ‘horseless carriages’, and carriages drawn by horses
were still referred to as ‘carriages’. However, once ‘horseless carriages’ came to outnumber
‘carriages’, then the situation changed, and ‘horseless carriages’ became known as ‘cars’, and
carriages drawn by horses became known as a ‘horse drawn carriages’. By extension, we could
predict that once self-driving cars outnumber cars driven by humans, self-driving cars will become
known as simply ‘cars’ and what we now call ‘cars’ will become known as ‘human-driven cars’.
What about AI? Are we now in ‘The AI Decade’? And what might we predict about the way that we
will refer to AI by the end of this decade? At present, we distinguish between AI and human
intelligence, and refer to human intelligence simply as ‘intelligence’. With time, however, as AI
becomes increasingly prevalent and more powerful than human intelligence, we are likely to reach yet
a further tipping point. Could we predict that by the end of the decade, AI will simply be known as
‘intelligence’, and what we now call ‘intelligence’ will become known as ‘human intelligence’? And
might we even begin to view ‘human intelligence’ with a degree of sentimentality, just as we now
view horse-drawn carriages, hand written letters and hand drawn drawings?
The irony of AI being called ‘intelligence’ is that when John McCarthy originally coined the term
‘artificial intelligence’ back in 1956, he and others did not really like the term, but “I had to call it
something, so I called it ‘Artificial Intelligence’.”644 His goal, however, was to achieve genuine –
rather than artificial – intelligence. This is still the case with many contemporary AI researchers.
Besides, as Walsh observes, “Putting the adjective artificial in front of anything never sounds very
good.”645 Stibel also claims that the word ‘artificial’ is misleading, causing people to associate AI
with something fake or “less than” intelligent. Instead, Stibel notes, what is needed is an artificial
brain to create real intelligence, “much in the way that an artificial heart is used to create a real
heartbeat.
Interestingly, many of the central figures in AI have been more concerned to understand how the
brain works. Turing, as we have already seen, had confessed that he was more interested in how the
brain works than in practical applications of computing. 647 Likewise, Geoffrey Hinton, now a
luminary within the world of AI, initially studied physiology for a particular reason: ‘I wanted to know how the brain worked.’648 Demis Hassabis, who holds a PhD in neuroscience, and is CEO of
DeepMind, does not refer to AI, but simply to ‘intelligent systems’: “Our ambition in DeepMind is to
build intelligent systems to help find solutions that can learn to solve any complex problem. . . Put
another way, we want to use it to solve everything else.’649
The quest for AI is the quest for intelligence itself.
Architectural Intelligence
The applications of AI and data driven informational systems have now become so widespread
throughout the domain of architecture that we should perhaps refer to them collectively as
contributing to a form of ‘architectural intelligence’, an intelligent approach to architectural design
that is fast becoming the dominant approach.650
Makoto sei Watanabe is probably the first to use the term, ‘architectural intelligence’ to refer to a new
type of architectural designer, the ‘AI Tect’, exploring the potential of AI in architecture.651 Wanyu
He has also coined a similar term, the ‘AI-chitect’, to refer to a very similar kind of designer.652 Let us
not forget, of course, that Molly Wright Steenson also uses the term in a more narrow sense, to refer
to four pioneers in the field of computational architecture.653
In this context, however, ‘architectural intelligence’ is not limited to the application of AI. It could be
used to refer to a new approach to design that embraces all forms of intelligence in architecture, such
as ‘structural intelligence’, ‘environmental intelligence’, ‘constructional intelligence’, ‘programmatic
intelligence’ and so on. It is a new approach that has already been defined: ‘A new movement is
emerging. It is a movement that operates at the interface between advanced digital technologies and
the built environment. . . We are calling this new movement ‘architectural intelligence’.’ 
Nor is architectural intelligence limited to the digital. We can find examples of ‘biological
intelligence’ throughout nature. Indeed nature itself offers countless examples that can inspire a
biological approach towards design. This informs the work of architects, such as Achim Menges, Neri Oxman, and Claudia Pasquero, who draw upon biomimicry and biomimetic principles. So too, we
can find examples of ‘material intelligence’ throughout the natural kingdom. This could even be
described as a form of ‘material computation’. The form of a sand dune, for example, is ‘computed’
through the force of wind and gravity on the particles of sand. Likewise the form of a soap bubble is
‘computed’ through a combination of forces, such as internal and external pressure, surface tension
and so on. This, in turn, informs the work of architects, such as Antoni Gaudí and Frei Otto, who draw
upon material behaviours and morphogenetic principles.655
Buildings, of course, are material, whereas computation is immaterial. However, we can now use
intelligent computational techniques, such as AI, to inform the intelligent design of a material
building and make our designs ever more materially intelligent. Architectural intelligence therefore
stands not only for the intelligent use of materials and the use of intelligent materials in the
construction of a building, but also for the use of intelligent computational techniques to design the
material form of that building.
How might we refer to ‘architectural intelligence’ in the future, once the various forms of intelligence
– structural intelligence, environmental intelligence, material intelligence, programmatic intelligence
and so on – have become increasingly prevalent in architectural circles? Could we predict, perhaps,
that once every aspect of design has become intelligent, the term ‘intelligence’ would cancel itself out?
Would references to ‘intelligence’ disappear?
If so, all that we would be left with would simply be ‘architecture.’
AI and the Future of Architecture
Undoubtedly, however, there will be some opposition to the introduction of AI into the architectural
studio, just as there was opposition to the introduction of computation. We could predict that AI might
also be banned from some architectural studios, just as computers were once banned in certain schools
of architecture.656 But this opposition is likely to fade away eventually, as happened with the initial
opposition to computation itself.657 Indeed, some might choose not to use AI, even though it will
obviously prove more convenient, just as some hipsters today deliberately choose to ride bicycles
instead of driving cars, as a lifestyle choice.658 Clearly, AI will not be for everyone.



It is the example of the self-driving car, however, that might shed some light on the full implications
of introducing AI into architecture. Christensen, as we have noted, compares the introduction of AI
into the architectural office with the development of the self-driving car. 659 There is, however, a
problem with this analogy.
AI, of course, will make life easier, just like self-driving cars. With self-driving cars, however, the
driver eventually becomes redundant. If we adopt the same model for architecture, would this not
mean that eventually the architect would also become redundant?660 Rather than striving for the
equivalent of the self-driving car in architecture, should we perhaps keep to the model that Wolf Prix
suggests, with the architects in the front seats, and AI in the back seats?
Or is it already too late to prevent these developments? Might the architect also disappear, just as the
human driver will disappear? And might we not notice or even care?
Let us finish, then, with a series of the predictions about the future impact of AI on architecture, based
on comments made above. These are predictions as to what will be technically possible – although not
perhaps implemented universally – by the end of the decade:
