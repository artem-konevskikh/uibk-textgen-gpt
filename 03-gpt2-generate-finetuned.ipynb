{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03-gpt2-generate-finetuned.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOI9G9jJCxTWruxksepv+BD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FNeXNKF6Zv59"},"source":["# GPT-2 Text Generation Notebook\n","\n","by [Artem Konevskikh](https://github.com/artem-konevskikh)\n","\n","Based on notebook by [Max Woolf](http://minimaxir.com). For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple)."]},{"cell_type":"markdown","metadata":{"id":"VM69Hoc5j27B"},"source":["## Installation"]},{"cell_type":"code","metadata":{"id":"-du42C9dZsEy","cellView":"form"},"source":["#@title Imports\n","#@markdown By running this cell we are loading libraries needed to work with GPT2\n","%tensorflow_version 1.x\n","!pip install -q gpt-2-simple\n","import gpt_2_simple as gpt2\n","from datetime import datetime\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"2scIRV9bpYuZ"},"source":["#@title GPU\n","\n","#@markdown Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n","\n","#@markdown We can verify which GPU is active by running this cell.\n","\n","!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"3QNyS3GKlVZD"},"source":["#@title Mounting Google Drive\n","\n","#@markdown Colab notebooks are Virtual Machines, so any data stored in it will be vanished as soon as we close it or reset it. So the best way to keep input data and save trained models is to mount your Google Drive and store it there.\n","\n","#@markdown After running this cell you will get the link, where you should grant the access to your Drive and copy auth token. Paste this token to the input below and press Enter\n","\n","gpt2.mount_gdrive()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wgWDuRBNnMyu"},"source":["## Text Generation\n","\n","In this notebook we will use the model you finetuned on your texts previously."]},{"cell_type":"code","metadata":{"cellView":"form","id":"vC5sZT3IdTOV"},"source":["#@title Load a Finetuned Model Checkpoint\n","\n","#@markdown Running this cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM.\n","\n","#@markdown **IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports.\n","\n","#@markdown Run name\n","run_name='run1' #@param {type: \"string\"}\n","gpt2.copy_checkpoint_from_gdrive(run_name=run_name)\n","sess = gpt2.start_tf_sess()\n","gpt2.load_gpt2(sess, run_name=run_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"k-9b2707geJ0","executionInfo":{"status":"ok","timestamp":1618211153888,"user_tz":-180,"elapsed":14940,"user":{"displayName":"Artem Konevskikh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzk0bqzeBuXtDrZ7vBWslL76vC9-a_i8tXACnzQQ=s64","userId":"00874259313111924918"}}},"source":["#@title Generation with the finetuned model\n","#@markdown **Generation parameters**\n","\n","#@markdown Run name\n","run_name= 'airun1' #@param {type: \"string\"}\n","\n","#@markdown You can pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there\n","prefix = '' #@param {type: \"string\"}\n","#@markdown Number of tokens to generate (default 1023, the maximum)\n","length = 300  #@param {type:\"slider\", min:1, max:1023, step:1}\n","#@markdown The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n","temperature=0.7  #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","#@markdown Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n","top_k=0  #@param {type: \"number\"}\n","#@markdown Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n","top_p=0.9  #@param {type:\"slider\", min:0, max:1, step:0.1}\n","#@markdown Number of samples to generate\n","nsamples=5  #@param {type: \"number\"}\n","#@markdown Number of samples to generate in pararallel to speed up the process\n","batch_size=5  #@param {type:\"slider\", min:1, max:20, step:1}\n","#@markdown Save samples to text file\n","save_to_file = True #@param {type:\"boolean\"}\n","\n","\n","#@markdown *__Set parameters and  and run the cell to generate samples__*\n","gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow()) if save_to_file else None\n","gpt2.generate(sess,\n","              run_name=run_name,\n","              destination_path=gen_file,\n","              prefix=None if prefix=='' else prefix,\n","              length=length,\n","              temperature=temperature,\n","              top_k=int(top_k),\n","              top_p=top_p,\n","              nsamples=int(nsamples),\n","              batch_size=batch_size\n","              )"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"-IpQoerrjdvz"},"source":["#@markdown **Download newest generated file**\n","if gen_file:\n","  files.download(gen_file)"],"execution_count":null,"outputs":[]}]}